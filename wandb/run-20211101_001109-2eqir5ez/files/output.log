
CUDA availability: True
  1%|█                                                                                                                                                                                   | 3/496 [00:00<02:17,  3.59it/s]
### event lambdas:  tensor([[72.0882, 56.7107, 32.5343]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[  6.9320,  33.7215,  11.0399,  84.6069, 111.7996,  49.3033,  34.8371,
          19.1710,  21.1177,  80.3711,   8.2151,  63.5651,   5.1312,  14.8554,
          58.1076,  27.0482,  20.0075,   6.1201,  32.3290,  31.3376,  10.3809,
          16.3096,  16.8634,  14.1780,  49.8331,   8.7307,  60.1750,   9.4385,
          78.1382,   8.3724]], grad_fn=<SoftplusBackward>)
##### event loss: -11.798147201538086 non event loss:  1583290.447265625 chocie_l: 0.6793563961982727
### event lambdas:  tensor([[20.6057,  9.1515, 48.9212, 25.1026, 19.6036, 23.5869]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[48.5238, 26.4576,  4.4008, 12.7469,  8.2639, 18.1511, 26.7608,  4.0072,
          8.5613,  4.1914, 19.8219, 18.4717,  3.5246,  4.7692, 16.5714, 43.0390,
         16.1977,  1.3418, 23.8948, 14.4766,  3.2914,  0.2802, 14.9565,  0.3760,
         15.8803,  8.7538,  7.7228, 19.9565,  1.2126, 11.6441,  1.6474, 19.8006,
          4.0464, 31.7669,  3.2233, 13.0604, 13.0157, 34.6003, 16.0842, 25.0602,
          5.6366,  1.9558, 17.4684, 12.1458, 26.6262, 19.9565, 28.8851, 23.1811,
          1.5523,  3.4003, 11.4981, 18.1775,  5.2200, 16.0892,  1.0866,  3.1489,
          3.9659,  9.3155,  9.3501, 16.3322]], grad_fn=<SoftplusBackward>)
##### event loss: -18.48907470703125 non event loss:  1342843.7917480469 chocie_l: 1.8003629446029663
### event lambdas:  tensor([[ 0.9208, 31.0727, 22.0512,  7.5079,  0.3283]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[ 5.4935,  4.7125,  2.0001,  6.3260,  1.9861,  1.4240,  1.9578,  2.3544,
          0.8139,  0.4459,  9.5334, 80.8248,  8.9707, 96.9864,  3.6680,  0.2982,
          0.4875,  0.3116,  2.9512,  6.8299,  5.9548,  0.2199,  0.1494,  1.1609,
         27.4136,  6.2349,  1.6387, 27.3335,  3.2904,  6.8329,  0.2245,  6.0161,
         10.1122, 11.2601, 34.7068,  2.3097, 11.0201, 12.5762,  9.3056,  4.8067,
          0.9292,  2.5982,  1.8852, 53.5072, 16.0105,  7.8658, 15.9642, 10.1354,
          1.0745, 39.5406]], grad_fn=<SoftplusBackward>)
##### event loss: -7.349394798278809 non event loss:  4835738.901550293 chocie_l: 0.5845227241516113
### event lambdas:  tensor([[ 52.3884, 101.6031, 304.3102,   6.8231,   5.8683]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[ 51.4141, 163.2561,  17.5709,  52.2302,   2.9496,  60.8341, 286.5172,
          37.4229, 178.5580, 296.3854,  70.4046,  21.1966,  52.1158, 164.6798,
          10.9886,  25.0476, 270.2216, 205.2271,  15.2306, 102.9388,   3.3174,
          24.9215,  82.5106,   5.7464, 232.5585,  12.8293,  46.8351,   4.8607,
         247.8478, 205.9561,  12.3293,  41.4411,   7.7231,  46.4703,  66.4311,
          30.6251, 197.9963,  17.2817,  25.8267,   2.9993,  19.4034,  93.2035,
          27.2758,  42.0778,  64.2772,  30.5561,  31.3190,  88.3463,  49.0207,
          40.6471]], grad_fn=<SoftplusBackward>)

  3%|█████                                                                                                                                                                              | 14/496 [00:02<01:15,  6.41it/s]
### event lambdas:  tensor([[2.9312e+01, 2.3261e+02, 3.4524e+01, 3.9787e+01, 6.4801e+01, 4.7212e-03]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[  3.4079,  29.3611,  65.6805,  70.1779,  27.5220,  40.9256,  20.4147,
         114.0940,   1.3582,   5.3406,  34.1198,  47.5422,  32.3601, 177.9543,
           8.8367, 128.1338,  50.5092,  85.0288, 143.5400,  80.9466, 111.5353,
          53.6636,  34.1582,  22.5459,  15.8410, 224.0585,  20.2722,  58.0735,
          50.7206,  20.2508,  93.9520,  24.4312,   0.7910,  92.5384,  73.3650,
          78.7563, 148.4554,  11.6608, 117.9140,  29.6868,   2.6331,  13.4922,
          26.9438,   0.7385,  31.7821,  36.9706,  60.5514,  37.2623,  48.5261,
          62.9610, 101.0312, 213.5331, 134.1772,  83.9311,   6.9316,  17.6825,
          28.6694,  23.4371,  24.4476, 149.6587]], grad_fn=<SoftplusBackward>)
##### event loss: -14.86819839477539 non event loss:  25324296.16796875 chocie_l: 0.017091792076826096
### event lambdas:  tensor([[7.4854e+00, 3.2468e+00, 2.7801e+01, 1.7750e-02, 3.7145e+00, 1.1862e-04,
         3.5661e-02, 4.1315e-03, 2.3869e+00, 6.6327e-05, 3.5677e+01, 1.0753e+01]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[3.0294e+01, 7.2182e+01, 2.5046e-04, 5.8000e+01, 1.1899e-01, 2.9222e-04,
         1.5678e+01, 5.8577e-01, 1.1003e+00, 7.9366e+00, 1.0184e+02, 3.2897e-02,
         1.5694e+01, 3.2056e+00, 6.8031e+01, 4.7227e-05, 2.2553e+00, 4.5096e-04,
         1.3772e-01, 4.2008e+01, 8.1550e+01, 5.7800e+01, 3.7822e-01, 8.2608e+00,
         6.4115e+01, 1.6544e+00, 6.4956e-04, 5.5163e+00, 4.0519e+01, 3.8570e+00,
         5.1230e+01, 1.6580e+00, 1.0792e+00, 8.2226e+01, 1.9614e-05, 4.2201e+01,
         9.0969e-03, 1.6716e-02, 1.8034e+01, 1.4250e+01, 8.2360e-05, 1.1433e-02,
         8.2663e+00, 9.2325e-02, 2.6100e-03, 7.0522e-03, 3.4212e+01, 7.8150e+01,
         2.9540e-02, 2.3258e+01, 2.3114e-01, 2.7681e+01, 3.2141e+01, 1.0933e-03,
         7.0811e-04, 1.4103e-04, 2.7303e+01, 1.5404e+01, 2.2205e+01, 2.0613e-04,
         3.4225e+01, 1.8398e-03, 1.1547e+00, 1.9792e+01, 3.3945e+00, 3.4701e+01,
         8.9043e-06, 5.1055e-03, 7.6876e+01, 2.8393e+01, 1.5298e+01, 3.0677e+00,
         1.2152e+01, 4.2179e+00, 3.2391e+01, 8.3349e+01, 2.3309e+00, 6.4902e+01,
         7.4105e+01, 4.1936e+01, 1.6729e+01, 6.4980e-04, 1.2374e+01, 2.6614e-04,
         3.6454e+00, 7.0661e+01, 5.7319e-04, 9.6802e+01, 1.4243e-01, 3.0788e+01,
         9.3421e-02, 1.1958e+00, 1.7441e+01, 2.6305e+01, 3.0893e+00, 1.2025e+02,
         2.1958e-01, 3.6571e-05, 1.2045e+01, 5.4730e+00, 8.1855e+01, 1.2969e-04,
         4.3425e-05, 2.0864e+01, 1.1015e-01, 7.9213e+01, 3.1095e+00, 1.3998e+00,
         4.0966e+01, 2.3420e-04, 7.1050e+01, 5.7096e-05, 5.8698e+00, 2.1718e-03,
         1.0306e+01, 5.5906e+01, 1.7489e-02, 5.8152e+01, 9.0307e+01, 1.1154e+01]],
       grad_fn=<SoftplusBackward>)
##### event loss: 16.86705207824707 non event loss:  21965279.97216797 chocie_l: 0.045127637684345245
### event lambdas:  tensor([[1.5685e-03, 1.8264e+01, 1.9036e-01, 9.2263e+01, 3.7640e+01, 1.5891e-06,
         3.2298e+01, 5.0322e+01, 1.1210e+02]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[5.7436e-05, 1.7653e+01, 1.0447e+02, 1.5569e-01, 2.4033e+01, 4.1814e+01,
         1.4530e-03, 2.5608e-01, 2.1483e+01, 1.3405e-04, 4.1626e+00, 1.8804e+01,
         2.0193e+01, 3.6404e+01, 1.6347e-01, 7.0561e+01, 5.8200e+01, 4.6660e+01,
         2.8745e+01, 2.9884e+01, 8.7816e-02, 1.0866e+02, 5.8555e+00, 6.8837e+01,
         8.3185e-04, 4.4984e+01, 4.4342e-01, 1.9774e+01, 4.4356e-03, 7.4509e-02,
         6.9457e-05, 1.3407e-04, 3.9827e-01, 1.4959e+01, 6.9500e-01, 4.8055e+01,
         2.9367e-04, 4.7588e-02, 9.4229e+00, 4.9180e+00, 1.4024e+01, 5.1574e+01,
         3.5751e-03, 4.0449e-01, 2.7243e-06, 2.5107e-03, 2.9729e+01, 1.0026e+01,
         1.4251e+00, 1.0686e+01, 1.0069e-04, 3.7284e-05, 3.0180e+01, 2.4718e-06,
         1.7546e+01, 6.9379e+01, 3.1796e+00, 3.0136e+00, 3.6053e+01, 3.9117e+00,
         1.2712e+00, 5.3277e+00, 9.4735e-01, 6.0746e-04, 3.0378e-04, 3.7064e-05,
         2.7815e+01, 3.8716e+01, 8.5740e+00, 7.3922e+00, 5.0973e+01, 6.4999e+01,
         6.3278e-05, 2.2834e+01, 2.1838e-02, 4.2011e-01, 2.2081e+01, 1.2346e+01,
         3.8166e+01, 1.4397e+01, 9.3308e-01, 5.3880e-02, 7.2827e-03, 2.9387e+01,
         8.9877e+01, 1.2048e+00, 4.9965e-02, 4.2222e-01, 3.9037e+01, 1.4597e-04]],
       grad_fn=<SoftplusBackward>)
##### event loss: -1.7016558647155762 non event loss:  13158829.264648438 chocie_l: 0.0680813193321228
### event lambdas:  tensor([[2.9828e-07, 3.9188e+01, 1.8058e-05]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[9.6630e-08, 2.7709e+00, 1.0371e-05, 2.0008e+01, 3.3311e+00, 3.4052e+01,
         2.0429e+01, 2.0548e+01, 1.7330e+01, 2.3530e+01, 4.6110e+01, 4.4723e+01,
         3.2887e-02, 1.9635e+01, 1.0562e+01, 1.9933e+01, 1.5570e+01, 1.5161e+01,
         1.2016e-05, 2.0857e-05, 1.7980e-06, 2.4825e+01, 7.1507e+00, 2.4802e-07,
         3.4729e+00, 4.8888e+01, 1.9099e+01, 8.6620e-06, 2.2256e-09, 2.4194e-03]],
       grad_fn=<SoftplusBackward>)
##### event loss: 22.278806686401367 non event loss:  1888497.8426513672 chocie_l: 0.028310570865869522
### event lambdas:  tensor([[2.9169e-05, 1.4351e-08, 1.5393e-04, 6.1113e-06, 2.2459e+01, 2.9021e-09]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[5.7232e+00, 8.3226e-11, 9.7928e-06, 2.3452e-08, 3.6546e-04, 2.2371e-10,
         1.4340e+01, 4.1400e-09, 2.0418e-02, 2.6605e-02, 9.1498e-01, 1.4467e-08,
         1.6114e-01, 2.6566e+00, 2.7609e-06, 3.7195e-08, 6.9316e-08, 1.9301e-08,
         1.5787e+01, 1.0562e+01, 1.4362e-03, 7.3795e-10, 3.3498e-03, 6.9523e-10,
         3.2752e-06, 6.5114e-05, 2.6273e+00, 3.0285e-05, 2.3032e-01, 2.4026e-03,
         5.5115e+00, 8.6001e-02, 1.0247e-05, 1.5377e+01, 5.5559e+01, 4.9605e-10,
         4.6886e-11, 1.5425e-06, 1.0834e-08, 1.6423e-09, 4.7928e+01, 1.1318e+01,
         1.2010e-02, 4.9845e-07, 4.3809e-03, 2.7205e-10, 3.7539e-10, 5.6621e-01,
         2.2497e-09, 8.2401e-06, 1.6793e-10, 2.1882e-08, 2.3888e-09, 2.3745e+01,
         5.8350e+01, 2.2687e-07, 9.1983e-05, 4.4654e-07, 1.5676e+01, 1.8385e+01]],
       grad_fn=<SoftplusBackward>)
##### event loss: 65.83241271972656 non event loss:  1635744.347229004 chocie_l: 0.051310911774635315
### event lambdas:  tensor([[3.3435e-10, 2.0904e-05, 3.6194e-08, 1.7114e-10]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[7.0296e-11, 1.3122e-10, 2.2037e-04, 1.9299e-10, 9.1242e-10, 1.2928e-02,
         6.6085e-10, 5.6972e-08, 5.6215e-08, 3.5645e-05, 3.9944e-08, 4.5080e-01,
         1.9463e-05, 9.5827e-10, 7.1737e-02, 2.4256e-09, 7.7643e-06, 6.5086e-10,
         1.1961e-11, 9.4563e-03, 2.2242e-01, 1.2520e-05, 6.4190e-10, 5.7956e-11,
         3.7670e-09, 5.6112e-09, 3.0457e-05, 7.8491e-09, 5.6218e-09, 1.2023e-08,
         6.0421e-11, 2.0432e-06, 8.3423e-08, 1.8811e-11, 1.0295e-11, 6.0605e-11,
         9.3482e-05, 5.1578e-11, 9.8519e-07, 4.2362e-10]],
       grad_fn=<SoftplusBackward>)
##### event loss: 72.21728515625 non event loss:  1836.4959840774536 chocie_l: 0.028533875942230225
### event lambdas:  tensor([[8.2875e-09, 8.0674e-09, 2.6605e-10, 5.3369e-06, 6.2829e-13, 3.2844e-11,
         2.0410e-11, 3.2659e-06, 3.7580e-10, 3.0652e-09, 4.7444e-09]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[1.7059e-09, 2.3617e-09, 4.8781e-13, 1.7660e-04, 5.4915e-08, 3.8466e-10,
         2.6175e-11, 1.8096e-06, 7.8835e-14, 1.6688e-04, 1.2823e-11, 8.3621e-08,
         1.8075e-04, 4.9100e-11, 1.2652e-10, 4.8398e-12, 3.5896e-14, 1.9794e-08,
         2.6755e-07, 1.1448e-11, 8.2380e-14, 1.8820e-08, 1.6326e-09, 2.8860e-06,
         6.0962e-08, 3.5875e-12, 2.4410e-09, 2.1286e-12, 8.0648e-12, 1.6307e-10,
         1.4856e-10, 7.8944e-09, 5.5682e-11, 4.6933e-06, 1.0409e-07, 1.1665e-11,
         1.8118e-10, 1.6827e-09, 7.8188e-14, 2.3320e-05, 4.9942e-11, 2.8936e-07,
         1.0162e-11, 1.5335e-10, 5.8373e-09, 3.6315e-11, 5.3174e-13, 3.1626e-11,
         6.5328e-12, 1.7327e-10, 1.5196e-04, 1.7964e-14, 1.8453e-10, 2.8423e-08,
         3.8179e-11, 9.7983e-12, 4.0093e-12, 2.6454e-14, 1.1118e-11, 2.8684e-06,
         1.9312e-10, 1.1022e-11, 4.1499e-12, 2.0022e-11, 1.0385e-09, 2.5798e-05,
         2.8483e-11, 8.4030e-10, 4.1264e-08, 3.5820e-11, 1.0307e-10, 4.9831e-08,
         8.9664e-11, 4.3404e-11, 1.5116e-11, 1.5982e-08, 7.5138e-05, 5.9568e-09,
         5.8291e-10, 2.0141e-05, 6.5011e-10, 3.6314e-11, 7.0001e-05, 3.2083e-11,
         3.9853e-09, 2.9972e-10, 1.5956e-09, 3.5178e-12, 8.8202e-11, 1.5350e-09,
         1.0623e-09, 4.8084e-11, 1.4465e-11, 6.1691e-12, 3.3860e-08, 3.3968e-10,
         7.0108e-11, 1.0909e-07, 7.9105e-07, 2.7237e-06, 4.4980e-12, 8.9535e-10,
         2.4659e-10, 8.9450e-07, 8.9878e-10, 1.6035e-12, 3.6676e-06, 9.8781e-12,
         1.8413e-06, 4.5888e-10]], grad_fn=<SoftplusBackward>)
##### event loss: 221.38555908203125 non event loss:  7.190408036403824 chocie_l: 0.18149664998054504
### event lambdas:  tensor([[3.0346e-13, 1.1829e-13, 9.0843e-14, 5.4643e-14, 1.2303e-13]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[1.0511e-15, 3.7623e-14, 4.2511e-14, 1.1230e-13, 2.5083e-16, 2.6004e-13,
         1.2659e-13, 1.3810e-13, 1.8221e-16, 2.8916e-13, 3.1840e-13, 8.3060e-14,
         2.3215e-13, 8.6584e-14, 1.3044e-13, 3.0981e-16, 1.4331e-13, 1.1421e-13,
         1.2429e-13, 2.5148e-13, 1.6699e-13, 1.1422e-13, 1.7233e-16, 7.6223e-16,
         2.4332e-16, 2.2521e-16, 1.2176e-16, 1.4539e-13, 3.5356e-14, 1.6709e-13,
         1.0104e-15, 1.1012e-13, 2.9550e-16, 2.1519e-16, 1.0303e-13, 3.2484e-13,
         1.0039e-13, 2.0571e-16, 8.1326e-14, 1.1031e-13, 2.3389e-16, 7.6010e-12,
         1.3325e-13, 3.5957e-14, 1.0580e-15, 1.8845e-13, 4.9875e-14, 1.9297e-13,
         2.4298e-13, 2.0946e-13]], grad_fn=<SoftplusBackward>)
##### event loss: 148.88314819335938 non event loss:  5.985763942579353e-08 chocie_l: 0.09174410998821259
### event lambdas:  tensor([[2.3936e-15, 2.5298e-17, 6.0325e-18, 1.1820e-17, 6.8758e-18, 6.8063e-21,
         6.3089e-20, 4.9696e-19, 1.6492e-21, 8.1157e-20]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[1.4584e-21, 5.7501e-19, 1.3840e-19, 1.7430e-16, 2.5435e-16, 2.4862e-16,
         1.3496e-16, 1.9583e-17, 2.6322e-16, 1.6471e-19, 1.7888e-21, 2.4664e-21,
         1.3164e-21, 1.2004e-16, 3.0702e-19, 2.3624e-18, 8.6118e-20, 2.0764e-19,
         2.8692e-16, 3.2292e-19, 2.8499e-18, 6.5506e-18, 2.6645e-21, 1.6986e-16,
         4.5787e-17, 6.2494e-18, 9.4628e-19, 1.5984e-17, 3.4025e-19, 1.3019e-21,
         5.6773e-21, 2.7388e-18, 1.3368e-17, 2.0592e-18, 7.9983e-17, 1.1648e-19,
         1.2076e-17, 2.2785e-19, 2.0582e-19, 1.9177e-16, 3.0013e-21, 1.5826e-16,
         1.1341e-17, 1.8419e-19, 8.8250e-20, 1.4486e-16, 6.0609e-16, 6.5720e-18,
         7.7045e-18, 2.4680e-19, 1.1071e-19, 3.7634e-19, 1.3759e-19, 6.8871e-21,
         6.4456e-19, 2.1413e-21, 9.6253e-16, 1.8675e-19, 2.5433e-18, 2.0398e-19,
         1.3135e-19, 1.6545e-16, 1.5210e-15, 4.8894e-20, 3.9592e-19, 2.1191e-20,
         1.0277e-18, 1.8009e-15, 6.6566e-18, 1.4259e-19, 6.0086e-18, 4.6995e-18,
         6.8214e-17, 3.2830e-17, 1.2519e-17, 2.9008e-21, 1.7850e-19, 1.1744e-19,
         3.4405e-17, 1.5168e-16, 3.4544e-19, 4.0670e-20, 1.7876e-17, 2.6497e-16,
         3.6547e-21, 2.1973e-19, 9.7127e-21, 5.2402e-19, 1.2261e-16, 1.7927e-16,
         7.8340e-16, 3.2105e-19, 6.7147e-18, 1.1577e-18, 4.7505e-20, 5.4424e-19,
         9.7650e-18, 2.7394e-16, 2.3179e-21, 7.8558e-18]],
       grad_fn=<SoftplusBackward>)
##### event loss: 414.6302795410156 non event loss:  1.2332137348351486e-11 chocie_l: 0.05591801181435585
### event lambdas:  tensor([[6.8289e-31, 1.0095e-20, 5.0725e-19, 1.3146e-32]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[2.6501e-23, 2.4433e-22, 3.7789e-17, 2.5563e-31, 1.7822e-17, 5.2885e-18,
         6.0383e-20, 3.5417e-26, 1.9935e-18, 2.7989e-27, 5.5342e-24, 3.4234e-16,
         2.9767e-17, 1.6016e-20, 1.6592e-17, 4.4725e-18, 3.6474e-18, 3.5362e-15,
         3.0858e-18, 7.2307e-20, 7.1446e-30, 4.4410e-18, 1.4323e-23, 4.8807e-23,
         2.0397e-20, 1.8240e-16, 2.7262e-23, 1.1171e-17, 3.7257e-31, 5.3305e-19,
         5.5630e-23, 2.6376e-18, 6.7986e-34, 1.4636e-18, 3.1000e-22, 3.2568e-26,
         4.9285e-33, 2.3635e-30, 4.2543e-27, 5.6640e-26]],
       grad_fn=<SoftplusBackward>)
##### event loss: 231.03567504882812 non event loss:  2.925706043171021e-11 chocie_l: 0.08143656700849533
### event lambdas:  tensor([[8.1939e-16, 1.0744e-22, 1.2018e-27, 7.3694e-19, 7.4495e-22]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[1.6844e-21, 1.4116e-17, 6.7047e-21, 1.1278e-19, 3.0716e-19, 1.3262e-22,
         2.1942e-21, 6.0656e-21, 5.1212e-26, 1.0431e-28, 6.6035e-18, 3.0717e-38,
         1.7947e-20, 1.3613e-19, 1.4336e-18, 1.4468e-24, 3.4306e-20, 1.8105e-15,
         2.8718e-17, 1.0138e-14, 1.5980e-37, 6.9997e-19, 7.0158e-21, 1.6544e-18,
         1.3520e-18, 1.3485e-18, 2.1817e-19, 4.7429e-22, 1.2148e-21, 4.6185e-19,
         5.6543e-22, 2.4825e-17, 2.6519e-17, 2.9261e-19, 1.4901e-25, 4.5054e-15,
         1.0481e-16, 2.0595e-26, 1.4873e-18, 7.1236e-24, 6.3000e-20, 7.9453e-21,
         1.6629e-20, 2.7361e-18, 1.5784e-20, 7.0897e-17, 5.9329e-21, 2.3489e-30,
         5.3618e-19, 3.2062e-17]], grad_fn=<SoftplusBackward>)
##### event loss: 237.70957946777344 non event loss:  1.3948774206099304e-10 chocie_l: 0.09784242510795593
### event lambdas:  tensor([[0.0000e+00, 3.9103e-24, 2.0448e-41, 0.0000e+00, 8.9347e-27, 0.0000e+00]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[5.6405e-28, 1.0156e-35, 7.6611e-40, 1.9411e-21, 2.4047e-21, 1.8550e-30,
         2.7898e-24, 1.0802e-40, 8.8771e-30, 1.1175e-37, 1.7946e-39, 4.6259e-31,
         4.4106e-19, 1.0112e-30, 2.4982e-26, 2.3224e-31, 1.4933e-24, 1.4159e-21,
         3.5170e-33, 2.7845e-24, 5.0371e-36, 6.9161e-20, 2.8130e-39, 1.2238e-36,
         6.1440e-26, 1.5020e-35, 5.2158e-25, 3.7437e-34, 4.2199e-25, 0.0000e+00,
         5.0279e-20, 4.1765e-26, 2.4481e-18, 3.0392e-26, 3.5683e-21, 7.6373e-23,
         1.1126e-37, 5.7852e-35, 1.2521e-22, 1.1023e-38, 1.3561e-36, 2.3684e-24,
         6.5272e-23, 9.2004e-20, 2.0682e-24, 4.9119e-25, 2.9205e-32, 0.0000e+00,
         4.3146e-42, 1.4279e-37, 7.2095e-22, 2.8271e-30, 6.9771e-42, 4.8513e-36,
         1.2534e-38, 5.7912e-28, 2.8124e-34, 2.8275e-31, 2.2288e-32, 5.6406e-32]],
       grad_fn=<SoftplusBackward>)
  3%|█████▍                                                                                                                                                                             | 15/496 [00:02<01:22,  5.86it/s]/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/autograd/__init__.py:145: UserWarning: Error detected in SoftplusBackward. Traceback of forward call that caused the error:
  File "main.py", line 156, in <module>
    main()
  File "main.py", line 152, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 107, in train
    loss, pos_timing_loss, neg_timing_loss, choice_l = model(arr_b.float(), arr_c.float(), arr_delta_time.float(), event_data, non_event_data, estimate_length, choice_data_dict)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 183, in forward
    event_lambdas = self.timing_net(mat_b, mat_c, event_data) # (L3, )
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 290, in forward
    lambda_dt = self.f_lambda(rate)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 784, in forward
    return F.softplus(input, self.beta, self.threshold)
 (Triggered internally at  /opt/conda/conda-bld/pytorch_1614378062065/work/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(
  3%|█████▍                                                                                                                                                                             | 15/496 [00:03<01:39,  4.83it/s]
Traceback (most recent call last):
  File "main.py", line 156, in <module>
    main()
  File "main.py", line 152, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 110, in train
    loss.backward() # required_graph = True
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/autograd/__init__.py", line 145, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Function 'SoftplusBackward' returned nan values in its 0th output.