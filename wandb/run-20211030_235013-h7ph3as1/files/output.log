
CUDA availability: True
  0%|                                                                                                                                                       | 0/496 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "main.py", line 126, in <module>
    main()
  File "main.py", line 122, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 81, in train
    loss, timing_loss, choice_l = model(arr_b.float(), arr_c.float(), arr_delta_time.float(), event_data, non_event_data, estimate_length, choice_data_dict)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 183, in forward
    event_lambdas = self.timing_net(mat_b, mat_c, event_data) # (L3, )
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 268, in forward
    lambda_dt = self.exponential_decay(rate)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 94, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/functional.py", line 1753, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x6 and 1x6)
#### arr_b tensor([[[ 2.8086,  0.3831, -0.1159, -0.3501, -0.3501, -0.3501, -0.3501,
          -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501],
         [ 4.6833,  0.7240, -0.2505, -0.3501, -0.3501, -0.3501, -0.3501,
          -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501],
         [ 2.8086,  0.3831, -0.1159, -0.3501, -0.3501, -0.3501, -0.3501,
          -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501],
         [ 4.5977,  0.6357,  0.1072, -0.3501, -0.3501, -0.3501, -0.3501,
          -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501],
         [ 4.4041,  0.5932,  0.1496, -0.3501, -0.3501, -0.3501, -0.3501,
          -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501],
         [ 2.8086,  0.3831, -0.1159, -0.3501, -0.3501, -0.3501, -0.3501,
          -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501],
         [ 2.8086,  0.3831, -0.1159, -0.3501, -0.3501, -0.3501, -0.3501,
          -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501],
         [ 2.8086,  0.3831, -0.1159, -0.3501, -0.3501, -0.3501, -0.3501,
          -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501],
         [ 3.7531,  0.5749,  0.2208, -0.3501, -0.3501, -0.3501, -0.3501,
          -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501],
         [ 2.8086,  0.2479, -0.1159, -0.3501, -0.3501, -0.3501, -0.3501,
          -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501, -0.3501]]]) torch.Size([1, 10, 14])
#### mat_b tensor([[[-2.6873e-01, -1.2544e-01,  1.1984e-01, -1.6836e-01, -3.8944e-01,
          -6.9714e-02,  1.0403e-01, -4.4322e-01, -1.4705e-02, -5.6610e-02,
          -4.5491e-01, -6.5148e-02, -1.3176e-01,  3.7445e-01, -3.4583e-01,
          -1.2790e-01, -3.0769e-01, -3.7165e-02, -9.6052e-02,  3.6260e-01,
           8.8389e-02,  1.9693e-01,  1.3228e-02, -5.7885e-02,  4.2218e-01,
           1.4454e-01,  6.1048e-02,  2.8015e-01, -1.8910e-01, -3.4616e-02,
          -7.1346e-02,  1.6859e-01],
         [-3.7089e-01, -2.0363e-01,  1.6860e-01, -2.9725e-01, -6.0476e-01,
          -4.3428e-02,  1.6115e-01, -6.5612e-01, -1.8018e-02, -4.7671e-02,
          -6.1472e-01, -5.0565e-03, -1.9454e-01,  4.6637e-01, -3.8186e-01,
          -4.1125e-02, -4.1564e-01, -6.3054e-02, -1.6091e-01,  4.0380e-01,
           1.2566e-01,  3.2117e-01,  7.2068e-02,  5.7628e-02,  5.9277e-01,
           2.0205e-01,  2.8562e-02,  4.1647e-01, -2.1316e-01, -6.2971e-02,
          -6.3071e-02,  2.6821e-01],
         [-2.6873e-01, -1.2544e-01,  1.1984e-01, -1.6836e-01, -3.8944e-01,
          -6.9714e-02,  1.0403e-01, -4.4322e-01, -1.4705e-02, -5.6610e-02,
          -4.5491e-01, -6.5148e-02, -1.3176e-01,  3.7445e-01, -3.4583e-01,
          -1.2790e-01, -3.0769e-01, -3.7165e-02, -9.6052e-02,  3.6260e-01,
           8.8389e-02,  1.9693e-01,  1.3228e-02, -5.7885e-02,  4.2218e-01,
           1.4454e-01,  6.1048e-02,  2.8015e-01, -1.8910e-01, -3.4616e-02,
          -7.1346e-02,  1.6859e-01],
         [-3.4192e-01, -1.9759e-01,  1.2102e-01, -3.1850e-01, -5.7589e-01,
          -6.7631e-02,  1.9099e-01, -6.3292e-01,  1.5733e-03, -2.9995e-02,
          -6.1681e-01, -3.3736e-02, -1.9242e-01,  4.4315e-01, -4.1153e-01,
          -3.4721e-02, -3.7901e-01, -6.4042e-02, -1.7240e-01,  3.9193e-01,
           1.2664e-01,  3.5103e-01,  6.6878e-02,  5.3269e-02,  5.8618e-01,
           1.9870e-01,  1.7954e-02,  4.2950e-01, -2.0882e-01, -5.8882e-02,
          -6.8208e-02,  2.5119e-01],
         [-3.2809e-01, -1.9013e-01,  1.1301e-01, -3.0651e-01, -5.5113e-01,
          -7.3120e-02,  1.8958e-01, -6.1033e-01,  3.4399e-03, -2.8597e-02,
          -6.0173e-01, -4.1635e-02, -1.8631e-01,  4.3293e-01, -4.1012e-01,
          -4.3954e-02, -3.6650e-01, -6.1780e-02, -1.6644e-01,  3.8796e-01,
           1.2186e-01,  3.4005e-01,  6.0324e-02,  4.3202e-02,  5.6903e-01,
           1.9383e-01,  2.0170e-02,  4.1828e-01, -2.0593e-01, -5.5451e-02,
          -7.0568e-02,  2.4159e-01],
         [-2.6873e-01, -1.2544e-01,  1.1984e-01, -1.6836e-01, -3.8944e-01,
          -6.9714e-02,  1.0403e-01, -4.4322e-01, -1.4705e-02, -5.6610e-02,
          -4.5491e-01, -6.5148e-02, -1.3176e-01,  3.7445e-01, -3.4583e-01,
          -1.2790e-01, -3.0769e-01, -3.7165e-02, -9.6052e-02,  3.6260e-01,
           8.8389e-02,  1.9693e-01,  1.3228e-02, -5.7885e-02,  4.2218e-01,
           1.4454e-01,  6.1048e-02,  2.8015e-01, -1.8910e-01, -3.4616e-02,
          -7.1346e-02,  1.6859e-01],
         [-2.6873e-01, -1.2544e-01,  1.1984e-01, -1.6836e-01, -3.8944e-01,
          -6.9714e-02,  1.0403e-01, -4.4322e-01, -1.4705e-02, -5.6610e-02,
          -4.5491e-01, -6.5148e-02, -1.3176e-01,  3.7445e-01, -3.4583e-01,
          -1.2790e-01, -3.0769e-01, -3.7165e-02, -9.6052e-02,  3.6260e-01,
           8.8389e-02,  1.9693e-01,  1.3228e-02, -5.7885e-02,  4.2218e-01,
           1.4454e-01,  6.1048e-02,  2.8015e-01, -1.8910e-01, -3.4616e-02,
          -7.1346e-02,  1.6859e-01],
         [-2.6873e-01, -1.2544e-01,  1.1984e-01, -1.6836e-01, -3.8944e-01,
          -6.9714e-02,  1.0403e-01, -4.4322e-01, -1.4705e-02, -5.6610e-02,
          -4.5491e-01, -6.5148e-02, -1.3176e-01,  3.7445e-01, -3.4583e-01,
          -1.2790e-01, -3.0769e-01, -3.7165e-02, -9.6052e-02,  3.6260e-01,
           8.8389e-02,  1.9693e-01,  1.3228e-02, -5.7885e-02,  4.2218e-01,
           1.4454e-01,  6.1048e-02,  2.8015e-01, -1.8910e-01, -3.4616e-02,
          -7.1346e-02,  1.6859e-01],
         [-2.9778e-01, -1.6072e-01,  8.2547e-02, -2.6966e-01, -4.8296e-01,
          -8.3457e-02,  1.5278e-01, -5.2732e-01,  5.4691e-03, -3.1361e-02,
          -5.4803e-01, -7.1438e-02, -1.6412e-01,  4.0404e-01, -3.9379e-01,
          -6.9974e-02, -3.3147e-01, -6.0379e-02, -1.4895e-01,  3.6283e-01,
           1.1485e-01,  2.8481e-01,  4.4563e-02,  2.6462e-04,  5.1233e-01,
           1.7393e-01,  3.8517e-02,  3.6636e-01, -2.0323e-01, -5.0695e-02,
          -6.1833e-02,  2.1403e-01],
         [-2.5659e-01, -1.2453e-01,  1.3660e-01, -1.6629e-01, -3.7630e-01,
          -7.0587e-02,  1.2742e-01, -4.5297e-01, -1.6884e-02, -5.7298e-02,
          -4.5445e-01, -5.6961e-02, -1.3151e-01,  3.7274e-01, -3.5099e-01,
          -1.3053e-01, -3.0344e-01, -2.6500e-02, -9.3572e-02,  3.7399e-01,
           7.4733e-02,  2.1605e-01,  3.3987e-03, -5.0722e-02,  4.2002e-01,
           1.4257e-01,  5.4563e-02,  2.8562e-01, -1.8115e-01, -2.7793e-02,
          -8.7187e-02,  1.6837e-01]]], grad_fn=<AddBackward0>) torch.Size([1, 10, 32])