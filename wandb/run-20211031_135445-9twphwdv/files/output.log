
CUDA availability: True
  1%|█▎                                                                                                                                                                                                               | 3/496 [00:00<01:30,  5.42it/s]
Traceback (most recent call last):
  File "main.py", line 126, in <module>
    main()
  File "main.py", line 122, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 81, in train
    loss, timing_loss, choice_l = model(arr_b.float(), arr_c.float(), arr_delta_time.float(), event_data, non_event_data, estimate_length, choice_data_dict)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 198, in forward
    choice_l = self.choice_net(mat_b, mat_c, choice_data_dict, self.s_year, self.e_year)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 345, in forward
    z_vt_i = self.gnn_choice(features_i.squeeze(), edges_i.squeeze()) # (N_i_1, embedding_z)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 450, in forward
    x = F.dropout(x, p=self.dropout)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/functional.py", line 1076, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/_VF.py", line 25, in __getattr__
    def __getattr__(self, attr):
KeyboardInterrupt
### event lambdas:  tensor([[2.3414e+01],
        [2.1920e+02],
        [4.0852e+01],
        [1.1515e-01],
        [3.3629e+01],
        [4.0531e+01]], grad_fn=<AddBackward0>)
##### event loss: tensor(-17.3092, grad_fn=<NegBackward>) non event loss:  tensor([363400.2987], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(42452.9922, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[ 29.6604],
        [  0.4034],
        [265.4069],
        [ 39.2379],
        [ 67.2115]], grad_fn=<AddBackward0>)
##### event loss: tensor(-15.9409, grad_fn=<NegBackward>) non event loss:  tensor([438373.8679], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(16503.0039, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[1.5245e+02],
        [5.3520e-07],
        [6.5664e+00],
        [2.1849e+02],
        [5.3676e-04],
        [3.2049e-09]], grad_fn=<AddBackward0>)
##### event loss: tensor(29.2336, grad_fn=<NegBackward>) non event loss:  tensor([393507.8066], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(2543.2119, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[1.3295e-07],
        [6.0665e+01],
        [8.2984e+00],
        [2.0748e+01],
        [3.9328e-09],
        [2.1379e-10],
        [4.2481e-05],
        [1.1093e+02],
        [1.8042e-04]], grad_fn=<AddBackward0>)