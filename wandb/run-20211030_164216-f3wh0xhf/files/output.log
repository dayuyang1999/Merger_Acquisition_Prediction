
CUDA availability: True
### b: tensor([[[ -30934.9199,   -9593.9707,   20702.5254,  -34395.5234,   -5596.7485,
             7348.2476,     591.5319,    6043.6382,   25411.6484,   19709.4766,
           -28937.4395,   22772.7656,   -8454.3994,  -33547.3281,   -6848.1387,
            36824.3555,   10388.5410,   22201.1094,   32825.4531,    5086.7119,
            16520.0117,   -5957.7305,   -9199.3398,    8617.1328,   -3378.9790,
             2659.3323,  -41499.9492,    3891.2393,   23306.0801,  -20052.7383,
            19406.8418,    3300.5007],
         [ -28967.9590,   10065.1729,   24213.7227,  -78891.3281,  -36288.2812,
            33057.4453,  -18336.1289,   -1494.9640,   13703.2559,   29678.7285,
           -36776.7578,   33802.1211,   21915.8809,  -38003.5781,  -38065.3281,
            35236.8516,   11277.6396,    9555.5469,   68978.8203,  -34631.2266,
             6948.6411,  -12245.6582,    6746.8262,   16402.6992,   -2982.5046,
            51086.6875,  -25614.8086,   20654.0645,   15533.1992,  -51810.3359,
            21708.8848,    4697.6118],
         [ -16397.2090,  -22157.1816,    1300.6787,  -65138.2656,   -3363.3855,
            44459.7734,  -28543.1367,   35781.9648,   52058.7891,   54553.3242,
           -32600.8574,   61411.9922,   77606.6172,  -68645.3750,   -9771.8008,
            80822.0781,  -48144.4141,   -2405.5891,   76095.9062,   -8799.0869,
            16249.9531,  -28271.5449,  -24335.7793,  -14166.7188,   26893.5488,
            56111.5508,  -57202.0625,   -8745.0859,   47958.1406,  -38965.3945,
           -10793.1553,   19888.2695],
         [  -4052.6917,  -28239.3867,   -4261.6953,  -25978.3086,  -30791.9453,
            55472.8164,   -1778.3916,   60275.5039,   42655.3750,   23466.1211,
           -28558.8086,   16625.9883,   25238.3984,  -55088.8828,  -29635.9141,
            42579.6602,  -29297.9023,    -392.7602,   36239.8672,    4494.8223,
            39747.1719,  -32050.3242,  -17739.9375,  -24668.2168,   39102.8164,
            46424.8320,   -3342.4797,   -2898.4626,   21890.9863,  -13983.1621,
             6068.7080,  -29608.4902],
         [ -32375.9746,   15771.1904,    1470.6890,  -34818.7969,  -22321.6836,
            24958.6465,    1281.0664,   37309.0586,   49032.5000,   68513.8828,
           -23423.5957,    9447.6455,   23403.2012,   -8615.0596,    4661.2617,
             6458.9678,  -50030.0625,  -31194.6328,   59073.3750,   16339.8740,
           -24067.1992,   -8618.3525,    4106.0200,   -8183.6484,   36963.3828,
            39741.2461,    5029.2295,   42266.5391,   23251.3750,  -11907.3145,
             8005.7026,   17032.7383],
         [ -32375.9746,   15771.1904,    1470.6890,  -34818.7969,  -22321.6836,
            24958.6465,    1281.0664,   37309.0586,   49032.5000,   68513.8828,
           -23423.5957,    9447.6455,   23403.2012,   -8615.0596,    4661.2617,
             6458.9678,  -50030.0625,  -31194.6328,   59073.3750,   16339.8740,
           -24067.1992,   -8618.3525,    4106.0200,   -8183.6484,   36963.3828,
            39741.2461,    5029.2295,   42266.5391,   23251.3750,  -11907.3145,
             8005.7026,   17032.7383],
         [ -57179.3789,  -68729.4453,    3226.9270,  -58586.4883,  -59868.3906,
            18448.2090,   51336.8828,   35615.9219,   -7655.9741,   42253.3164,
             2796.4380,  -28158.1582,  -24165.1738,  -27254.9395,  -37112.9453,
             2225.8298,  -25006.3262,  -36557.7578,   46249.4336,    7693.2935,
           -40130.8438,   -7278.6665,  -29929.1016,   14679.9941,   12332.3867,
             6567.9297,  -31152.8359,    8064.6787,  -31578.7637,   24836.3086,
            43774.9336,   12996.2891],
         [  -2898.0911,  -30540.4434,    1521.9465,  -37233.8555,  -20833.7012,
            67056.3359,   -9716.5508,   40656.9648,   44842.8945,   31546.8848,
           -65001.4180,   59694.1875,   93894.5625,  -83033.1719,  -27171.7402,
            56771.0195, -105481.7344,   13081.5469,   73814.4922,  -59495.3203,
            -3688.6189,  -48749.6953,  -39550.3203,  -67504.5000,   38900.7500,
            97725.7422,  -18495.2637,  -16392.1074,  -13296.1621,  -49931.7695,
            -3399.9934,   22184.1465],
         [  -2898.0911,  -30540.4434,    1521.9465,  -37233.8555,  -20833.7012,
            67056.3359,   -9716.5508,   40656.9648,   44842.8945,   31546.8848,
           -65001.4180,   59694.1875,   93894.5625,  -83033.1719,  -27171.7402,
            56771.0195, -105481.7344,   13081.5469,   73814.4922,  -59495.3203,
            -3688.6189,  -48749.6953,  -39550.3203,  -67504.5000,   38900.7500,
            97725.7422,  -18495.2637,  -16392.1074,  -13296.1621,  -49931.7695,
            -3399.9934,   22184.1465]]], grad_fn=<IndexSelectBackward>)
### rate: tensor([[-232938.3438,  -53301.0117, -277192.3438, -186996.2656,  167739.1875,
          167740.1250,  -97079.9062,   -5145.4644,   -5146.6172]],
       grad_fn=<AddBackward0>)
### b: tensor([[[ -4052.6917, -28239.3867,  -4261.6953,  ..., -13983.1621,
            6068.7080, -29608.4902],
         [-23292.9766,  -8273.8203,  16730.1113,  ..., -37338.8711,
              66.4124,  19302.4297],
         [-13261.7168, -23812.0996,  -7179.9414,  ...,   3962.3682,
           11793.6699,  -1112.6411],
         ...,
         [-28967.9590,  10065.1729,  24213.7227,  ..., -51810.3359,
           21708.8848,   4697.6118],
         [-24422.8945,   1529.6224,  40522.6914,  ..., -23954.2461,
           27958.6797,  32477.8457],
         [-31687.4531, -26670.2969,  29847.8418,  ..., -25101.9512,
           39731.7461,   3888.4832]]], grad_fn=<IndexSelectBackward>)
### rate: tensor([[-186991.0781,  -57040.2695,    1832.6331,    1827.3730,   24744.1465,
          -97080.4688,  -53293.2305, -195955.1250, -105822.2891,   -5154.1167,
          -53286.1953,  -57070.3320,  -53291.3828, -277194.3125, -105817.4375,
         -422934.0312,  -97081.3438, -186993.4375, -149244.1250, -287559.3125,
          167741.0625, -422932.8438, -186994.1406, -139050.6250,   24743.8809,
         -139049.4844,  -53286.3125,   24744.2949,   24744.5820,  167739.6562,
         -195955.8438, -186992.9844,   24745.9062,   24744.9277, -433165.8750,
          -57043.7539,   24743.5391,  167736.9531, -149246.6562, -105812.9297,
           49199.9648,  167732.8125,  167737.2500,   -5153.1392, -186990.4062,
          167734.8438,   24742.4609, -277187.6875,  167737.0938,   24747.4141,
         -277192.1250, -195963.4375,  -47729.5273,   -5151.3652,  -23643.7168,
         -433148.0938,  -97082.9844,  -47730.6055, -287553.5000,  -57041.9531,
          -23641.6426,  -47736.5742,   24745.6836, -232945.7344, -277193.8125,
         -433176.2188, -232941.1719, -232940.8594,  -57073.5078,   49199.5078,
         -277204.0938, -277199.0312,   24746.8340,   24747.0000, -232940.0781,
         -232938.8438, -186992.5469,  -53292.0430,   -5150.1631, -433173.5625,
         -105814.8359, -105823.5469,  -47729.6367,    1829.6737, -422935.1875,
          167738.1250, -277204.3125,  -53284.2852,   24745.8281, -139052.0312]],
       grad_fn=<AddBackward0>)
### event lambdas:  tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0.]], grad_fn=<SigmoidBackward>)
### non event lambdas:  tensor([[0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
         1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.]],
       grad_fn=<SigmoidBackward>)
Traceback (most recent call last):
  File "main.py", line 89, in <module>
    main()
  File "main.py", line 85, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 48, in train
    loss, timing_loss, choice_loss  = model(arr_b.float(), arr_c.float(), arr_delta_time.float(), event_data, non_event_data, estimate_length, choice_data_dict)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 195, in forward
    event_choice_loss = self.choice_net(mat_b, mat_c, choice_data_dict, self.s_year, self.e_year)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 324, in forward
    arr_b_idx_i = torch.stack(arr_b_idx_i).squeeze()
TypeError: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor