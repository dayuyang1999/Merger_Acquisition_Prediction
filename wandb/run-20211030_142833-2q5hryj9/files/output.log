CUDA availability: True
tensor([0.4362], requires_grad=True)
tensor([[  53083.8789, -127806.6562, -127806.6562,  -12544.8838]],
       grad_fn=<ViewBackward>)
tensor([[-0.4006,  0.6719,  1.2734, -0.9307]], grad_fn=<ViewBackward>)
tensor([[0.0133, 0.0023, 0.2820, 0.0006]], dtype=torch.float64,
       grad_fn=<MulBackward0>)
tensor([[  53083.4899, -127805.9821, -127805.1008,  -12545.8138]],
       dtype=torch.float64, grad_fn=<AddBackward0>)
tensor([0.4362], requires_grad=True)
tensor([[-237973.7812,  -95749.9375,  -68421.6875, -127806.6562, -293899.7812,
         -168671.3594, -293899.7812, -168671.3594, -274835.0000,   53083.8711,
          -99121.4844, -149882.9688, -293899.7812,  -95749.9375,   53083.8711,
           53083.8711, -293899.7812,  -99121.4844,  -68421.6875,  -10136.9766,
         -168671.3594, -237973.7812, -168671.3594,  -12544.8633,  145172.4219,
           53083.8711, -243642.6719,  -99121.4844,  -12544.8633,   -1963.2500,
         -237973.7812, -168671.3594, -168671.3594,   53083.8711, -243642.6719,
           53083.8711, -149882.9688,   14767.9746,   -1963.2500,   14667.8438]],
       grad_fn=<ViewBackward>)
tensor([[-0.3162, -1.2591, -0.9307,  0.5474,  0.6832, -0.0300, -0.3471, -0.0300,
         -0.8632, -1.2591,  0.3825,  0.4996,  0.6832, -1.2591, -1.2591, -1.2591,
         -0.3471,  0.3825, -0.9307,  1.1321, -0.0300, -0.3162, -0.0300, -0.9307,
         -0.1314,  0.2808, -0.9307, -0.8632,  0.9519,  0.6832, -0.3162, -0.0300,
         -0.0300, -1.2591, -0.9307, -1.2591,  0.4996, -0.5615,  0.6832, -0.5615]],
       grad_fn=<ViewBackward>)
tensor([[ 2.6902e-54,  1.2522e-78, 1.2496e-123,  4.1693e-17,  3.3558e-23,
          6.0274e-26,  8.0640e-25,  2.3139e-21,  1.3775e-59,  1.2748e-23,
          8.3993e-09,  2.8249e-13,  1.3835e-25,  1.1059e-44,  2.0620e-22,
          9.9918e-34,  7.5762e-21,  9.1352e-15, 2.0682e-146,  2.0343e-10,
          4.2871e-62,  5.4738e-38,  3.6109e-72, 6.9034e-194,  2.1728e-74,
          2.0901e-13,  1.3330e-24,  1.7931e-10,  1.3134e-02,  4.5195e-09,
          1.5680e-52,  1.8851e-32,  1.0855e-24,  4.5346e-28,  8.6288e-49,
          3.8929e-29,  7.0725e-05,  9.7344e-74,  4.2081e-03,  4.6447e-27]],
       dtype=torch.float64, grad_fn=<MulBackward0>)
tensor([[-237974.0938,  -95751.1953,  -68422.6172, -127806.1094, -293899.0938,
         -168671.3906, -293900.1250, -168671.3906, -274835.8750,   53082.6133,
          -99121.1016, -149882.4688, -293899.0938,  -95751.1953,   53082.6133,
           53082.6133, -293900.1250,  -99121.1016,  -68422.6172,  -10135.8447,
         -168671.3906, -237974.0938, -168671.3906,  -12545.7939,  145172.2969,
           53084.1523, -243643.6094,  -99122.3437,  -12543.8980,   -1962.5668,
         -237974.0938, -168671.3906, -168671.3906,   53082.6133, -243643.6094,
           53082.6133, -149882.4687,   14767.4131,   -1962.5626,   14667.2822]],
       dtype=torch.float64, grad_fn=<AddBackward0>)
/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
Traceback (most recent call last):
  File "main.py", line 88, in <module>
    main()
  File "main.py", line 84, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 54, in train
    choice_loss_e += choice_loss.detach().numpy()[0]
IndexError: too many indices for array: array is 0-dimensional, but 1 were indexed