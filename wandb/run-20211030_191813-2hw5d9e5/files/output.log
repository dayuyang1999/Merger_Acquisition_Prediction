
CUDA availability: True
Traceback (most recent call last):
  File "main.py", line 89, in <module>
    main()
  File "main.py", line 85, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 48, in train
    loss, timing_loss, choice_loss  = model(arr_b.float(), arr_c.float(), arr_delta_time.float(), event_data, non_event_data, estimate_length, choice_data_dict)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 195, in forward
    event_choice_loss = self.choice_net(mat_b, mat_c, choice_data_dict, self.s_year, self.e_year)*1000
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 327, in forward
    arr_b_idx_i = torch.stack(arr_b_idx_i).squeeze()
TypeError: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor
#### arr_b: tensor([[[ 1.6416,  0.2271, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 1.8722,  0.3001, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.2511,  0.3824, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.6105,  0.4627, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.8426,  0.5884, -0.2861, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2659,  0.5711, -0.2796, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.8512,  0.6076, -0.2809, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 4.3783,  0.6288, -0.2535, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.4571,  0.8924, -0.2310, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.3584,  0.7907,  0.1813, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.1351,  0.7417,  0.2302, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 4.3846,  0.7205,  0.3123, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3435, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4078, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3785, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3619, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 1.5889,  0.3488, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459]]])
### b: tensor([[[-1.8181e-01,  1.6826e-01, -6.7256e-02,  3.9211e-01, -2.6751e-02,
          -1.2397e-01, -1.6589e-02, -1.0481e-01,  3.6542e-02,  1.6718e-01,
          -5.3983e-02, -3.4611e-01, -6.9934e-02,  2.5562e-02, -3.2079e-02,
           1.3357e-01, -4.2918e-01,  1.8572e-01, -1.8896e-01,  3.1289e-02,
          -4.5794e-02,  2.3397e-01,  1.1118e-01, -1.7900e-01, -5.2127e-02,
          -2.2425e-01, -2.9772e-03, -2.0450e-01, -1.5097e-01,  5.2607e-02,
          -1.3081e-01, -3.9372e-02],
         [-6.4397e-01,  1.2694e-01, -2.9656e-01,  2.0661e-02, -1.2839e-01,
           7.6020e-02, -9.8429e-02, -2.1658e-01, -1.1716e-01, -2.0079e-01,
          -2.1285e-01, -4.9350e-02, -1.5974e-01,  2.8020e-01, -1.7979e-01,
           1.0150e-01, -5.7914e-01,  3.7576e-01, -1.1715e-01,  3.6972e-02,
           4.8225e-02, -9.1898e-02, -1.0703e-01, -5.8680e-01,  3.4091e-01,
          -3.2219e-01,  1.7347e-01, -2.3015e-01,  2.1957e-01, -3.4361e-01,
          -1.4437e-02, -1.2055e-01],
         [-2.8583e-01,  3.6067e-01, -1.1466e-01,  3.3584e-01, -4.4778e-02,
           8.1535e-02, -5.8942e-03, -1.3297e-01,  1.4972e-01, -1.5451e-01,
           1.5281e-01, -5.3244e-01, -1.0185e-01,  9.3043e-02, -2.2960e-01,
           4.4272e-02, -6.5965e-01,  4.7162e-01, -4.8792e-02,  2.0061e-01,
           2.3110e-01,  3.9890e-02, -9.6559e-02, -2.7146e-01, -1.6874e-01,
          -3.5605e-01,  1.2210e-01, -1.4947e-02,  1.2512e-02, -2.5020e-01,
           1.3953e-01, -2.7348e-02],
         [-3.9031e-01,  8.7248e-02, -3.3175e-01,  6.2683e-01,  1.2509e-01,
          -8.5234e-04, -9.5675e-02, -2.1161e-01,  7.6481e-03, -4.1050e-01,
           1.5211e-01, -4.8230e-01, -1.7968e-01,  1.0980e-01, -3.4356e-01,
           1.1661e-01, -1.0491e+00,  5.6430e-01, -6.1304e-01,  3.9825e-02,
           4.4293e-01,  5.2765e-02, -3.7418e-03, -8.6821e-01, -4.3247e-02,
          -6.7513e-01,  2.0533e-01, -1.5790e-01,  1.1939e-01, -2.4860e-01,
           3.1592e-01, -4.2884e-01]]], grad_fn=<IndexSelectBackward>)
### b: tensor([[[-0.3075,  0.0434, -0.2774,  ..., -0.0989, -0.1804, -0.1120],
         [-0.1670,  0.2751, -0.2584,  ...,  0.2531, -0.0182, -0.3821],
         [-0.3075,  0.0434, -0.2774,  ..., -0.0989, -0.1804, -0.1120],
         ...,
         [-0.2595,  0.4811, -0.0837,  ...,  0.0395,  0.1307, -0.1508],
         [-0.2696,  0.2137, -0.0032,  ..., -0.0182,  0.2925, -0.0503],
         [-0.4227,  0.2100, -0.2999,  ..., -0.4013, -0.1168, -0.0629]]],
       grad_fn=<IndexSelectBackward>)