
CUDA availability: True
### event lambdas:  tensor([[0.0772, 0.0281, 0.0767, 0.0871, 0.0598, 0.1464, 0.0476]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(18.9233, grad_fn=<NegBackward>) non event loss:  tensor([46299.9584], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(3.6747, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[0.0048, 0.0094, 0.0143, 0.0135, 0.0106]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(23.1108, grad_fn=<NegBackward>) non event loss:  tensor([1595.7724], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(2.2088, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[0.0038, 0.0050, 0.0007, 0.0009, 0.0004, 0.0008, 0.0006]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(47.5257, grad_fn=<NegBackward>) non event loss:  tensor([413.9838], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(1.1038, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[9.5733e-05, 4.1367e-05, 7.9933e-05, 3.8725e-05, 2.6451e-05, 3.6123e-05,
         1.0297e-05, 1.6969e-05, 2.8881e-04]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(90.3266, grad_fn=<NegBackward>) non event loss:  tensor([103.6686], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.2093, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.1015e-04, 2.3348e-04, 4.4970e-05, 1.6105e-04, 7.4645e-05]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(45.7222, grad_fn=<NegBackward>) non event loss:  tensor([23.1394], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0117, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.5762e-05, 3.5017e-05, 1.6012e-05]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(31.8684, grad_fn=<NegBackward>) non event loss:  tensor([0.7293], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0016, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.5887e-06, 6.8189e-08, 5.8711e-07, 5.3124e-07]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(58.1614, grad_fn=<NegBackward>) non event loss:  tensor([0.1133], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0218, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[5.6253e-07, 4.7215e-07, 2.7211e-07, 8.0557e-08, 2.4529e-07, 1.3306e-07]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(91.4615, grad_fn=<NegBackward>) non event loss:  tensor([0.1542], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0428, grad_fn=<SumBackward0>)
  1%|█▋                                                                                                                                              | 6/496 [00:00<00:51,  9.55it/s]
### event lambdas:  tensor([[3.1938e-06, 4.3180e-06, 2.1181e-07, 1.2844e-08, 5.4395e-08, 1.0918e-06,
         2.0885e-06, 2.9485e-08]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(119.4182, grad_fn=<NegBackward>) non event loss:  tensor([0.0568], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0331, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.6942e-07, 1.5017e-07, 3.4351e-09, 8.2196e-09, 2.3957e-08, 2.6760e-09]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(106.2304, grad_fn=<NegBackward>) non event loss:  tensor([0.0158], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0568, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[5.4842e-08, 1.5896e-08, 9.0575e-08, 4.0255e-09, 5.0046e-08]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(87.0340, grad_fn=<NegBackward>) non event loss:  tensor([0.0135], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0803, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.4075e-07, 5.1565e-07, 1.2214e-07, 4.5110e-07, 2.4944e-09, 9.5525e-10]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(101.3621, grad_fn=<NegBackward>) non event loss:  tensor([0.0061], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0485, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[3.4910e-08, 2.8479e-08, 4.1412e-08, 4.2411e-08, 1.1167e-08]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(86.8305, grad_fn=<NegBackward>) non event loss:  tensor([0.0058], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0673, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.0907e-08, 3.3666e-10, 4.1729e-09, 1.1590e-09, 4.4789e-09, 1.1851e-09]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(119.1428, grad_fn=<NegBackward>) non event loss:  tensor([0.0012], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1161, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.8302e-08, 6.7565e-09, 3.3030e-09, 4.7918e-09, 1.5378e-09, 1.2607e-09,
         3.0138e-10, 2.5834e-10, 9.0693e-10, 3.5772e-09, 3.9632e-09, 3.2117e-09,
         7.8394e-10, 1.0547e-09, 6.5828e-09, 3.2377e-09, 1.5262e-08, 9.5828e-09,
         5.1510e-10, 7.9622e-10, 3.9919e-09, 1.5275e-09, 3.9350e-09, 2.8953e-10,
         3.4424e-09, 1.4246e-09, 3.5245e-08, 2.7551e-10, 4.9481e-09, 7.9345e-09,
         1.6800e-08, 8.3916e-10, 2.6242e-09, 1.0284e-08, 1.9224e-10, 1.3260e-08,
         1.4988e-08, 3.8308e-08, 2.3640e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(763.2319, grad_fn=<NegBackward>) non event loss:  tensor([0.0054], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.2770, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.1425e-08, 3.1618e-08, 9.1602e-10, 9.7904e-10, 1.5412e-09]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(97.4031, grad_fn=<NegBackward>) non event loss:  tensor([0.0003], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0656, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.5364e-08, 4.0462e-09, 3.6372e-09, 1.1793e-09]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(77.3071, grad_fn=<NegBackward>) non event loss:  tensor([2.4503e-05], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0311, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.0147e-08, 2.4607e-09, 1.6829e-10, 2.1358e-09, 1.8205e-09]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(100.1370, grad_fn=<NegBackward>) non event loss:  tensor([0.0006], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0986, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.1796e-09, 7.7165e-09, 6.2667e-09, 4.2660e-10]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(79.0872, grad_fn=<NegBackward>) non event loss:  tensor([0.0011], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0808, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[4.7982e-08, 1.6074e-08, 3.1166e-09, 4.9209e-09, 8.3530e-10]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(94.4181, grad_fn=<NegBackward>) non event loss:  tensor([0.0006], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0653, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.0405e-08, 1.4518e-08, 2.9895e-09, 8.3400e-10, 4.8381e-10]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(97.7377, grad_fn=<NegBackward>) non event loss:  tensor([0.0010], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0704, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.7992e-09, 1.3919e-09, 1.2878e-09]], grad_fn=<SoftplusBackward>)

  4%|██████                                                                                                                                         | 21/496 [00:02<00:55,  8.57it/s]
### event lambdas:  tensor([[1.5585e-08, 2.5856e-09, 7.8878e-11, 2.4984e-11, 6.4211e-11, 5.2114e-09,
         1.0500e-09, 3.9624e-11, 2.2952e-11, 2.6339e-11, 1.1802e-11]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(246.6138, grad_fn=<NegBackward>) non event loss:  tensor([0.0005], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1330, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.2474e-07, 6.9744e-10, 3.7594e-09, 1.3751e-10, 9.7599e-11, 2.5584e-10,
         4.2158e-11]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(147.5245, grad_fn=<NegBackward>) non event loss:  tensor([0.0007], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1194, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.8023e-09, 3.0030e-09, 4.4338e-10, 8.2981e-12, 9.3674e-11]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(109.9006, grad_fn=<NegBackward>) non event loss:  tensor([0.0001], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0756, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[7.7719e-10, 7.9142e-10, 5.5117e-09, 9.4008e-11, 2.7051e-11, 7.3440e-11,
         1.0844e-10, 1.7382e-12, 8.2170e-12, 7.7185e-12, 3.8668e-11]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(256.8156, grad_fn=<NegBackward>) non event loss:  tensor([0.0002], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1163, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.7008e-07, 5.7963e-09, 1.6916e-09, 1.0840e-09, 1.8642e-10, 1.0776e-11,
         1.9538e-10, 1.0201e-11]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(170.7147, grad_fn=<NegBackward>) non event loss:  tensor([0.0002], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1350, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.2085e-08, 4.1561e-09, 4.1869e-09, 2.1598e-09, 3.1560e-10, 4.7840e-10,
         8.8451e-11, 4.1406e-11, 3.6249e-11, 5.4225e-11, 1.6833e-10, 2.9797e-10]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(258.6825, grad_fn=<NegBackward>) non event loss:  tensor([0.0010], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1594, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.4097e-09, 4.5754e-10, 1.6451e-10, 5.7620e-11, 3.8129e-11, 7.4217e-12,
         9.3462e-11, 5.8395e-12, 4.6854e-11, 1.3693e-10]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(232.5262, grad_fn=<NegBackward>) non event loss:  tensor([0.0003], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1708, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.5893e-08, 6.2845e-10, 8.4452e-12, 3.0456e-11, 1.0760e-12]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(116.4151, grad_fn=<NegBackward>) non event loss:  tensor([0.0014], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0672, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[5.6056e-09, 7.9388e-09, 4.0968e-09, 5.2754e-09, 5.4326e-09, 1.5323e-09,
         1.3236e-09, 8.2006e-11, 8.5124e-10, 1.0283e-10, 1.1068e-10, 2.2417e-11,
         1.2346e-09, 1.0160e-10, 4.9855e-12]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(319.8936, grad_fn=<NegBackward>) non event loss:  tensor([0.0005], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0599, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[3.8704e-08, 9.7029e-09, 1.4605e-09, 1.4154e-10, 3.1639e-10, 3.2521e-12,
         6.7065e-12]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(152.5948, grad_fn=<NegBackward>) non event loss:  tensor([6.7408e-05], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0786, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[5.9926e-09, 2.3022e-10, 1.5997e-10, 7.0028e-11]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(87.0629, grad_fn=<NegBackward>) non event loss:  tensor([0.0002], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0681, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.2895e-09, 2.5857e-09, 1.0881e-09, 2.9599e-11, 1.4835e-10, 5.2450e-11,
         2.2309e-12, 5.8783e-12, 2.1834e-11]], grad_fn=<SoftplusBackward>)

  6%|█████████▏                                                                                                                                     | 32/496 [00:04<01:19,  5.83it/s]
### event lambdas:  tensor([[9.9053e-11, 1.6816e-10, 5.3958e-10, 2.7192e-10, 1.4318e-09, 1.4465e-10,
         4.5206e-11, 1.6022e-10, 2.3236e-11, 3.8888e-11, 1.4007e-11, 2.6275e-10,
         2.2599e-10]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(296.0201, grad_fn=<NegBackward>) non event loss:  tensor([0.0001], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1696, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[6.0341e-08, 5.6616e-09, 9.1826e-10, 6.5246e-10, 9.6280e-11, 3.3160e-10]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(122.4625, grad_fn=<NegBackward>) non event loss:  tensor([9.9647e-05], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0986, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.4629e-08, 1.2227e-08, 2.9664e-11, 2.1358e-11, 1.0710e-10]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(108.0278, grad_fn=<NegBackward>) non event loss:  tensor([0.0006], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0812, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[3.5616e-08, 1.1620e-08, 5.5406e-10, 5.8783e-11, 4.3720e-10, 3.4115e-10,
         3.1720e-10, 1.2586e-11, 6.9309e-11, 1.1974e-12, 8.1629e-13, 1.0420e-11,
         1.0357e-11, 4.9718e-12, 5.3150e-12]], grad_fn=<SoftplusBackward>)
  7%|██████████▋                                                                                                                                    | 37/496 [00:05<01:11,  6.38it/s]
Traceback (most recent call last):
  File "main.py", line 156, in <module>
    main()
  File "main.py", line 152, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 110, in train
    loss.backward() # required_graph = True
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/autograd/__init__.py", line 145, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt