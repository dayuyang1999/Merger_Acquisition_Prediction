
CUDA availability: True
### event lambdas:  tensor([[3.2933, 2.0051, 2.2832, 2.6942, 2.8067]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[2.7859, 3.4214, 2.6092, 3.8057, 2.7947, 3.4246, 2.9661, 2.8835, 3.0772,
         3.5380, 2.2003, 2.6747, 3.7069, 3.4824, 2.5310, 3.2494, 2.9264, 2.4354,
         2.5072, 3.0827, 3.5208, 1.8682, 2.7143, 3.8221, 3.3844, 3.1656, 2.8579,
         2.2217, 2.6485, 2.4998, 2.2448, 2.4904, 2.9024, 3.0137, 2.2623, 3.0538,
         2.8413, 2.8705, 2.9001, 3.3413, 2.8208, 2.6588, 3.3374, 3.3211, 2.9977,
         2.7495, 3.2951, 2.7019, 3.7376, 2.0725]], grad_fn=<SoftplusBackward>)
##### event loss: -4.736269950866699 non event loss:  319779.509765625 chocie_l: 3.5595626831054688
### event lambdas:  tensor([[0.5220, 1.3891, 0.9360, 0.9999, 0.6309, 0.4047, 0.3888]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[0.5418, 0.8150, 0.9328, 0.6622, 0.9707, 1.1501, 0.6850, 1.2104, 0.9132,
         0.8360, 0.2884, 1.0213, 0.7709, 0.9192, 0.4261, 1.1734, 0.6803, 1.0937,
         1.2164, 1.0409, 1.2551, 1.1364, 0.6345, 0.7535, 1.5298, 0.7524, 0.5795,
         1.1067, 0.5137, 0.7389, 0.5005, 0.4701, 1.1254, 0.6728, 0.5676, 0.5209,
         0.9372, 0.6794, 1.0034, 0.7035, 1.1830, 1.1124, 0.7518, 0.7906, 0.5319,
         1.3488, 0.8319, 0.8305, 0.8723, 0.7808, 0.4748, 0.8029, 0.4335, 1.1811,
         0.7220, 0.4220, 0.9680, 1.0730, 0.9438, 0.7603, 1.4415, 1.0046, 0.7995,
         1.1519, 0.7857, 0.7260, 0.8757, 0.3528, 1.2106, 0.8520]],
       grad_fn=<SoftplusBackward>)
##### event loss: 2.697648286819458 non event loss:  167678.349609375 chocie_l: 2.244316339492798
### event lambdas:  tensor([[0.1113, 0.1110, 0.0420, 0.0888, 0.0785, 0.0837, 0.1584, 0.0881, 0.0616]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[0.1475, 0.1258, 0.0479, 0.0576, 0.0311, 0.1421, 0.0940, 0.0456, 0.1782,
         0.0597, 0.0466, 0.0406, 0.0985, 0.0500, 0.0869, 0.1455, 0.0588, 0.0828,
         0.0521, 0.0921, 0.1465, 0.1409, 0.0661, 0.1267, 0.1748, 0.0954, 0.1641,
         0.1754, 0.0588, 0.0850, 0.0476, 0.0332, 0.1027, 0.1198, 0.0667, 0.0679,
         0.1166, 0.0706, 0.1141, 0.2652, 0.1867, 0.0463, 0.1223, 0.2239, 0.0673,
         0.0863, 0.1980, 0.1463, 0.0884, 0.3147, 0.1772, 0.0765, 0.1879, 0.0643,
         0.1330, 0.1148, 0.1388, 0.1400, 0.1127, 0.1480, 0.0682, 0.1652, 0.2403,
         0.1395, 0.1479, 0.0772, 0.0760, 0.0842, 0.2327, 0.0241, 0.1735, 0.0534,
         0.0798, 0.0550, 0.1067, 0.1127, 0.1043, 0.0570, 0.0769, 0.0585, 0.1447,
         0.1523, 0.1366, 0.1601, 0.1662, 0.0732, 0.0489, 0.1489, 0.0653, 0.1921]],
       grad_fn=<SoftplusBackward>)
##### event loss: 22.068023681640625 non event loss:  78119.41339874268 chocie_l: 0.6576424837112427
### event lambdas:  tensor([[0.0051, 0.0061, 0.0029, 0.0010, 0.0013, 0.0011, 0.0175]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[0.0050, 0.0010, 0.0017, 0.0024, 0.0081, 0.0031, 0.0018, 0.0013, 0.0058,
         0.0101, 0.0068, 0.0039, 0.0041, 0.0017, 0.0030, 0.0004, 0.0064, 0.0037,
         0.0028, 0.0044, 0.0043, 0.0054, 0.0029, 0.0189, 0.0054, 0.0115, 0.0023,
         0.0043, 0.0091, 0.0128, 0.0027, 0.0061, 0.0035, 0.0016, 0.0016, 0.0080,
         0.0057, 0.0046, 0.0025, 0.0003, 0.0051, 0.0034, 0.0054, 0.0025, 0.0058,
         0.0025, 0.0016, 0.0016, 0.0046, 0.0083, 0.0058, 0.0036, 0.0066, 0.0044,
         0.0064, 0.0006, 0.0062, 0.0051, 0.0116, 0.0031, 0.0063, 0.0054, 0.0054,
         0.0160, 0.0016, 0.0027, 0.0057, 0.0009, 0.0103, 0.0036]],
       grad_fn=<SoftplusBackward>)
##### event loss: 40.64339065551758 non event loss:  2882.8842401504517 chocie_l: 0.04672221094369888
### event lambdas:  tensor([[0.0007, 0.0004, 0.0002, 0.0003]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[9.8364e-05, 2.6051e-04, 5.3117e-04, 5.6831e-04, 1.3498e-04, 2.9160e-04,
         5.1701e-04, 4.7211e-04, 4.9301e-04, 2.5225e-04, 4.5384e-04, 2.5938e-04,
         2.2251e-04, 4.4093e-04, 2.4804e-04, 3.1736e-04, 5.0054e-05, 2.0112e-04,
         3.7763e-04, 1.4738e-04, 2.0886e-04, 3.0282e-04, 2.7612e-04, 2.8405e-04,
         1.0752e-04, 5.2613e-04, 5.2021e-05, 1.2057e-04, 5.5831e-04, 8.6343e-04,
         2.8263e-04, 8.8246e-04, 7.4093e-05, 2.0360e-04, 2.7470e-04, 9.3880e-05,
         5.2747e-05, 5.3784e-04, 1.7248e-04, 3.9215e-04]],
       grad_fn=<SoftplusBackward>)
##### event loss: 31.503931045532227 non event loss:  75.52297854423523 chocie_l: 0.0017125486629083753
### event lambdas:  tensor([[6.9256e-05, 1.0313e-05, 2.0387e-05, 1.0700e-05, 1.6414e-05, 1.9731e-06,
         7.9768e-06, 1.3222e-05, 5.4246e-07, 4.9040e-06]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[2.5353e-06, 9.9643e-05, 2.7104e-05, 1.1605e-05, 1.7480e-05, 1.0660e-05,
         1.0013e-05, 7.4175e-05, 4.1871e-05, 3.3184e-05, 2.0040e-05, 3.1893e-06,
         8.6738e-07, 1.6394e-06, 7.9304e-06, 2.9914e-06, 3.9405e-05, 5.8343e-06,
         2.3352e-05, 3.7442e-05, 1.8173e-05, 3.6866e-05, 1.7689e-05, 3.3109e-05,
         1.1868e-05, 1.1807e-05, 7.3856e-06, 4.9877e-05, 3.4987e-05, 3.5856e-06,
         7.3357e-05, 1.6789e-05, 4.7403e-06, 5.0378e-06, 3.9101e-05, 5.9895e-05,
         3.1104e-05, 4.5882e-06, 1.6187e-05, 5.7598e-05, 1.7062e-06, 9.0355e-06,
         1.2430e-05, 1.3360e-05, 2.5764e-05, 1.1313e-05, 3.0572e-05, 7.7655e-06,
         5.1833e-06, 6.2041e-05, 7.2583e-06, 1.4085e-05, 3.5779e-05, 3.7668e-06,
         1.8183e-05, 2.7185e-05, 1.8538e-05, 1.0661e-05, 4.1156e-05, 4.0182e-05,
         2.5851e-05, 1.0354e-05, 2.4321e-05, 1.0303e-05, 3.8681e-06, 1.7275e-05,
         1.6009e-06, 3.4756e-05, 2.2026e-05, 2.0119e-06, 1.6397e-06, 7.5619e-06,
         1.4293e-05, 2.5438e-05, 1.5929e-05, 1.9539e-05, 3.6640e-05, 2.3459e-05,
         2.4302e-06, 5.9507e-05, 2.1809e-05, 1.6907e-06, 4.6237e-05, 1.3821e-05,
         7.7543e-05, 7.6703e-05, 1.8979e-05, 5.1174e-06, 1.4650e-05, 8.4225e-06,
         1.0446e-05, 2.0018e-05, 3.0301e-05, 2.9073e-05, 1.8738e-06, 1.1677e-05,
         2.5428e-05, 7.6439e-06, 2.1623e-05, 2.9010e-05]],
       grad_fn=<SoftplusBackward>)
##### event loss: 117.08415985107422 non event loss:  17.531027041375637 chocie_l: 0.037388626486063004
### event lambdas:  tensor([[4.5150e-06, 1.6684e-07, 8.6374e-07, 7.5033e-07, 2.0615e-07]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[3.8971e-06, 1.0996e-06, 9.5003e-06, 2.5894e-06, 9.2861e-07, 1.5866e-06,
         1.3188e-07, 2.5509e-06, 5.8368e-07, 1.1866e-06, 2.3039e-06, 4.5856e-07,
         1.9075e-06, 3.9279e-06, 5.1328e-06, 8.7111e-06, 1.3294e-06, 1.4780e-06,
         2.3806e-06, 1.4701e-06, 3.6127e-07, 3.6367e-07, 7.0133e-07, 1.4269e-05,
         1.9917e-06, 2.0270e-06, 1.0681e-06, 4.1880e-07, 4.1756e-07, 3.1202e-07,
         1.5160e-06, 2.1072e-06, 2.6439e-07, 1.8684e-06, 2.6117e-06, 1.0046e-06,
         2.3889e-07, 1.7105e-06, 1.3239e-06, 2.4248e-07, 2.0468e-06, 7.2174e-06,
         1.0769e-06, 6.9965e-07, 2.9789e-06, 2.0706e-06, 2.6034e-06, 1.1197e-06,
         2.9518e-06, 1.4164e-06]], grad_fn=<SoftplusBackward>)
  1%|██▏                                                                                                                                                                                 | 6/496 [00:01<01:35,  5.12it/s]
##### event loss: 71.37373352050781 non event loss:  0.846205147645378 chocie_l: 0.032682813704013824
### event lambdas:  tensor([[1.6790e-08, 3.1764e-08, 5.1194e-08, 5.5500e-07, 7.3560e-07]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[3.8737e-07, 2.2786e-08, 6.0059e-08, 2.6841e-08, 3.5954e-08, 3.7799e-08,
         5.2761e-08, 6.3564e-07, 7.9370e-07, 4.4126e-07, 5.6383e-07, 2.1086e-08,
         3.9026e-08, 2.7426e-08, 2.4357e-08, 2.5668e-08, 3.5245e-07, 5.1645e-07,
         7.2606e-07, 3.0942e-08, 9.4627e-07, 9.5754e-07, 7.4533e-07, 5.5230e-08,
         7.6788e-07, 2.8144e-08, 8.0410e-07, 3.2798e-08, 1.5737e-08, 2.5232e-08,
         4.6367e-08, 1.9166e-08, 4.0137e-07, 3.5502e-08, 2.7177e-08, 5.3737e-07,
         1.7955e-08, 7.4021e-08, 4.2359e-08, 2.7546e-08, 3.8472e-08, 2.7261e-08,
         2.0019e-08, 3.0441e-08, 2.0355e-08, 3.3847e-08, 3.6217e-07, 7.1319e-07,
         3.8904e-08, 2.8840e-08]], grad_fn=<SoftplusBackward>)
##### event loss: 80.48194122314453 non event loss:  0.0109435935592046 chocie_l: 0.03567885980010033
### event lambdas:  tensor([[8.4112e-07, 2.9840e-07, 5.6548e-07, 2.6183e-07, 4.6474e-07, 1.2651e-07,
         1.9827e-07, 2.4404e-07, 2.1202e-07, 2.2013e-07, 8.0722e-08, 1.5663e-07,
         5.9128e-08, 1.5997e-07, 1.8828e-07, 1.2131e-07, 1.9466e-07, 1.1518e-07,
         1.0725e-07, 1.8695e-07, 6.4036e-08, 8.1649e-08, 1.0555e-07, 7.6696e-08,
         1.0729e-07, 4.0388e-08, 3.7677e-08, 7.8917e-08, 6.2539e-08, 5.1119e-08,
         3.9489e-08, 7.5921e-08, 3.9477e-08, 5.7668e-08, 4.1582e-08, 3.6531e-08,
         2.1536e-08, 7.6060e-08, 6.1773e-08, 6.6991e-08, 1.0180e-07, 4.1862e-08,
         7.2746e-08, 1.4145e-08, 2.0106e-08, 3.5411e-08, 3.5907e-08, 2.4798e-08,
         1.1093e-08, 1.6905e-08, 2.9848e-08, 1.1236e-08, 1.9009e-08, 7.6658e-09,
         1.3301e-08, 1.3903e-08, 1.5285e-08, 1.6692e-08, 9.8068e-09, 8.3614e-09,
         9.1490e-09, 2.7439e-09, 5.9975e-09, 2.7158e-09, 1.0616e-08, 2.5807e-08,
         9.8887e-09, 1.9201e-08, 3.0248e-08, 2.4312e-08, 1.8191e-08, 1.2661e-08,
         2.8423e-08, 2.6374e-08, 2.2261e-08, 1.4990e-08, 4.7705e-08, 2.0543e-08,
         3.1930e-09, 2.2062e-09, 2.7546e-09, 3.4030e-09, 1.3651e-08, 3.3584e-08,
         1.5502e-08, 1.6191e-09, 1.7024e-09, 4.4789e-09, 3.9023e-09, 3.2126e-08,
         4.1477e-08, 4.6888e-08, 6.7377e-09, 1.6660e-08, 4.3328e-09, 9.0839e-08,
         2.3482e-08, 6.6214e-08, 8.3400e-08]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[1.8585e-08, 2.1330e-08, 6.5915e-09, 5.6721e-09, 6.8080e-08, 1.2916e-08,
         1.8973e-07, 9.0633e-08, 2.4251e-09, 3.2989e-08, 6.0799e-09, 2.5413e-08,
         1.3523e-08, 2.7123e-08, 5.5491e-08, 3.1037e-08, 2.1106e-09, 5.7871e-09,
         1.0902e-08, 2.6450e-09, 7.5327e-08, 9.9955e-08, 9.4707e-08, 1.5410e-09,
         4.2783e-08, 3.7380e-08, 3.0378e-08, 6.8311e-08, 5.9529e-09, 1.1071e-08,
         3.1575e-08, 5.3653e-08, 6.6691e-08, 1.7452e-09, 2.8832e-08, 1.5277e-07,
         4.3126e-08, 2.3907e-08, 1.9410e-08, 4.5659e-08, 7.8424e-09, 2.3325e-08,
         1.1181e-07, 6.2422e-08, 1.1307e-08, 3.8403e-08, 3.4793e-08, 4.1192e-08,
         9.3976e-08, 1.2057e-08, 6.8876e-08, 2.0485e-08, 3.5963e-08, 2.0521e-09,
         2.0940e-08, 2.5128e-08, 1.8212e-07, 2.6027e-08, 1.8128e-08, 1.5920e-07,
         6.8929e-08, 4.9834e-08, 5.1984e-08, 9.3133e-09, 1.8509e-08, 2.3656e-09,
         1.1868e-07, 1.8267e-08, 2.4551e-08, 1.3236e-08, 2.9411e-08, 3.5900e-07,
         2.8632e-09, 5.0441e-08, 2.8419e-08, 9.5847e-08, 8.2094e-09, 4.0383e-08,
         2.4748e-09, 9.7241e-08, 6.0930e-10, 9.6211e-08, 4.3158e-09, 4.0780e-08,
         1.1109e-08, 1.2081e-08, 7.4813e-09, 2.0152e-08, 3.9739e-08, 2.0291e-07,
         4.3052e-08, 4.0363e-08, 3.5899e-08, 2.3565e-08, 1.8989e-08, 9.9884e-09,
         3.8583e-08, 3.2401e-08, 3.1621e-09, 6.3279e-08, 9.5224e-08, 4.7633e-08,
         4.9261e-08, 1.9384e-07, 3.7634e-08, 3.0352e-08, 1.9605e-09, 5.0228e-09,
         1.8967e-09, 1.8594e-07, 4.4811e-08, 6.2732e-08, 4.1518e-08, 2.9678e-08,
         2.6891e-08, 1.1269e-08, 3.2746e-08, 2.6761e-08, 2.0029e-08, 2.0810e-08,
         2.7975e-07, 3.1991e-09, 3.6758e-08, 1.1023e-09, 1.5923e-09, 1.5508e-08,
         7.9678e-08, 1.1440e-09, 1.3199e-08, 1.9160e-08, 7.3600e-09, 4.8499e-07,
         6.1351e-08, 3.6815e-08, 2.3999e-09, 1.5775e-09, 2.7643e-08, 4.6111e-08,
         6.0013e-08, 1.0201e-07, 6.9047e-08, 1.9209e-09, 2.7631e-07, 5.0966e-08,
         6.7920e-08, 3.0690e-07, 3.4956e-08, 3.1085e-08, 1.2092e-08, 3.0418e-08,
         1.9203e-08, 2.2208e-09, 3.8616e-08, 3.3916e-08, 1.5221e-07, 4.5579e-09,
         5.5920e-08, 4.3145e-08, 4.5424e-08, 8.8964e-09, 4.3790e-08, 3.0608e-08,
         5.1539e-09, 5.8697e-09, 4.4932e-08, 4.2401e-08, 1.9562e-08, 3.4940e-08,
         2.1765e-08, 1.2089e-07, 1.7189e-09, 6.6609e-09, 1.2700e-07, 2.6256e-08,
         2.5421e-08, 2.4638e-08, 2.4040e-08, 2.7806e-09, 6.8655e-08, 1.9621e-08,
         5.3791e-08, 3.4338e-08, 2.5892e-08, 1.1287e-08, 4.8823e-09, 2.2429e-08,
         3.0306e-08, 7.4250e-08, 1.6693e-09, 9.1485e-08, 8.5619e-09, 1.0259e-07,
         1.2382e-08, 3.9863e-08, 2.0795e-08, 2.3438e-07, 6.2051e-08, 1.0206e-08,
         1.8955e-09, 9.1455e-09, 3.8002e-09, 1.9933e-09, 1.8096e-07, 6.9882e-08,
         6.0946e-09, 4.7592e-08, 1.1894e-08, 3.0705e-08, 1.8751e-08, 2.3752e-08,
         1.3199e-07, 9.7088e-08, 3.3806e-09, 3.3259e-09, 7.0527e-08, 2.5209e-09,
         2.5400e-08, 1.3786e-08, 2.6923e-09, 3.1245e-08, 2.9966e-08, 5.6611e-08,
         2.7766e-08, 4.5349e-09, 2.3091e-09, 7.1364e-09, 5.5532e-08, 2.0767e-09,
         2.4774e-08, 1.0534e-08, 2.6506e-08, 1.5640e-08, 1.1545e-08, 1.0181e-08,
         7.4229e-09, 2.2342e-08, 9.1639e-08, 7.7303e-09, 3.2226e-09, 1.0718e-08,
         2.6798e-08, 5.0858e-08, 1.9032e-08, 2.0639e-08, 1.9525e-09, 3.6368e-08,
         5.1753e-09, 1.7199e-08, 3.2185e-08, 2.0183e-08, 3.6252e-08, 6.9730e-08,
         2.6126e-08, 2.3566e-09, 2.0423e-09, 1.7151e-08, 1.1194e-09, 1.2848e-07,
         5.2871e-08, 4.3970e-08, 8.3481e-09, 3.0671e-08, 3.2491e-08, 3.4589e-08,
         5.1468e-08, 4.7767e-08, 2.9312e-09, 1.9870e-08, 1.8942e-09, 1.2304e-08,
         1.7859e-08, 1.2827e-08, 5.0747e-08, 1.6996e-08, 9.2900e-09, 1.7006e-08,
         1.3262e-07, 2.6984e-08, 3.5622e-09, 4.9887e-09, 2.0273e-07, 1.5545e-08,
         1.2423e-08, 2.7643e-08, 3.0302e-09, 4.8638e-08, 1.6715e-09, 1.2541e-07,
         5.7653e-08, 1.0798e-09, 4.8254e-08, 3.5761e-08, 1.9632e-08, 5.3211e-08,
         1.4958e-08, 1.0553e-07, 2.2965e-08, 2.4543e-09, 3.7922e-07, 1.0971e-08,
         1.2917e-07, 2.3229e-08, 9.6261e-09, 4.2801e-08, 8.6978e-09, 3.2263e-09,
         5.5850e-09, 5.1377e-08, 3.0131e-08, 1.3192e-09, 2.6086e-08, 2.2972e-09,
         3.4076e-08, 9.7344e-10, 2.7422e-09, 2.0869e-09, 2.3417e-08, 1.7764e-08,
         1.4995e-07, 1.4849e-08, 3.0001e-08, 1.0589e-09, 1.6353e-07, 2.8858e-08,
         1.7189e-08, 4.3110e-08, 5.8648e-09, 9.1767e-09, 6.5472e-09, 2.0757e-08,
         9.7473e-09, 5.2322e-08, 1.7543e-08, 2.2475e-08, 2.1070e-08, 4.7376e-09,
         2.2650e-09, 3.6177e-08, 9.0149e-08, 6.1546e-08, 1.0905e-07, 8.8383e-09,
         7.3718e-09, 3.0545e-08, 6.8382e-08, 2.7496e-08, 4.0068e-08, 2.5552e-09,
         2.6491e-08, 5.2416e-09, 4.0863e-08, 1.7228e-07, 2.3354e-09, 2.9253e-09,
         5.3867e-08, 1.9290e-07, 1.8286e-07, 2.6651e-08, 6.4825e-08, 1.1262e-09,
         2.3035e-08, 2.7957e-08, 3.2221e-08, 1.5822e-07, 1.5450e-07, 2.7693e-08,
         2.2799e-08, 1.6214e-09, 3.8965e-08, 1.7016e-07, 2.5362e-08, 3.2280e-09,
         4.2357e-08, 4.4004e-07, 2.2534e-08, 4.1434e-08, 1.1343e-08, 7.7526e-08,
         2.0175e-08, 2.6508e-08, 1.8871e-09, 3.1745e-08, 3.8703e-08, 5.0704e-09,
         2.1240e-08, 8.0486e-08, 2.6859e-08, 4.5155e-09, 2.7220e-08, 4.5510e-08,
         5.3494e-09, 5.5777e-08, 2.1436e-08, 1.6799e-08, 8.1623e-08, 1.7545e-09,
         5.5873e-08, 2.4690e-08, 2.2183e-08, 3.7078e-08, 3.3716e-08, 3.1553e-08,
         4.0082e-08, 2.9094e-09, 3.6270e-08, 3.1021e-08, 4.0523e-08, 2.4322e-09,
         6.6968e-09, 1.1860e-08, 1.0356e-07, 2.0548e-08, 4.1805e-09, 4.9209e-08,
         4.1122e-08, 3.0574e-08, 3.4941e-07, 1.0747e-08, 1.8949e-09, 2.2762e-08,
         4.3553e-08, 5.4486e-08, 1.1808e-07, 1.5056e-09, 7.3612e-09, 2.0966e-08,
         4.8115e-08, 1.6929e-07, 3.3763e-08, 3.3879e-08, 1.6118e-07, 3.6917e-08,
         4.1067e-09, 1.2087e-09, 3.0164e-08, 1.7723e-08, 1.7802e-07, 1.7408e-08,
         2.4549e-08, 2.0837e-08, 3.2879e-09, 2.1642e-08, 2.3614e-08, 2.2669e-08,
         1.7144e-08, 3.3262e-08, 2.8367e-09, 4.2802e-09, 3.0776e-08, 4.9836e-08,
         1.5235e-08, 7.4082e-08, 1.8295e-08, 1.5972e-09, 1.0496e-07, 2.8525e-08,
         4.2405e-08, 5.4392e-08, 4.1204e-08, 2.3993e-08, 4.2065e-08, 3.3786e-08,
         5.2061e-09, 5.2960e-08, 2.0794e-08, 1.4266e-08, 1.5611e-08, 2.3924e-08,
         1.5832e-07, 5.8514e-09, 4.0309e-09, 3.2999e-08, 5.7691e-09, 4.9022e-08,
         2.6046e-08, 3.0165e-09, 1.1328e-07, 3.1484e-09, 1.1889e-09, 1.6196e-07,
         1.2153e-08, 4.0378e-08, 1.8022e-08, 8.8952e-09, 3.3986e-08, 1.5226e-07,
         6.0080e-07, 2.6378e-09, 1.3089e-08, 3.8323e-08, 7.6138e-08, 1.8085e-09,
         7.7246e-09, 4.2229e-08, 5.9618e-08, 1.8418e-08, 1.3762e-08, 6.3878e-08,
         4.4792e-09, 2.3229e-08, 4.3732e-08, 3.2220e-09, 2.4667e-09, 5.1748e-08,
         3.4092e-08, 1.0166e-09, 1.6545e-08, 2.1005e-08, 2.3339e-08, 8.7493e-08,
         1.1405e-07, 3.5936e-08, 9.8666e-08, 2.1855e-08, 5.2874e-08, 2.7445e-07,
         4.0987e-09, 2.4279e-07, 3.7989e-08, 1.2834e-07, 3.6409e-08, 2.5908e-09,
         8.7915e-08, 2.5710e-09, 2.3143e-08, 1.7009e-07, 8.6926e-09, 2.0522e-07,
         2.2361e-09, 4.0570e-08, 2.8981e-08, 2.3015e-08, 2.1410e-09, 1.8543e-07,
         1.9741e-09, 1.2587e-08, 1.4644e-08, 2.1738e-08, 3.0274e-08, 1.8209e-09,
         9.4145e-09, 4.8103e-08, 1.6423e-08, 1.1251e-07, 1.1151e-09, 2.2251e-08,
         3.6240e-08, 8.8946e-09, 1.2457e-08, 9.2535e-09, 2.9221e-08, 1.3569e-07,
         1.1704e-07, 3.5537e-09, 2.9582e-08, 3.3880e-08, 1.1688e-08, 5.8272e-08,
         6.7461e-09, 2.2276e-08, 2.8097e-08, 2.4716e-07, 5.5086e-09, 8.5673e-08,
         2.6653e-08, 1.5662e-07, 5.5950e-08, 1.0103e-07, 8.3681e-08, 5.9130e-09,
         8.3070e-09, 1.4131e-07, 4.8582e-08, 6.9055e-09, 6.0940e-08, 5.0169e-08,
         4.6003e-08, 7.1303e-09, 4.3600e-08, 8.1814e-09, 1.0771e-08, 2.6035e-09,
         1.1260e-08, 1.2853e-07, 3.5839e-08, 1.7964e-08, 1.6345e-08, 4.7023e-09,
         6.9300e-08, 2.6081e-08, 6.7597e-08, 3.6323e-07, 1.1490e-07, 2.8654e-08,
         1.8849e-08, 2.7549e-08, 2.7610e-08, 3.9611e-08, 1.7043e-07, 3.0457e-08,
         1.7275e-08, 2.1796e-08, 2.1966e-08, 2.9204e-08, 1.1417e-07, 1.4201e-08,
         3.9934e-08, 1.8675e-08, 8.6213e-09, 5.7412e-08, 4.1987e-08, 5.5109e-08,
         1.9653e-09, 2.7605e-08, 5.0135e-08, 3.2800e-08, 1.3647e-08, 1.5352e-09,
         2.0630e-08, 4.4897e-08, 1.3578e-08, 3.0547e-09, 2.0756e-08, 3.4554e-08,
         3.8546e-08, 2.1120e-09, 2.5440e-08, 6.0684e-08, 7.2885e-09, 2.8753e-08,
         4.1631e-08, 3.8175e-08, 1.2486e-08, 2.2582e-08, 1.3927e-08, 3.2250e-07,
         3.8807e-08, 2.7885e-08, 1.1536e-09, 5.0065e-08, 2.7169e-08, 2.1287e-09,
         3.0124e-08, 2.5419e-09, 5.0493e-08, 4.3724e-09, 2.5746e-09, 1.1012e-07,
         1.4147e-09, 2.0086e-08, 3.7667e-09, 1.9149e-09, 2.2854e-09, 3.1541e-07,
         3.6054e-08, 4.0570e-08, 9.4775e-09, 1.5715e-09, 4.1034e-08, 9.6888e-09,
         5.5775e-08, 3.6471e-08, 8.0485e-09, 3.8883e-08, 2.6205e-08, 1.1639e-07,
         1.7125e-09, 1.5670e-08, 3.7169e-08, 2.1136e-08, 3.2838e-08, 3.4091e-08,
         1.7017e-08, 3.0813e-08, 3.5593e-08, 1.1260e-07, 4.7027e-09, 3.5393e-08,
         3.5915e-09, 1.3031e-07, 1.4648e-07, 2.3386e-09, 1.8459e-08, 2.2708e-08,
         2.9432e-08, 1.7308e-08, 5.8742e-08, 2.7336e-08, 4.2011e-08, 9.5318e-09,
         2.9493e-08, 2.0427e-07, 1.6574e-08, 1.0074e-08, 2.4045e-08, 2.0800e-08,
         3.6590e-08, 2.6375e-08, 3.6634e-08, 1.6684e-07, 3.5466e-08, 7.2407e-08,
         1.0111e-08, 2.8545e-08, 2.9916e-08, 1.6787e-09, 3.9522e-08, 2.5948e-08,
         2.0610e-08, 1.5971e-07, 7.5647e-09, 2.2146e-09, 1.0409e-08, 1.4272e-07,
         5.3512e-08, 2.9869e-07, 1.2742e-07, 4.6067e-08, 4.0543e-08, 2.0851e-09,
         3.2202e-08, 2.2287e-08, 2.2918e-08, 3.8401e-08, 1.0750e-07, 3.5820e-08,
         2.1729e-08, 3.3880e-08, 5.5812e-08, 2.1473e-08, 3.7456e-08, 2.4341e-08,
         1.6611e-08, 2.7914e-07, 5.6063e-08, 4.7004e-08, 1.9898e-09, 1.1696e-08,
         1.2985e-08, 1.1829e-07, 1.0366e-07, 5.0429e-08, 2.3357e-08, 4.8068e-08,
         7.7026e-08, 5.4025e-08, 2.8625e-09, 1.4290e-08, 3.8398e-08, 7.4109e-08,
         1.5796e-09, 9.0787e-09, 1.4377e-07, 3.3198e-08, 2.6529e-08, 3.1910e-09,
         2.8731e-08, 3.8921e-07, 3.4945e-08, 5.5862e-09, 3.2532e-09, 6.0787e-09,
         1.2931e-07, 3.1192e-08, 1.1932e-07, 2.7229e-08, 1.0592e-07, 2.0008e-09,
         1.8433e-07, 1.0685e-07, 5.1367e-08, 1.9205e-08, 7.8743e-09, 2.0151e-07,
         3.0538e-08, 2.2541e-07, 1.0695e-08, 4.9779e-09, 5.1333e-08, 4.4003e-09,
         1.7987e-08, 2.7832e-08, 1.0766e-07, 9.9490e-08, 1.1097e-07, 2.2220e-08,
         5.0231e-09, 9.3236e-08, 5.5887e-08, 3.7808e-08, 2.8934e-08, 2.0516e-08,
         2.1641e-08, 3.9626e-09, 9.0105e-08, 1.7416e-08, 3.7655e-08, 3.7994e-08,
         4.5117e-08, 1.7892e-08, 3.9851e-08, 1.0178e-07, 2.5312e-08, 1.3535e-09,
         8.6835e-09, 1.3971e-08, 2.3874e-08, 5.7287e-08, 4.8299e-09, 5.4906e-09,
         5.5590e-09, 5.0763e-08, 1.4933e-08, 9.1385e-09, 1.2227e-07, 2.5366e-08,
         6.4154e-09, 4.2081e-08, 1.6568e-08, 3.2043e-08, 1.7923e-08, 4.8063e-08,
         3.3737e-09, 3.5353e-08, 2.8463e-08, 4.4480e-08, 7.3454e-08, 1.9374e-09,
         5.2521e-08, 5.5763e-09, 1.5246e-08, 8.6452e-09, 2.0486e-08, 2.2267e-09,
         3.3997e-08, 3.2076e-08, 7.0937e-09, 1.5419e-07, 1.6597e-08, 3.2364e-08,
         2.1912e-08, 1.3039e-08, 1.0794e-08, 2.5342e-08, 3.3573e-08, 7.2121e-08,
         4.7124e-08, 1.2623e-08, 4.7469e-08, 1.6277e-08, 3.9240e-08, 1.9726e-08,
         1.1457e-08, 1.7647e-09, 4.2132e-08, 3.9852e-08, 5.0116e-09, 1.7457e-08,
         1.5229e-09, 3.8507e-08, 2.8033e-08, 1.8077e-08, 5.0549e-08, 1.3426e-08,
         2.3788e-07, 1.3060e-07, 8.9891e-09, 3.9119e-08, 5.9074e-08, 1.0241e-08,
         2.8161e-08, 2.0021e-08, 4.7786e-08, 9.9668e-09, 3.7996e-08, 6.3797e-08,
         1.4640e-07, 2.4328e-09, 9.0380e-09, 2.7747e-08, 5.5128e-08, 2.4151e-08,
         1.6615e-09, 2.8254e-08, 4.2644e-08, 4.1676e-08, 1.8504e-07, 3.3235e-08,
         2.3869e-09, 1.6235e-07, 2.4588e-08, 6.8117e-08, 3.7189e-07, 3.1197e-08,
         1.0549e-07, 1.9703e-09, 3.3012e-09, 4.0989e-08, 1.1756e-08, 2.8188e-08,
         1.1966e-08, 3.0681e-08, 5.1340e-08, 4.2856e-08, 4.1378e-08, 3.1917e-08,
         1.9161e-08, 3.3933e-09, 2.1578e-08, 2.1727e-08, 4.9169e-09, 4.3476e-08,
         5.3532e-08, 1.8966e-08, 4.9693e-08, 4.2484e-08, 7.6231e-08, 2.7369e-09,
         2.5473e-09, 6.9024e-08, 2.1714e-07, 4.1323e-08, 3.5492e-08, 1.1948e-08,
         2.2028e-08, 1.6681e-07, 1.5200e-08, 2.1742e-08, 1.4134e-09, 3.0412e-08,
         2.3957e-08, 4.3214e-08, 1.2196e-07, 2.1728e-09, 2.2559e-09, 8.4540e-09,
         2.5500e-09, 4.0215e-09, 3.2323e-08, 2.9207e-08, 2.4464e-08, 1.9669e-09,
         2.7035e-08, 3.5538e-09, 2.6531e-08, 4.6235e-08, 1.5813e-08, 9.9987e-08,
         1.1882e-09, 2.5073e-08, 4.6832e-08, 2.2083e-08, 4.5309e-07, 1.8132e-07,
         1.9126e-09, 2.9319e-08, 2.0540e-08, 1.0950e-07, 2.1878e-08, 3.4380e-08,
         4.9472e-07, 1.9229e-08, 1.6702e-08, 3.6271e-08, 2.2586e-07, 2.6145e-08,
         2.9425e-08, 5.2410e-08, 3.9798e-08, 5.6678e-09, 1.9191e-08, 2.2629e-09,
         4.0372e-08, 3.5129e-09, 1.2498e-07, 3.0318e-09, 4.6796e-08, 1.4878e-08,
         6.4690e-09, 1.6973e-08, 8.9958e-08, 3.9446e-08, 3.6670e-09, 8.2263e-09,
         2.4232e-08, 5.7641e-08, 3.2562e-08, 7.3543e-09, 3.7579e-08, 1.9674e-08]],
  2%|██▉                                                                                                                                                                                 | 8/496 [00:01<01:48,  4.51it/s]
Traceback (most recent call last):
  File "main.py", line 156, in <module>
    main()
  File "main.py", line 152, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 107, in train
    loss, pos_timing_loss, neg_timing_loss, choice_l = model(arr_b.float(), arr_c.float(), arr_delta_time.float(), event_data, non_event_data, estimate_length, choice_data_dict)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 195, in forward
    choice_l = self.choice_net(mat_b, mat_c, choice_data_dict, self.s_year, self.e_year)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 369, in forward
    z_vt_i = self.gnn_choice(features_i.squeeze(), edges_i.squeeze()) # (N_i_1, embedding_z)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 472, in forward
    x = self.convs[i](x, edge_index)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 510, in forward
    out = self.lin_l(x) + self.lin_r(prop)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/traceback.py", line 197, in format_stack
    return format_list(extract_stack(f, limit=limit))
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/traceback.py", line 211, in extract_stack
    stack = StackSummary.extract(walk_stack(f), limit=limit)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/traceback.py", line 366, in extract
    f.line
KeyboardInterrupt