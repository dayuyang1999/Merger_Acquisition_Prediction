
CUDA availability: True
  1%|██                                                                                                                                                                                                               | 5/496 [00:00<01:26,  5.71it/s]
### event lambdas:  tensor([[ 2.9034],
        [ 3.0629],
        [ 8.6976],
        [ 6.0916],
        [ 4.7508],
        [10.3821],
        [ 6.4779],
        [14.2693]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[ 3.2363],
        [ 4.8161],
        [ 5.5438],
        [ 4.6516],
        [ 6.2511],
        [ 8.7548],
        [ 5.0672],
        [ 4.4335],
        [ 4.0040],
        [ 4.5030],
        [25.4897],
        [ 5.8471],
        [ 9.1569],
        [ 4.6469],
        [ 8.3430],
        [ 8.5270],
        [ 9.7626],
        [17.6782],
        [ 4.9114],
        [17.2222],
        [ 9.1472],
        [16.7438],
        [ 9.9414],
        [29.6520],
        [ 9.8549],
        [34.2005],
        [34.3563],
        [10.3259],
        [ 5.3715],
        [ 9.6584],
        [ 5.0995],
        [ 2.8241],
        [ 5.6059],
        [ 5.3020],
        [10.9396],
        [16.5921],
        [ 8.3051],
        [ 5.6467],
        [13.0347],
        [ 5.1737],
        [ 3.5996],
        [ 8.3333],
        [ 5.9320],
        [ 4.4598],
        [ 5.5151],
        [ 5.0552],
        [ 8.9771],
        [ 3.9747],
        [30.9817],
        [ 4.8518],
        [34.0373],
        [ 2.6530],
        [ 8.7352],
        [ 5.9176],
        [ 5.9222],
        [23.6007],
        [ 6.9471],
        [11.6431],
        [ 6.1294],
        [ 3.9007],
        [33.0548],
        [11.0185],
        [36.7855],
        [27.2740],
        [ 8.3538],
        [ 6.7168],
        [20.0389],
        [29.3675],
        [11.9703],
        [ 5.3781],
        [ 5.0417],
        [ 4.8625],
        [ 4.5453],
        [ 4.5737],
        [23.4700],
        [ 7.0234],
        [ 4.2477],
        [ 5.4638],
        [ 5.7063],
        [ 5.7494]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(-14.5801, grad_fn=<NegBackward>) non event loss:  tensor([81014.5174], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[0.8088],
        [0.6038],
        [0.5265],
        [0.2309],
        [0.6170],
        [0.7139],
        [0.4495],
        [0.5067],
        [0.6172],
        [1.5622]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[4.0713],
        [0.4246],
        [0.3565],
        [0.1884],
        [0.4696],
        [0.1968],
        [0.4888],
        [0.2373],
        [0.8181],
        [0.3287],
        [0.4617],
        [0.5830],
        [1.5466],
        [0.5370],
        [1.8200],
        [0.4925],
        [0.3508],
        [0.6671],
        [1.0067],
        [0.3197],
        [0.5160],
        [0.5329],
        [0.3303],
        [0.7903],
        [0.4819],
        [0.3180],
        [0.4026],
        [1.5848],
        [1.3556],
        [0.5616],
        [0.5758],
        [2.1622],
        [1.3017],
        [0.5993],
        [1.6030],
        [0.3819],
        [0.6733],
        [0.4806],
        [0.2574],
        [0.4366],
        [0.3527],
        [0.3372],
        [0.4903],
        [0.2505],
        [1.6180],
        [2.3660],
        [0.3237],
        [3.5220],
        [0.3934],
        [0.5556],
        [0.2733],
        [0.5729],
        [0.1893],
        [5.1035],
        [1.4894],
        [0.4706],
        [0.4773],
        [0.3585],
        [0.1802],
        [0.3562],
        [4.7537],
        [0.8675],
        [4.0287],
        [0.4428],
        [0.5762],
        [0.3762],
        [0.6971],
        [0.5769],
        [0.4844],
        [2.7824],
        [0.3984],
        [0.4599],
        [0.5256],
        [0.2572],
        [1.3843],
        [0.8109],
        [0.8994],
        [0.8677],
        [0.9878],
        [0.6596],
        [0.5486],
        [0.4455],
        [0.4455],
        [0.5841],
        [0.4773],
        [0.4334],
        [0.2807],
        [4.4160],
        [1.2248],
        [1.8290],
        [1.3600],
        [1.3336],
        [0.3523],
        [0.4762],
        [0.4700],
        [3.8014],
        [3.0043],
        [0.6149],
        [0.2273],
        [0.4548]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(5.1598, grad_fn=<NegBackward>) non event loss:  tensor([4351.0803], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[0.0377],
        [0.0667],
        [0.0411],
        [0.0473],
        [1.3092]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[2.6036e-02],
        [3.6740e-01],
        [2.3043e-02],
        [4.0432e-02],
        [4.0738e-02],
        [2.5406e-02],
        [4.4597e-02],
        [2.8112e-02],
        [4.8086e-02],
        [3.3157e-02],
        [1.2485e+00],
        [4.3060e-02],
        [4.5948e-02],
        [3.1645e-02],
        [3.0438e-01],
        [3.3530e-02],
        [2.8286e-02],
        [5.0456e-03],
        [7.3629e-02],
        [8.6134e-02],
        [8.5513e-02],
        [1.1200e+00],
        [2.5537e-01],
        [1.0559e-01],
        [2.5195e-02],
        [3.8295e-01],
        [1.2886e-01],
        [1.6319e-02],
        [3.0048e+00],
        [5.2825e-02],
        [1.1274e+00],
        [1.2353e-01],
        [3.8315e+00],
        [3.0526e-02],
        [1.5117e-02],
        [5.8086e-02],
        [1.2188e+00],
        [1.9355e+00],
        [8.7012e-02],
        [5.9990e-02],
        [1.3549e+01],
        [2.9725e-01],
        [3.5023e+00],
        [1.3123e+01],
        [2.3600e-01],
        [3.8595e-02],
        [2.7257e-02],
        [1.3014e+01],
        [1.8930e+00],
        [6.7106e-01]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(11.9576, grad_fn=<NegBackward>) non event loss:  tensor([8079.4619], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[0.0089],
        [0.0100],
        [0.0083],
        [0.0038],
        [0.0034],
        [0.0019],
        [0.0016],
        [0.0001]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[0.0006],
        [0.0007],
        [0.0009],
        [0.0066],
        [0.0004],
        [0.0036],
        [0.0007],
        [0.0025],
        [0.0033],
        [0.0024],
        [0.0001],
        [0.0001],
        [0.0028],
        [0.0005],
        [0.0056],
        [0.0017],
        [0.0016],
        [0.0013],
        [0.0078],
        [0.0001],
        [0.0003],
        [0.0010],
        [0.0013],
        [0.0026],
        [0.0060],
        [0.0030],
        [0.0115],
        [0.0092],
        [0.0002],
        [0.0019],
        [0.0005],
        [0.0013],
        [0.0020],
        [0.0102],
        [0.0001],
        [0.0003],
        [0.0006],
        [0.0026],
        [0.0018],
        [0.0070],
        [0.0118],
        [0.0008],
        [0.0033],
        [0.0091],
        [0.0039],
        [0.0062],
        [0.0020],
        [0.0024],
        [0.0005],
        [0.0006],
        [0.0019],
        [0.0010],
        [0.0041],
        [0.0005],
        [0.0034],
        [0.0014],
        [0.0014],
        [0.0015],
        [0.0027],
        [0.0019],
        [0.0005],
        [0.0007],
        [0.0002],
        [0.0016],
        [0.0007],
        [0.0015],
        [0.0002],
        [0.0025],
        [0.0001],
        [0.0035],
        [0.0015],
        [0.0002],
        [0.0003],
        [0.0018],
        [0.0028],
        [0.0013],
        [0.0107],
        [0.0020],
        [0.0033],
        [0.0011]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(46.9228, grad_fn=<NegBackward>) non event loss:  tensor([14.1531], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[8.0559e-04],
        [1.4873e-04],
        [6.6352e-05],
        [1.0421e-04],
        [7.5155e-05]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[8.9535e-05],
        [6.0504e-06],
        [7.6531e-05],
        [3.4061e-05],
        [6.2956e-06],
        [4.4978e-06],
        [8.7148e-05],
        [2.6922e-06],
        [3.7866e-06],
        [8.3385e-05],
        [9.0675e-05],
        [2.4826e-04],
        [8.3110e-05],
        [2.7407e-06],
        [7.6263e-05],
        [8.0048e-05],
        [7.7349e-05],
        [9.6361e-05],
        [9.7031e-05],
        [9.3959e-05],
        [8.8168e-05],
        [8.1731e-04],
        [6.1903e-06],
        [1.0352e-04],
        [1.3037e-04],
        [8.6393e-05],
        [9.4677e-05],
        [9.7517e-05],
        [3.3618e-05],
        [1.7911e-05],
        [1.0180e-04],
        [4.9472e-04],
        [9.8160e-05],
        [8.9522e-05],
        [1.0130e-03],
        [8.1088e-05],
        [1.4311e-04],
        [1.4828e-05],
        [2.4321e-06],
        [6.1741e-06],
        [1.4609e-04],
        [2.6979e-06],
        [2.7108e-04],
        [9.6160e-05],
        [8.8104e-05],
        [4.0572e-05],
        [9.6227e-05],
        [1.3238e-04],
        [9.8741e-05],
        [9.9707e-05]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(44.2229, grad_fn=<NegBackward>) non event loss:  tensor([0.9159], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[9.3572e-06],
        [2.0231e-06],
        [3.3789e-08],
        [6.1316e-07],
        [8.5258e-06],
        [1.1537e-06],
        [3.7384e-06],
        [6.9594e-06]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[2.1961e-06],
        [7.6178e-06],
        [2.1591e-06],
        [1.4918e-05],
        [7.8737e-08],
        [1.3121e-05],
        [8.4324e-07],
        [1.9084e-05],
        [9.3417e-08],
        [1.7544e-07],
        [3.8619e-08],
        [1.2649e-07],
        [5.2262e-08],
        [1.2370e-06],
        [7.5890e-07],
        [8.3723e-06],
        [4.4613e-06],
        [4.5991e-07],
        [1.6154e-05],
        [3.8264e-08],
        [1.6201e-06],
        [4.7915e-08],
        [2.1771e-06],
        [2.6398e-06],
        [5.3465e-06],
        [4.1430e-06],
        [1.9770e-05],
        [6.7585e-06],
        [1.3629e-06],
        [4.9878e-06],
        [7.3610e-07],
        [1.2137e-05],
        [2.0416e-05],
        [7.8561e-06],
        [9.0644e-06],
        [1.0949e-07],
        [7.4674e-08],
        [2.0302e-05],
        [9.3544e-05],
        [4.4150e-06],
        [9.1235e-06],
        [1.3978e-05],
        [4.1890e-07],
        [7.8130e-05],
        [1.6440e-06],
        [1.3325e-05],
        [5.7331e-07],
        [5.4973e-06],
        [5.9220e-06],
        [9.7688e-06],
        [1.8683e-06],
        [1.4635e-06],
        [1.4309e-06],
        [1.0801e-06],
        [2.3088e-06],
        [3.6468e-06],
        [4.6931e-06],
        [3.3537e-06],
        [5.5391e-06],
        [4.8064e-08],
        [8.9850e-07],
        [1.5099e-07],
        [4.6269e-08],
        [4.5012e-06],
        [5.8699e-06],
        [5.6901e-06],
        [4.5228e-06],
        [1.5722e-05],
        [6.6911e-06],
        [7.8942e-06],
        [9.8005e-08],
        [1.7351e-05],
        [7.0118e-08],
        [9.0287e-06],
        [1.4216e-05],
        [1.7643e-07],
        [9.7501e-08],
        [4.1504e-06],
        [1.2548e-06],
        [1.0739e-07]], grad_fn=<SoftplusBackward>)

  3%|███████▏                                                                                                                                                                                                        | 17/496 [00:03<01:03,  7.51it/s]
### event lambdas:  tensor([[1.2718e-09],
        [4.9503e-07],
        [1.5678e-08],
        [1.0171e-09],
        [2.4949e-07],
        [4.4166e-09]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[1.5163e-09],
        [1.0586e-06],
        [1.1386e-07],
        [2.6007e-09],
        [9.0495e-07],
        [3.2184e-08],
        [4.7352e-09],
        [1.2137e-07],
        [2.0443e-07],
        [4.5492e-07],
        [1.4410e-07],
        [1.7699e-08],
        [9.9706e-08],
        [1.4499e-09],
        [2.7034e-09],
        [1.6736e-07],
        [1.4708e-06],
        [2.7300e-09],
        [1.3836e-08],
        [4.7852e-07],
        [1.0285e-08],
        [1.4626e-06],
        [9.7749e-09],
        [1.1469e-08],
        [2.4883e-08],
        [3.4277e-07],
        [6.8352e-07],
        [1.5964e-08],
        [1.7988e-08],
        [5.2804e-07],
        [3.9081e-08],
        [8.9136e-08],
        [1.4553e-07],
        [7.0726e-09],
        [6.4856e-08],
        [6.1854e-08],
        [4.7857e-07],
        [1.0859e-06],
        [5.3720e-08],
        [2.8491e-08],
        [9.3384e-09],
        [3.6778e-08],
        [4.1954e-08],
        [1.2569e-08],
        [2.4748e-09],
        [6.1902e-09],
        [3.3561e-08],
        [1.0877e-08],
        [4.5880e-08],
        [6.3677e-09],
        [9.0885e-09],
        [1.7570e-07],
        [8.5915e-08],
        [5.3481e-08],
        [7.8465e-08],
        [5.8345e-07],
        [3.7867e-08],
        [4.8371e-09],
        [1.6329e-08],
        [2.6588e-08]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(108.1206, grad_fn=<NegBackward>) non event loss:  tensor([0.0012], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[3.7493e-07],
        [8.3407e-09],
        [1.6532e-07],
        [3.1567e-07],
        [4.8857e-07],
        [3.8574e-07]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[3.4045e-07],
        [4.2609e-09],
        [4.8899e-07],
        [4.6713e-07],
        [1.5338e-07],
        [3.4179e-07],
        [1.5999e-07],
        [4.8384e-09],
        [9.7860e-09],
        [4.5099e-09],
        [3.8619e-07],
        [2.7558e-07],
        [4.1750e-07],
        [3.7609e-07],
        [4.0114e-07],
        [5.4761e-07],
        [3.4674e-07],
        [3.6406e-07],
        [3.6249e-07],
        [2.6030e-07],
        [4.2766e-07],
        [3.8863e-07],
        [4.0886e-07],
        [8.6520e-09],
        [6.5089e-08],
        [4.4976e-09],
        [3.3271e-09],
        [1.7631e-07],
        [3.8006e-07],
        [5.5657e-09],
        [4.1011e-07],
        [3.3396e-09],
        [3.1077e-09],
        [3.4009e-09],
        [6.9034e-09],
        [3.4502e-07],
        [3.3721e-07],
        [4.5665e-07],
        [3.9012e-07],
        [3.1105e-07],
        [6.5291e-08],
        [6.3644e-09],
        [7.9045e-09],
        [3.4368e-07],
        [3.4217e-08],
        [1.0209e-08],
        [3.4161e-07],
        [4.2400e-07],
        [7.0475e-09],
        [8.2271e-10],
        [6.8788e-08],
        [4.3667e-07],
        [5.5844e-09],
        [3.6458e-07],
        [5.9572e-07],
        [4.7973e-07],
        [9.1685e-08],
        [6.5854e-09],
        [4.3646e-07],
        [4.1794e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(93.2825, grad_fn=<NegBackward>) non event loss:  tensor([0.0009], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[1.1051e-08],
        [5.2337e-08],
        [7.1738e-10],
        [6.1966e-09],
        [3.3362e-11],
        [1.4720e-12],
        [3.4428e-09],
        [9.0464e-09],
        [1.2347e-08]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[1.6271e-10],
        [3.7862e-09],
        [5.5445e-12],
        [2.2671e-08],
        [2.0862e-08],
        [5.6731e-10],
        [4.3636e-09],
        [3.2707e-07],
        [4.2890e-11],
        [3.0928e-08],
        [2.1755e-08],
        [3.1388e-09],
        [1.8970e-08],
        [5.7542e-10],
        [1.5544e-10],
        [1.2362e-08],
        [8.5029e-10],
        [1.1460e-10],
        [1.1250e-11],
        [2.3904e-12],
        [1.0066e-09],
        [1.7844e-08],
        [2.0247e-08],
        [4.8310e-09],
        [5.8599e-12],
        [1.0922e-08],
        [7.6753e-09],
        [1.2737e-08],
        [1.2224e-11],
        [1.0186e-10],
        [4.9576e-12],
        [2.3750e-08],
        [4.2204e-10],
        [5.7799e-11],
        [1.3406e-11],
        [8.1933e-10],
        [1.8753e-08],
        [8.4253e-12],
        [9.5380e-10],
        [7.1322e-10],
        [8.1791e-11],
        [1.1010e-08],
        [5.9797e-10],
        [2.3182e-08],
        [1.1590e-07],
        [1.6946e-07],
        [6.3215e-12],
        [1.3554e-08],
        [1.4262e-09],
        [1.9842e-09],
        [3.9411e-07],
        [2.5284e-11],
        [1.5517e-09],
        [1.1947e-10],
        [1.0941e-11],
        [1.8303e-08],
        [9.2407e-09],
        [1.5925e-07],
        [1.3390e-09],
        [1.2880e-08],
        [5.5020e-10],
        [3.5341e-10],
        [2.0041e-09],
        [3.3976e-08],
        [6.8689e-12],
        [7.2862e-10],
        [2.0012e-07],
        [1.8088e-10],
        [6.2097e-08],
        [1.3098e-10],
        [6.1657e-08],
        [2.0841e-09],
        [6.7552e-08],
        [2.5028e-08],
        [1.8744e-09],
        [1.0864e-08],
        [6.5493e-11],
        [4.7913e-10],
        [2.4293e-12],
        [7.8008e-10],
        [1.7986e-08],
        [2.1812e-09],
        [1.3136e-08],
        [7.8919e-10],
        [8.2302e-09],
        [8.8421e-10],
        [2.1934e-11],
        [4.9277e-09],
        [4.4835e-09],
        [6.4263e-10]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(182.6267, grad_fn=<NegBackward>) non event loss:  tensor([0.0002], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[2.7721e-07],
        [4.0293e-09],
        [6.6593e-09],
        [3.3910e-09],
        [4.2643e-10],
        [8.3889e-09]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[4.5171e-07],
        [7.5922e-09],
        [4.2292e-11],
        [4.5367e-12],
        [4.5730e-09],
        [7.0381e-13],
        [1.2435e-12],
        [1.5243e-11],
        [7.2368e-10],
        [1.1708e-09],
        [7.0169e-08],
        [1.4679e-11],
        [2.6075e-11],
        [6.1280e-13],
        [4.1250e-11],
        [4.0605e-09],
        [5.5731e-07],
        [2.2320e-10],
        [3.2034e-09],
        [2.9897e-10],
        [5.4203e-08],
        [3.0007e-08],
        [3.8906e-12],
        [8.2070e-11],
        [9.7504e-09],
        [4.2611e-09],
        [8.7494e-13],
        [8.4615e-12],
        [5.3482e-09],
        [7.2567e-10],
        [4.5774e-09],
        [1.3371e-08],
        [2.5433e-12],
        [5.2485e-08],
        [8.3964e-09],
        [8.6046e-11],
        [3.7738e-08],
        [8.1061e-11],
        [1.0535e-07],
        [2.6069e-09],
        [4.5242e-07],
        [3.3088e-11],
        [4.9720e-07],
        [7.3357e-09],
        [1.6350e-09],
        [4.8759e-09],
        [1.4722e-07],
        [2.6393e-11],
        [2.3665e-11],
        [4.6803e-13],
        [2.1842e-12],
        [5.8395e-10],
        [2.1432e-12],
        [6.4763e-09],
        [3.3085e-11],
        [1.8830e-11],
        [9.8477e-10],
        [2.8459e-08],
        [9.2092e-09],
        [5.0843e-09]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(112.9295, grad_fn=<NegBackward>) non event loss:  tensor([0.0002], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[2.4836e-07],
        [4.7174e-08],
        [3.1341e-09],
        [1.7782e-08],
        [1.1675e-09],
        [7.5487e-09]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[1.4182e-09],
        [2.3826e-11],
        [2.6262e-15],
        [1.6312e-09],
        [7.6844e-12],
        [1.0010e-07],
        [5.1499e-12],
        [4.7616e-14],
        [4.1624e-11],
        [8.4623e-11],
        [2.3444e-10],
        [2.5775e-13],
        [2.1177e-15],
        [5.6337e-11],
        [7.2801e-08],
        [7.9302e-12],
        [6.4000e-11],
        [4.4387e-14],
        [6.1983e-13],
        [1.2938e-10],
        [2.2504e-10],
        [1.1407e-09],
        [6.8189e-08],
        [3.9026e-13],
        [1.4745e-08],
        [1.1901e-08],
        [3.2934e-11],
        [5.0800e-11],
        [9.4076e-11],
        [1.4073e-10],
        [7.3299e-09],
        [9.3169e-11],
        [3.8222e-13],
        [5.5075e-10],
        [7.0337e-14],
        [2.2489e-11],
        [2.9080e-11],
        [6.2111e-10],
        [1.0577e-12],
        [2.2300e-10],
        [2.9399e-10],
        [1.6528e-09],
        [2.4254e-11],
        [2.0384e-10],
        [3.5203e-12],
        [1.2519e-12],
        [6.0962e-12],
        [2.5335e-14],
        [1.5015e-11],
        [8.3309e-14],
        [6.1231e-09],
        [1.2006e-07],
        [1.2204e-09],
        [7.3933e-16],
        [3.4528e-13],
        [4.0537e-11],
        [3.7646e-10],
        [2.2942e-10],
        [1.7649e-14],
        [1.0123e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(108.7741, grad_fn=<NegBackward>) non event loss:  tensor([6.4330e-05], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[6.6457e-09],
        [1.5499e-12],
        [1.4099e-10],
        [4.6873e-14],
        [1.7730e-12],
        [5.1291e-11]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[2.8561e-10],
        [4.8198e-13],
        [6.2930e-11],
        [4.9879e-17],
        [3.8789e-08],
        [2.0724e-11],
        [1.3126e-10],
        [1.7639e-13],
        [7.6632e-11],
        [6.1303e-10],
        [7.6655e-11],
        [1.7160e-12],
        [1.9272e-11],
        [2.2325e-12],
        [6.9577e-12],
        [6.2291e-15],
        [1.3108e-10],
        [3.9534e-12],
        [9.9739e-13],
        [1.8404e-12],
        [3.4059e-10],
        [2.7907e-13],
        [8.9385e-12],
        [2.0924e-12],
        [1.4139e-11],
        [1.6540e-08],
        [7.5330e-15],
        [2.8632e-12],
        [1.1048e-15],
        [3.2884e-12],
        [6.0678e-14],
        [6.9835e-16],
        [4.9628e-13],
        [1.7385e-12],
        [3.9899e-08],
        [2.3837e-10],
        [5.5784e-12],
        [1.8150e-11],
        [1.8197e-17],
        [9.0967e-11],
        [4.3340e-11],
        [5.6881e-16],
        [5.2715e-13],
        [6.3859e-10],
        [1.2959e-17],
        [1.3829e-15],
        [2.7054e-10],
        [7.7535e-18],
        [1.0988e-10],
        [1.7068e-11],
        [1.7980e-12],
        [2.8192e-15],
        [1.3499e-11],
        [2.4211e-12],
        [9.6551e-13],
        [3.6491e-11],
        [3.0078e-11],
        [1.4712e-09],
        [1.1599e-14],
        [6.3235e-12]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(150.1476, grad_fn=<NegBackward>) non event loss:  tensor([1.2494e-05], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[2.9537e-11],
        [6.8677e-16],
        [9.5373e-11],
        [7.4439e-12],
        [3.6148e-10],
        [4.7631e-09]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[2.2287e-11],
        [1.5332e-13],
        [8.3805e-12],
        [1.2847e-13],
        [3.6932e-11],
        [1.7264e-10],
        [9.0108e-14],
        [1.1182e-11],
        [3.4988e-11],
        [1.0731e-12],
        [1.7397e-10],
        [3.1701e-10],
        [9.4071e-12],
        [2.2240e-10],
        [2.7154e-10],
        [3.2006e-11],
        [4.0360e-11],
        [7.6644e-14],
        [3.7482e-12],
        [1.7111e-11],
        [1.2049e-11],
        [6.1078e-11],
        [9.3074e-14],
        [3.2068e-13],
        [7.0510e-11],
        [2.4853e-10],
        [3.1763e-10],
        [5.3187e-12],
        [1.0550e-12],
        [1.0034e-11],
        [1.5087e-08],
        [2.5010e-11],
        [7.1714e-11],
        [1.6164e-10],
        [1.3155e-10],
        [1.8983e-10],
        [7.9411e-13],
        [5.8383e-11],
        [1.2223e-10],
        [8.3528e-12],
        [2.6071e-11],
        [1.5571e-13],
        [1.7276e-10],
        [1.7886e-10],
        [2.5891e-11],
        [2.7011e-10],
        [5.0504e-11],
        [1.3046e-11],
        [2.6385e-12],
        [1.8566e-10],
        [1.2431e-10],
        [1.3941e-10],
        [4.6915e-14],
        [8.7328e-12],
        [1.3086e-10],
        [1.1391e-10],
        [1.8763e-10],
        [1.0068e-10],
        [6.1674e-12],
        [1.3941e-13]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(148.7599, grad_fn=<NegBackward>) non event loss:  tensor([1.6692e-06], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[1.3848e-10],
        [3.5757e-10],
        [9.5898e-14],
        [2.0445e-12],
        [1.0849e-11],
        [1.0010e-12],
        [2.6504e-13],
        [4.3980e-15],
        [4.3235e-14],
        [3.1096e-15],
        [8.9670e-14],
        [1.8640e-11]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[1.0590e-14],
        [6.1498e-15],
        [1.3146e-11],
        [1.1129e-10],
        [4.4260e-13],
        [2.0906e-13],
        [2.8755e-11],
        [6.3419e-12],
        [5.0738e-12],
        [1.1341e-12],
        [6.4694e-15],
        [2.7918e-11],
        [1.7005e-14],
        [2.4546e-11],
        [2.7650e-14],
        [3.7778e-10],
        [3.7950e-12],
        [4.9916e-11],
        [4.0378e-12],
        [1.9269e-11],
        [1.7449e-11],
        [2.8725e-14],
        [2.0008e-15],
        [1.3588e-09],
        [1.1873e-14],
        [3.7672e-14],
        [8.0651e-15],
        [5.7438e-16],
        [1.0613e-15],
        [3.4787e-11],
        [2.9353e-11],
        [2.6943e-11],
        [7.3277e-12],
        [4.7036e-11],
        [1.5542e-15],
        [1.4846e-11],
        [2.0364e-11],
        [5.1897e-15],
        [1.7576e-12],
        [7.8861e-14],
        [4.4586e-11],
        [9.5624e-13],
        [8.6502e-12],
        [1.0894e-13],
        [1.0877e-14],
        [4.4659e-11],
        [8.1482e-14],
        [3.7491e-14],
        [8.6506e-09],
        [2.4814e-11],
        [6.1055e-11],
        [2.6262e-12],
        [1.4726e-11],
        [3.9283e-11],
        [1.7234e-11],
        [7.1326e-09],
        [4.4975e-11],
        [1.4581e-16],
        [3.7132e-12],
        [9.6097e-12],
        [4.1922e-11],
        [1.0846e-11],
        [2.6623e-11],
        [5.2071e-12],
        [1.9929e-10],
        [1.7318e-10],
        [2.9740e-13],
        [2.6074e-11],
        [2.0214e-11],
        [1.1743e-11],
        [3.6344e-12],
        [7.6475e-09],
        [3.3337e-15],
        [4.0563e-11],
        [4.5525e-12],
        [9.3292e-12],
        [3.2741e-12],
        [1.7536e-12],
        [2.1267e-09],
        [2.3679e-12],
        [2.4526e-14],
        [2.5809e-11],
        [4.6637e-14],
        [2.0517e-15],
        [4.9916e-14],
        [4.4455e-11],
        [6.3632e-16],
        [2.1382e-10],
        [1.1492e-10],
        [2.5417e-14],
        [8.2640e-15],
        [2.3125e-15],
        [4.8119e-13],
        [5.2900e-13],
        [4.8497e-10],
        [5.9001e-11],
        [4.9686e-12],
        [3.9020e-13],
        [4.4975e-10],
        [1.3451e-12],
        [8.6628e-13],
        [2.9337e-13],
        [3.8196e-14],
        [3.7991e-13],
        [6.4184e-15],
        [2.2382e-11],
        [1.7909e-11],
        [1.4357e-14],
        [6.4715e-12],
        [3.1014e-11],
        [2.8116e-14],
        [2.0083e-12],
        [8.2380e-15],
        [9.2882e-15],
        [1.4840e-11],
        [1.1946e-15],
        [1.5506e-16],
        [6.8920e-15],
        [2.3168e-16],
        [3.5308e-11]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(335.1616, grad_fn=<NegBackward>) non event loss:  tensor([1.6180e-06], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[8.2533e-15],
        [9.9380e-12],
        [3.0760e-23]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[4.3830e-18],
        [4.4832e-23],
        [1.6986e-11],
        [1.1092e-14],
        [9.9858e-17],
        [3.3439e-15],
        [1.8379e-11],
        [1.2909e-13],
        [4.0145e-14],
        [1.8315e-11],
        [2.8675e-14],
        [2.6499e-18],
        [3.9976e-17],
        [6.4521e-20],
        [1.6708e-14],
        [1.7718e-11],
        [8.7193e-20],
        [2.6013e-18],
        [9.3275e-21],
        [1.4323e-11],
        [3.5680e-12],
        [5.5475e-11],
        [1.0631e-20],
        [1.5528e-20],
        [1.1184e-16],
        [3.4197e-14],
        [6.3131e-23],
        [4.3037e-23],
        [1.3014e-11],
        [2.0209e-19]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(109.5987, grad_fn=<NegBackward>) non event loss:  tensor([2.4285e-08], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[2.7707e-12],
        [1.9676e-18],
        [4.3324e-13],
        [1.6468e-09]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[4.8103e-14],
        [4.7030e-09],
        [2.4457e-16],
        [6.0277e-09],
        [1.1035e-12],
        [2.3815e-12],
        [1.1319e-13],
        [6.4317e-15],
        [2.9395e-18],
        [4.0189e-18],
        [1.4441e-09],
        [3.6589e-13],
        [5.0402e-20],
        [9.7060e-13],
        [5.9238e-13],
        [3.8786e-12],
        [4.3509e-12],
        [3.7602e-15],
        [1.3696e-17],
        [3.5691e-18],
        [5.8559e-12],
        [2.4369e-18],
        [2.4404e-12],
        [2.2759e-16],
        [8.2221e-14],
        [1.6510e-12],
        [7.6258e-11],
        [1.2576e-17],
        [2.8582e-16],
        [2.0016e-23],
        [1.1323e-10],
        [2.9328e-14],
        [3.3985e-15],
        [1.6944e-17],
        [9.0649e-15],
        [1.1435e-16],
        [9.7974e-23],
        [5.6954e-11],
        [3.1436e-15],
        [9.4316e-18]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(116.0735, grad_fn=<NegBackward>) non event loss:  tensor([2.6742e-06], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[1.0881e-16],
        [3.0651e-14],
        [3.7916e-12],
        [2.9268e-12]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[8.2397e-11],
        [4.7458e-15],
        [2.7341e-13],
        [2.7434e-12],
        [3.5793e-12],
        [5.8907e-12],
        [6.2526e-12],
        [4.6084e-15],
        [5.8691e-15],
        [1.4389e-13],
        [1.6018e-13],
        [1.6723e-17],
        [1.3255e-10],
        [1.4087e-13],
        [1.3253e-14],
        [3.6750e-15],
        [5.9005e-12],
        [1.0595e-12],
        [8.3172e-13],
        [1.4014e-12],
        [2.2715e-13],
        [7.6898e-15],
        [2.8596e-12],
        [7.4981e-15],
        [8.1473e-14],
        [2.5739e-14],
        [1.0527e-13],
        [1.4761e-13],
        [1.0939e-13],
        [2.1700e-15],
        [7.4178e-12],
        [3.3667e-14],
        [1.6522e-13],
        [2.3621e-12],
        [4.1079e-12],
        [6.3838e-15],
        [1.6799e-12],
        [2.8354e-12],
        [3.5564e-14],
        [7.6442e-16]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(120.7284, grad_fn=<NegBackward>) non event loss:  tensor([2.4851e-08], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[2.6258e-11],
        [1.4105e-11],
        [7.4852e-12],
        [7.2845e-14],
        [3.3550e-16]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[5.5539e-14],
        [7.3072e-14],
        [9.4280e-14],
        [4.5906e-13],
        [1.7127e-15],
        [6.9930e-13],
        [1.4434e-12],
        [3.3690e-15],
        [1.7455e-18],
        [1.4981e-12],
        [2.8053e-13],
        [1.3124e-15],
        [4.5147e-18],
        [8.2229e-12],
        [3.7897e-13],
        [8.8372e-15],
        [8.9371e-19],
        [2.3791e-15],
        [4.7169e-19],
        [1.4978e-11],
        [3.9267e-19],
        [1.4579e-11],
        [1.1991e-12],
        [2.9868e-15],
        [1.9398e-11],
        [5.1096e-15],
        [1.5337e-15],
        [3.0213e-15],
        [1.3358e-15],
        [2.0200e-17],
        [3.2350e-15],
        [3.3719e-17],
        [7.5639e-12],
        [1.4899e-15],
        [5.9733e-16],
        [1.0621e-15],
        [3.5922e-16],
        [1.4740e-17],
        [4.2519e-16],
        [7.4431e-13],
        [3.5589e-13],
        [1.9724e-12],
        [2.0538e-12],
        [3.1288e-17],
        [4.3440e-16],
        [3.5898e-13],
        [9.2608e-15],
        [5.4977e-16],
        [1.4618e-14],
        [4.1171e-17]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(140.8470, grad_fn=<NegBackward>) non event loss:  tensor([3.7089e-09], dtype=torch.float64, grad_fn=<MulBackward0>)
### event lambdas:  tensor([[2.3155e-09],
        [6.5320e-10],
        [5.3179e-10],
        [4.2567e-10],
        [1.0165e-09],
        [1.3865e-09],
        [1.7126e-09],
        [4.4368e-10],
        [9.4546e-10],
        [9.2925e-10],
        [7.7233e-10],
        [1.3970e-10],
        [6.9130e-11],
        [1.3318e-10],
        [2.6363e-10],
        [3.6816e-10],
        [2.1238e-10],
        [2.2051e-10],
        [1.5680e-10],
        [1.5974e-10],
        [3.8302e-11],
        [5.2247e-11],
        [6.7231e-11],
        [4.1598e-11],
        [7.1461e-11],
        [9.6426e-12],
        [1.1707e-11],
        [1.4853e-11],
        [1.2690e-11],
        [1.4933e-11],
        [1.5832e-12],
        [2.4556e-12],
        [1.3676e-12],
        [1.0250e-12],
        [3.2250e-12],
        [2.4968e-12],
        [2.1776e-12],
        [2.7617e-12],
        [3.0772e-12],
        [3.5924e-12],
        [1.3483e-12],
        [6.2336e-13],
        [3.0442e-12],
        [3.6362e-13],
        [2.6781e-13],
        [2.2353e-13],
        [4.8364e-13],
        [1.3346e-13],
        [4.0394e-13],
        [3.2024e-13],
        [3.2333e-13],
        [3.9363e-13],
        [4.4412e-13],
        [2.7696e-14],
        [1.7292e-14],
        [3.9360e-14],
        [7.2727e-15],
        [1.9134e-14],
        [2.6693e-14],
        [3.2836e-14],
        [5.1970e-15],
        [5.5078e-15],
        [3.9303e-15],
        [7.0250e-16],
        [4.7279e-15],
        [8.1251e-13],
        [5.9824e-13],
        [9.5879e-13],
        [2.5233e-13],
        [5.5323e-13],
        [2.3773e-13],
        [7.0354e-13],
        [8.2236e-13],
        [4.6718e-13],
        [3.3235e-13],
        [9.4474e-14],
        [5.2879e-13],
        [8.4649e-13],
        [9.5389e-18],
        [3.7965e-17],
        [2.0828e-17],
        [5.3674e-17],
        [5.9871e-15],
        [8.9432e-13],
        [5.9765e-13],
        [2.5913e-16],
        [1.7085e-16],
        [2.9321e-16],
        [7.8397e-17],
        [2.2251e-13],
        [9.7136e-14],
        [5.5954e-13],
        [4.3180e-15],
        [5.1024e-13],
        [6.6543e-18],
        [1.3389e-15],
        [1.4953e-14],
        [1.1436e-13],
        [7.8335e-14]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[1.0016e-13],
        [7.3883e-13],
        [2.8857e-13],
        [3.7201e-13],
        [1.5758e-09],
        [4.7423e-14],
        [9.7604e-13],
        [7.5776e-12],
        [1.2130e-15],
        [3.1855e-13],
        [1.1226e-14],
        [6.3863e-12],
        [3.0140e-17],
        [3.6823e-15],
        [3.2572e-13],
        [1.2465e-11],
        [4.6378e-13],
        [7.3291e-16],
        [3.2262e-14],
        [5.5665e-15],
        [5.5293e-14],
        [3.6697e-16],
        [1.8868e-13],
        [7.0165e-15],
        [3.2322e-13],
        [6.2421e-14],
        [1.3636e-14],
        [1.9707e-12],
        [5.4932e-13],
        [1.8748e-12],
        [4.2962e-16],
        [1.6022e-13],
        [1.5156e-11],
        [7.1835e-12],
        [2.8988e-13],
        [1.1854e-09],
        [1.2398e-13],
        [1.7565e-12],
        [1.3645e-14],
        [7.8537e-13],
        [6.6829e-16],
        [1.2245e-11],
        [6.3115e-15],
        [4.2181e-13],
        [1.6199e-13],
        [2.8717e-13],
        [7.5605e-10],
        [5.3450e-11],
        [1.4903e-16],
        [2.6251e-13],
        [9.0662e-14],
        [1.2665e-14],
        [9.0914e-13],
        [1.0711e-13],
        [4.4600e-13],
        [1.0517e-12],
        [1.9654e-10],
        [6.4649e-15],
        [3.7591e-15],
        [1.0657e-13],
        [4.1528e-14],
        [1.4493e-15],
        [9.0809e-12],
        [3.6449e-14],
        [4.8739e-16],
        [1.8156e-12],
        [4.4261e-14],
        [1.3967e-10],
        [1.9965e-13],
        [1.5530e-11],
        [1.5938e-17],
        [3.7668e-10],
        [8.2233e-13],
        [3.3819e-15],
        [7.3713e-10],
        [9.3989e-10],
        [2.5896e-13],
        [1.0845e-13],
        [3.0972e-13],
        [1.6799e-13],
        [2.5575e-10],
        [2.8082e-14],
        [4.0529e-14],
        [6.6613e-10],
        [1.0638e-09],
        [4.2383e-14],
        [1.6129e-13],
        [2.5801e-14],
        [1.6178e-13],
        [5.4051e-14],
        [2.3945e-15],
        [2.0576e-14],
        [3.6171e-13],
        [1.3815e-13],
        [2.8659e-10],
        [6.2387e-13],
        [1.8263e-16],
        [2.6503e-18],
        [8.3571e-11],
        [3.6315e-17],
        [1.5271e-16],
        [6.4629e-15],
        [8.2550e-11],
        [7.1720e-13],
        [1.2273e-15],
        [1.4751e-13],
        [1.6618e-13],
        [2.8381e-17],
        [7.1492e-13],
        [2.9240e-16],
        [4.5355e-14],
        [5.1282e-17],
        [2.0230e-12],
        [3.5074e-13],
        [4.5365e-10],
        [8.3778e-15],
        [4.9732e-14],
        [5.9110e-13],
        [1.3922e-15],
        [9.1988e-11],
        [5.8589e-12],
        [5.0904e-11],
        [8.3435e-13],
        [4.1330e-13],
        [4.8807e-13],
        [8.7085e-13],
        [4.4257e-13],
        [9.1349e-14],
        [2.2527e-12],
        [2.7985e-12],
        [1.3596e-11],
        [6.1097e-11],
        [3.8936e-15],
        [3.5127e-13],
        [6.0531e-13],
        [7.6907e-14],
        [1.1034e-09],
        [2.9958e-13],
        [4.9184e-13],
        [2.3806e-15],
        [7.3994e-10],
        [5.0607e-13],
        [1.7212e-13],
        [5.1637e-15],
        [1.4030e-17],
        [1.6393e-15],
        [2.6378e-10],
        [4.0491e-13],
        [5.7740e-11],
        [6.1916e-11],
        [2.4035e-17],
        [1.8565e-12],
        [1.0582e-12],
        [1.5636e-13],
        [2.3580e-13],
        [2.7191e-13],
        [4.3145e-14],
        [4.8307e-15],
        [1.1845e-16],
        [1.8921e-13],
        [2.6147e-13],
        [2.6832e-14],
        [1.4267e-17],
        [1.1685e-12],
        [4.9196e-17],
        [1.8709e-11],
        [4.2841e-13],
        [4.1052e-14],
        [1.1279e-10],
        [4.8348e-13],
        [1.2544e-17],
        [4.3099e-16],
        [9.6324e-13],
        [3.5478e-12],
        [2.1043e-14],
        [4.5264e-17],
        [4.8345e-13],
        [5.1019e-13],
        [5.9810e-13],
        [5.1060e-11],
        [2.3494e-14],
        [8.8292e-10],
        [3.1786e-10],
        [1.3734e-13],
        [1.4396e-11],
        [7.4007e-13],
        [1.1099e-12],
        [4.1802e-13],
        [5.2301e-13],
        [1.5202e-13],
        [1.6700e-13],
        [4.4296e-13],
        [5.7504e-11],
        [1.0935e-14],
        [7.3882e-13],
        [1.1750e-13],
        [2.8546e-13],
        [2.7969e-13],
        [5.1426e-14],
        [6.9676e-15],
        [4.6102e-15],
        [7.0327e-11],
        [4.9203e-14],
        [5.4017e-13],
        [3.7704e-12],
        [2.5819e-13],
        [5.4847e-13],
        [2.3167e-17],
        [1.8731e-17],
        [7.0776e-12],
        [1.1419e-17],
        [6.6847e-13],
        [5.1981e-11],
        [2.3242e-12],
        [4.5846e-10],
        [5.3238e-13],
        [3.6857e-13],
        [1.4929e-13],
        [1.0997e-16],
        [2.2939e-13],
        [2.6787e-15],
        [7.0259e-13],
        [2.1140e-14],
        [4.9076e-15],
        [7.5407e-13],
        [4.4419e-15],
        [1.2204e-13],
        [4.3062e-13],
        [2.5426e-14],
        [2.0585e-12],
        [4.9509e-15],
        [5.2271e-13],
        [2.1781e-13],
        [8.7873e-17],
        [7.1909e-14],
        [4.2205e-13],
        [5.5440e-15],
        [2.2537e-18],
        [1.2287e-16],
        [5.5745e-15],
        [9.6395e-15],
        [1.6501e-12],
        [7.3322e-15],
        [1.4505e-13],
        [5.2495e-15],
        [5.3345e-11],
        [4.1565e-13],
        [2.8640e-13],
        [6.3821e-11],
        [7.2284e-13],
        [1.0146e-12],
        [1.0577e-13],
        [7.4840e-13],
        [1.3980e-11],
        [2.0763e-13],
        [2.8171e-16],
        [5.3137e-13],
        [1.0061e-12],
        [1.0882e-14],
        [3.4253e-14],
        [2.9194e-15],
        [1.8017e-14],
        [7.8868e-13],
        [2.4827e-13],
        [7.2955e-13],
        [8.8805e-13],
        [2.6302e-13],
        [1.4641e-13],
        [1.2245e-14],
        [6.6310e-13],
        [2.4081e-16],
        [2.9313e-15],
        [1.0760e-17],
        [7.6704e-13],
        [4.5147e-17],
        [4.6187e-15],
        [8.8020e-18],
        [3.8247e-14],
        [8.6536e-13],
        [1.2578e-13],
        [1.7537e-16],
        [5.1825e-18],
        [3.6617e-13],
        [4.1411e-14],
        [6.4815e-17],
        [7.1613e-15],
        [4.3260e-13],
        [3.7062e-14],
        [6.0683e-11],
        [2.8728e-15],
        [1.4380e-13],
        [5.2381e-13],
        [1.3213e-16],
        [1.6109e-13],
        [1.7835e-18],
        [4.7852e-13],
        [4.2625e-15],
        [8.4204e-12],
        [3.2588e-14],
        [4.0841e-13],
        [4.8306e-13],
        [9.4966e-18],
        [1.9580e-13],
        [1.2868e-14],
        [8.9685e-15],
        [7.1725e-15],
        [3.0272e-13],
        [2.9383e-13],
        [3.1718e-13],
        [4.3676e-14],
        [1.4866e-13],
        [6.9829e-12],
        [8.8743e-13],
        [2.9987e-14],
        [3.2694e-13],
        [2.0255e-12],
        [1.3460e-13],
        [7.3007e-15],
        [3.9329e-13],
        [3.2071e-13],
        [2.3713e-12],
        [1.0874e-12],
        [1.5088e-15],
        [9.8404e-14],
        [3.4962e-17],
        [6.1488e-13],
        [2.0542e-14],
        [5.2755e-13],
        [6.3590e-13],
        [1.9328e-12],
        [1.5490e-16],
        [3.5617e-13],
        [2.9341e-14],
        [2.5417e-13],
        [1.6551e-13],
        [5.0444e-13],
        [9.5424e-18],
        [1.1446e-15],
        [2.7590e-15],
        [3.9715e-15],
        [8.9042e-17],
        [7.9251e-11],
        [2.8235e-13],
        [1.4293e-10],
        [5.6969e-10],
        [2.9108e-16],
        [1.3803e-16],
        [1.6575e-13],
        [7.1209e-11],
        [7.6659e-13],
        [1.1057e-17],
        [2.2653e-18],
        [2.7656e-15],
        [8.5991e-10],
        [4.7964e-17],
        [1.0033e-13],
        [1.2149e-13],
        [3.1167e-10],
        [6.1917e-13],
        [6.5446e-11],
        [4.4457e-13],
        [4.9403e-13],
        [5.5325e-13],
        [1.9195e-10],
        [1.9995e-13],
        [2.0658e-12],
        [1.9642e-11],
        [1.2978e-10],
        [4.4126e-17],
        [2.9533e-13],
        [1.2946e-13],
        [1.4849e-18],
        [1.1659e-12],
        [1.9512e-14],
        [4.1832e-15],
        [1.1581e-11],
        [1.7418e-16],
        [1.3476e-11],
        [6.8612e-18],
        [4.9950e-10],
        [2.5594e-17],
        [4.5022e-13],
        [7.2781e-18],
        [6.4509e-11],
        [6.9220e-15],
        [2.1506e-13],
        [1.2127e-13],
        [1.0195e-13],
        [2.1290e-12],
        [1.6603e-13],
        [3.0008e-13],
        [1.2716e-12],
        [4.3081e-14],
        [2.7141e-12],
        [3.9940e-13],
        [7.5916e-18],
        [1.6377e-15],
        [4.5228e-13],
        [5.8787e-13],
        [3.9658e-13],
        [6.4865e-13],
        [5.2471e-13],
        [1.9827e-13],
        [2.8228e-14],
        [4.4321e-11],
        [4.4594e-13],
        [1.3611e-13],
        [1.0646e-16],
        [2.0817e-13],
        [3.9558e-13],
        [2.5089e-17],
        [2.0321e-15],
        [4.3620e-10],
        [4.9605e-11],
        [6.4302e-13],
        [6.2566e-15],
        [4.3850e-13],
        [3.6666e-11],
        [1.7034e-13],
        [2.1542e-14],
        [2.4959e-13],
        [1.5922e-15],
        [4.9452e-13],
        [1.9518e-17],
        [1.1176e-16],
        [2.9838e-17],
        [1.0382e-13],
        [4.1744e-18],
        [1.7077e-12],
        [2.1686e-13],
        [2.7998e-13],
        [4.5072e-13],
        [3.1459e-15],
        [2.2196e-13],
        [7.1546e-17],
        [1.6687e-14],
        [2.7017e-12],
        [1.0798e-09],
        [6.5639e-11],
        [2.3302e-13],
        [3.6265e-14],
        [1.2624e-09],
        [1.0611e-14],
        [3.9152e-14],
        [4.8774e-13],
        [2.3040e-15],
        [5.9323e-12],
        [1.5701e-14],
        [1.7210e-15],
        [8.7035e-12],
        [1.9942e-14],
        [3.3290e-17],
        [7.2482e-10],
        [4.7952e-13],
        [1.4784e-17],
        [2.0069e-10],
        [6.9370e-15],
        [1.0649e-12],
        [1.0183e-13],
        [2.7526e-14],
        [1.1203e-11],
        [5.7972e-15],
        [4.5849e-14],
        [1.8052e-13],
        [7.3249e-18],
        [2.4824e-10],
        [5.2454e-11],
        [1.5618e-17],
        [8.1463e-13],
        [5.7717e-13],
        [1.8018e-13],
        [5.5421e-15],
        [7.8010e-10],
        [2.0909e-12],
        [8.7984e-13],
        [5.4929e-13],
        [1.4489e-12],
        [7.1065e-14],
        [2.7562e-15],
        [1.2423e-12],
        [7.7395e-13],
        [8.0583e-13],
        [7.1407e-13],
        [7.5063e-11],
        [2.7535e-13],
        [3.4218e-13],
        [9.5072e-13],
        [1.9352e-10],
        [1.5720e-13],
        [1.1964e-11],
        [5.2565e-14],
        [1.0433e-18],
        [3.4553e-13],
        [1.4573e-11],
        [1.4310e-12],
        [4.6407e-13],
        [7.1040e-18],
        [5.6021e-17],
        [8.6342e-10],
        [1.1950e-13],
        [7.1944e-18],
        [4.3221e-15],
        [1.4167e-14],
        [3.8245e-15],
        [5.3403e-13],
        [1.1810e-14],
        [1.6371e-12],
        [1.4110e-14],
        [5.0717e-11],
        [8.8306e-17],
        [1.7828e-13],
        [1.4457e-14],
        [1.8765e-13],
        [1.2518e-14],
        [4.1351e-11],
        [6.2942e-13],
        [2.4864e-13],
        [9.0972e-13],
        [2.0012e-16],
        [4.8840e-15],
        [2.6838e-15],
        [3.8518e-13],
        [1.4380e-15],
        [1.4231e-12],
        [6.3674e-13],
        [7.4056e-13],
        [3.7167e-11],
        [3.3622e-10],
        [6.0109e-14],
        [5.5116e-13],
        [1.2553e-11],
        [6.5885e-10],
        [8.3332e-16],
        [1.4708e-11],
        [7.2841e-13],
        [6.0039e-15],
        [5.4067e-13],
        [1.7441e-13],
        [7.8008e-11],
        [2.4197e-14],
        [1.6721e-10],
        [2.5572e-14],
        [1.1772e-16],
        [1.2539e-13],
        [3.1941e-14],
        [6.7285e-14],
        [1.2001e-13],
        [3.6308e-13],
        [6.5864e-13],
        [4.2135e-14],
        [2.2972e-13],
        [2.5146e-13],
        [1.0924e-17],
        [2.4361e-12],
        [9.4802e-13],
        [2.1763e-12],
        [8.1174e-10],
        [1.1059e-13],
        [1.0744e-15],
        [7.0052e-13],
        [2.4019e-16],
        [8.2432e-13],
        [2.3196e-10],
        [1.5666e-13],
        [9.3286e-13],
        [4.4593e-11],
        [1.7893e-16],
        [7.0689e-14],
        [2.0465e-12],
        [4.2306e-15],
        [2.8368e-13],
        [4.0392e-17],
        [1.0712e-16],
        [4.5586e-10],
        [1.0289e-13],
        [6.8710e-10],
        [1.0118e-09],
        [9.5896e-14],
        [1.6298e-13],
        [6.4569e-13],
        [4.9027e-13],
        [4.2221e-13],
        [6.4880e-17],
        [2.6067e-14],
        [6.1071e-11],
        [7.1745e-11],
        [2.2130e-18],
        [8.9652e-10],
        [3.7535e-14],
        [3.2574e-13],
        [8.3943e-13],
        [4.6521e-14],
        [1.3585e-11],
        [1.5873e-13],
        [1.0130e-12],
        [3.6615e-13],
        [1.8801e-17],
        [1.3231e-14],
        [3.2036e-13],
        [1.1004e-14],
        [6.0365e-13],
        [2.1835e-13],
        [4.3745e-18],
        [1.7977e-17],
        [2.2860e-13],
        [3.6138e-15],
        [7.0194e-15],
        [2.0395e-14],
        [7.3254e-13],
        [1.0919e-14],
        [6.4757e-13],
        [3.6035e-10],
        [4.4753e-12],
        [3.9426e-13],
        [7.6674e-13],
        [5.7163e-13],
        [7.6533e-10],
        [4.3347e-18],
        [4.0391e-14],
        [3.7094e-18],
        [1.9357e-14],
        [5.0558e-10],
        [1.3284e-13],
        [5.1012e-13],
        [3.3527e-15],
        [8.2853e-13],
        [2.7032e-13],
        [6.3225e-13],
        [1.5283e-13],
        [7.0414e-12],
        [3.8451e-10],
        [3.6032e-16],
        [4.5427e-13],
        [1.6633e-14],
        [6.9146e-13],
        [9.9077e-14],
        [5.8570e-15],
        [5.5344e-11],
        [8.2523e-15],
        [2.1478e-10],
        [3.1949e-10],
        [1.4359e-13],
        [1.2035e-09],
        [3.3099e-16],
        [1.0102e-10],
        [2.2978e-12],
        [6.3366e-13],
        [3.6799e-14],
        [2.1712e-13],
        [6.2671e-16],
        [2.8688e-13],
        [1.1630e-16],
        [6.3749e-11],
        [6.7591e-13],
        [5.0970e-14],
        [1.1401e-17],
        [3.0008e-13],
        [5.5801e-15],
        [5.3730e-13],
        [1.0609e-15],
        [4.4311e-16],
        [1.3023e-13],
        [3.4278e-17],
        [1.6674e-14],
        [1.9087e-10],
        [1.7677e-13],
        [2.0483e-13],
        [3.8075e-14],
        [8.2257e-13],
        [2.7427e-13],
        [3.4912e-10],
        [5.3345e-13],
        [1.0423e-10],
        [4.5321e-13],
        [3.7732e-13],
        [4.4689e-13],
        [1.2673e-13],
        [3.5535e-11],
        [2.6598e-15],
        [1.1176e-12],
        [2.4714e-14],
        [4.5237e-13],
        [6.8793e-13],
        [2.6338e-15],
        [7.2197e-12],
        [2.5449e-13],
        [5.2723e-17],
        [9.9273e-17],
        [5.4419e-15],
        [2.6928e-14],
        [2.5868e-14],
        [1.3432e-15],
        [1.9209e-12],
        [3.6538e-13],
        [2.2712e-13],
        [5.6938e-11],
        [6.9776e-13],
        [2.5884e-14],
        [1.9507e-13],
        [5.3816e-13],
        [8.1895e-17],
        [1.0776e-14],
        [2.8227e-13],
        [2.0230e-14],
        [2.6228e-15],
        [1.6450e-13],
        [2.5315e-17],
        [3.7804e-14],
        [1.1003e-12],
        [9.2269e-13],
        [1.0449e-13],
        [2.5841e-15],
        [1.7465e-11],
        [1.0099e-12],
        [1.1933e-16],
        [4.2598e-13],
        [3.0292e-13],
        [4.9691e-11],
        [7.7880e-10],
        [1.9875e-13],
        [9.2416e-15],
        [1.6296e-15],
        [1.2513e-14],
        [5.9631e-13],
        [1.2240e-14],
        [6.5550e-12],
        [6.6405e-11],
        [3.3605e-14],
        [1.4878e-17],
        [8.1609e-14],
        [1.9413e-13],
        [6.5181e-10],
        [8.2078e-13],
        [2.3452e-14],
        [4.6015e-10],
        [1.4486e-15],
        [3.9238e-17],
        [6.6813e-13],
        [2.6309e-15],
        [6.6629e-12],
        [1.6019e-13],
        [2.0833e-10],
        [5.1294e-13],
        [2.4895e-12],
        [3.8782e-13],
        [1.2801e-13],
        [8.4433e-13],
        [2.2485e-13],
        [1.5863e-16],
        [1.0348e-12],
        [5.4574e-11],
        [1.1340e-14],
        [7.9107e-15],
        [5.0163e-15],
        [4.4877e-15],
        [2.7497e-10],
        [5.1541e-13],
        [1.7987e-14],
        [4.4279e-11],
        [1.5189e-14],
        [5.1090e-13],
        [3.1628e-11],
        [1.0387e-16],
        [3.8019e-13],
        [3.9754e-15],
        [5.3289e-18],
        [5.6687e-17],
        [1.1036e-12],
        [7.0882e-13],
        [5.7830e-11],
        [2.4230e-10],
        [3.3237e-13],
        [2.7891e-12],
        [5.1202e-18],
        [3.3661e-13],
        [1.9669e-13],
        [3.0377e-10],
        [4.3569e-15],
        [4.1453e-17],
        [2.1895e-14],
        [6.5582e-13],
        [8.1309e-13],
        [5.8816e-18],
        [5.0291e-13],
        [1.0904e-14],
        [4.9963e-14],
        [1.6471e-18],
        [3.6774e-14],
        [9.1243e-17],
        [5.0695e-14],
        [5.3400e-11],
        [5.5194e-11],
        [5.2684e-10],
        [1.7890e-13],
        [3.8684e-14],
        [3.2038e-14],
        [3.1422e-18],
        [6.2334e-14],
        [2.9615e-15],
        [1.0754e-10],
        [1.2852e-14],
        [5.0493e-16],
        [2.8128e-13],
        [4.1118e-14],
        [1.4380e-13],
        [1.7846e-14],
        [3.1086e-12],
        [4.4246e-10],
        [1.6434e-12],
        [2.4711e-17],
        [8.6190e-13],
        [5.2815e-13],
        [1.2077e-11],
        [3.0517e-13],
        [7.3216e-17],
        [2.8365e-14],
        [1.0221e-09],
        [1.6410e-14],
        [3.6340e-17],
        [2.9608e-13],
        [3.4464e-13],
        [7.2127e-10],
        [1.2242e-13],
        [6.2060e-13],
        [4.4485e-17],
        [9.7523e-17],
        [2.2619e-14],
        [2.9733e-12],
        [9.4536e-15],
        [5.0820e-13],
        [1.2280e-13],
        [9.6496e-13],
        [4.4836e-13],
        [1.7480e-10],
        [2.8580e-14],
        [5.2126e-13],
        [1.2811e-13],
        [3.1365e-15],
        [4.4988e-13],
        [5.6029e-13],
        [4.2981e-14],
        [4.0588e-15],
        [3.4088e-17],
        [1.1288e-14],
        [2.4220e-14],
        [5.0239e-13],
        [2.7933e-14],
        [2.3658e-13],
        [2.5251e-16],
        [1.7084e-10],
        [4.1441e-14],
        [1.9869e-12],
        [4.0055e-12],
        [6.4453e-13],
        [5.7389e-13],
        [5.0042e-14],
        [1.8767e-13],
        [4.2180e-11],
        [2.5920e-15],
        [1.6103e-17],
        [5.0388e-10],
        [5.2635e-15],
        [6.6661e-17],
        [7.2267e-15],
        [7.8309e-18],
        [4.3184e-13],
        [8.8636e-10],
        [4.0119e-13],
        [6.1155e-14],
        [1.8321e-13],
        [3.5917e-14],
        [1.1197e-09],
        [7.3380e-13],
        [1.4738e-17],
        [3.0472e-10],
        [1.4965e-10],
        [2.5522e-14],
        [4.8848e-13],
        [8.9882e-11],
        [1.4056e-11],
        [1.2846e-12],
        [5.2094e-13],
        [5.8891e-13],
        [6.9768e-17],
        [1.0261e-13],
        [2.2592e-13],
        [1.3394e-14],
        [1.8617e-14],
        [7.0916e-14],
        [5.1298e-13],
        [5.5516e-13],
        [4.2308e-14],
        [4.5160e-13],
        [2.2366e-15],
        [5.8399e-13],
        [2.7905e-15],
        [2.2900e-13],
        [7.7781e-13],
        [7.8043e-15],
        [2.5618e-13],
        [4.3492e-11],
        [5.5653e-17],
        [3.6643e-13],
        [3.2707e-15],
        [9.8293e-12],
        [4.9285e-14],
        [8.4019e-13],
        [2.6673e-15],
        [3.3500e-13],
        [2.1571e-17],
        [3.7530e-17],
        [2.0672e-16],
        [3.8859e-13],
        [1.3758e-16],
        [1.7802e-13],
        [2.9794e-16],
        [5.3762e-13],
        [5.7813e-18],
        [8.1336e-15],
        [1.7683e-18],
        [3.5834e-14],
        [9.7588e-13],
        [1.3283e-12],
        [3.3953e-13],
        [8.4569e-13],
        [4.6607e-17],
        [1.7587e-12],
        [1.6112e-13],
        [7.4331e-13],
        [1.6256e-13],
        [6.6731e-14],
        [6.4045e-14],
        [1.8396e-10],
        [5.1204e-13],
        [4.4721e-10],
        [9.1901e-13],
        [1.1233e-12],
        [2.3910e-17],
        [6.4810e-13],
        [2.7364e-15],
        [2.8526e-11],
        [1.3327e-13],
        [4.7042e-10],
        [1.8923e-12],
        [4.6367e-14],
        [1.1471e-17],
        [2.0254e-17],
        [1.4452e-11],
        [2.5583e-13],
        [4.5984e-10],
        [4.6390e-13],
        [1.8561e-13],
        [2.4244e-18],
        [4.5275e-13],
        [8.0773e-12],
        [1.5006e-13],
        [3.5565e-14],
        [3.3603e-18],
        [4.3149e-13],
        [4.7845e-13],
        [3.2327e-17],
        [9.2919e-13],
        [6.2893e-13],
        [1.6973e-10],
        [4.0301e-14],
        [4.6354e-13],
        [6.0098e-14],
        [5.0365e-13],
        [3.0888e-13],
        [3.4490e-13],
        [2.9673e-14],
        [1.1541e-13],
        [3.2026e-10],
        [7.4559e-13],
        [5.8551e-14],
        [3.2596e-13],
        [1.0377e-15],
        [2.5397e-13],
        [3.1027e-17],
        [7.3169e-13],
        [3.9688e-11],
        [1.1137e-15],
        [8.0462e-13],
        [5.7191e-15],
        [1.1107e-17],
        [1.3070e-11],
        [5.9008e-10],
        [5.2465e-18],
        [3.8060e-13],
        [7.6119e-11]], grad_fn=<SoftplusBackward>)
  4%|███████▌                                                                                                                                                                                                        | 18/496 [00:03<01:44,  4.57it/s]
Traceback (most recent call last):
  File "main.py", line 126, in <module>
    main()
  File "main.py", line 122, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 84, in train
    loss.backward() # required_graph = True
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/autograd/__init__.py", line 145, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt