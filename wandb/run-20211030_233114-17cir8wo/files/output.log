
CUDA availability: True
  0%|                                                                                                                                                                                       | 0/496 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "main.py", line 125, in <module>
    main()
  File "main.py", line 121, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 82, in train
    print("#### grad:", model.b_net.weights.grad)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 947, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'Sequential' object has no attribute 'weights'
#### mat_b tensor([[[ 1.3503e-01, -8.9852e-02, -8.7391e-02,  1.8040e-01,  3.1051e-01,
           6.5353e-02, -9.4811e-02, -1.1960e-01,  6.7022e-01,  5.4214e-01,
          -3.9019e-01,  4.4780e-02,  3.9803e-01,  1.4410e-01,  5.7923e-01,
          -1.2421e-01,  6.4573e-02,  3.3251e-01,  2.5354e-01, -3.4376e-01,
          -4.3481e-01, -2.0328e-01,  3.1078e-01,  1.7634e-03, -8.6438e-02,
           1.4631e-02,  1.4118e-01,  3.7990e-01,  1.9662e-01, -1.0945e-01,
          -7.7468e-02, -5.7292e-01],
         [ 1.4299e-01, -1.1713e-01, -1.2299e-01,  2.8993e-01,  3.3589e-01,
           3.6345e-02, -7.3493e-02, -2.0295e-01,  7.1790e-01,  5.5939e-01,
          -4.4695e-01,  3.0960e-02,  4.0754e-01,  1.6981e-01,  5.6907e-01,
          -8.4259e-02,  9.9048e-02,  4.0354e-01,  2.1865e-01, -3.3387e-01,
          -4.2300e-01, -2.6779e-01,  2.1543e-01, -2.7118e-02, -3.8373e-02,
           4.7375e-04,  2.2929e-01,  3.4286e-01,  1.6330e-01, -1.2767e-01,
          -1.0306e-01, -5.6459e-01],
         [ 1.3503e-01, -8.9852e-02, -8.7391e-02,  1.8040e-01,  3.1051e-01,
           6.5353e-02, -9.4811e-02, -1.1960e-01,  6.7022e-01,  5.4214e-01,
          -3.9019e-01,  4.4780e-02,  3.9803e-01,  1.4410e-01,  5.7923e-01,
          -1.2421e-01,  6.4573e-02,  3.3251e-01,  2.5354e-01, -3.4376e-01,
          -4.3481e-01, -2.0328e-01,  3.1078e-01,  1.7634e-03, -8.6438e-02,
           1.4631e-02,  1.4118e-01,  3.7990e-01,  1.9662e-01, -1.0945e-01,
          -7.7468e-02, -5.7292e-01],
         [ 1.3207e-01, -1.1411e-01, -1.1330e-01,  2.7944e-01,  3.3764e-01,
           4.2551e-02, -6.7903e-02, -2.0533e-01,  7.0575e-01,  5.5397e-01,
          -4.4383e-01,  3.7234e-02,  4.1557e-01,  1.6700e-01,  5.5632e-01,
          -9.6680e-02,  1.0182e-01,  3.9105e-01,  2.1891e-01, -3.2250e-01,
          -4.3256e-01, -2.5247e-01,  2.2363e-01, -3.3200e-02, -3.4853e-02,
           7.2585e-03,  2.4464e-01,  3.5200e-01,  1.7143e-01, -1.3310e-01,
          -9.6560e-02, -5.7624e-01],
         [ 1.3035e-01, -1.1126e-01, -1.0920e-01,  2.6840e-01,  3.3540e-01,
           4.5932e-02, -6.9366e-02, -1.9766e-01,  7.0014e-01,  5.5196e-01,
          -4.3832e-01,  3.9160e-02,  4.1532e-01,  1.6439e-01,  5.5606e-01,
          -1.0169e-01,  9.8860e-02,  3.8335e-01,  2.2242e-01, -3.2225e-01,
          -4.3474e-01, -2.4497e-01,  2.3319e-01, -3.0895e-02, -3.8949e-02,
           9.2187e-03,  2.3783e-01,  3.5617e-01,  1.7517e-01, -1.3177e-01,
          -9.3628e-02, -5.7810e-01],
         [ 1.3503e-01, -8.9852e-02, -8.7391e-02,  1.8040e-01,  3.1051e-01,
           6.5353e-02, -9.4811e-02, -1.1960e-01,  6.7022e-01,  5.4214e-01,
          -3.9019e-01,  4.4780e-02,  3.9803e-01,  1.4410e-01,  5.7923e-01,
          -1.2421e-01,  6.4573e-02,  3.3251e-01,  2.5354e-01, -3.4376e-01,
          -4.3481e-01, -2.0328e-01,  3.1078e-01,  1.7634e-03, -8.6438e-02,
           1.4631e-02,  1.4118e-01,  3.7990e-01,  1.9662e-01, -1.0945e-01,
          -7.7468e-02, -5.7292e-01],
         [ 1.3503e-01, -8.9852e-02, -8.7391e-02,  1.8040e-01,  3.1051e-01,
           6.5353e-02, -9.4811e-02, -1.1960e-01,  6.7022e-01,  5.4214e-01,
          -3.9019e-01,  4.4780e-02,  3.9803e-01,  1.4410e-01,  5.7923e-01,
          -1.2421e-01,  6.4573e-02,  3.3251e-01,  2.5354e-01, -3.4376e-01,
          -4.3481e-01, -2.0328e-01,  3.1078e-01,  1.7634e-03, -8.6438e-02,
           1.4631e-02,  1.4118e-01,  3.7990e-01,  1.9662e-01, -1.0945e-01,
          -7.7468e-02, -5.7292e-01],
         [ 1.3503e-01, -8.9852e-02, -8.7391e-02,  1.8040e-01,  3.1051e-01,
           6.5353e-02, -9.4811e-02, -1.1960e-01,  6.7022e-01,  5.4214e-01,
          -3.9019e-01,  4.4780e-02,  3.9803e-01,  1.4410e-01,  5.7923e-01,
          -1.2421e-01,  6.4573e-02,  3.3251e-01,  2.5354e-01, -3.4376e-01,
          -4.3481e-01, -2.0328e-01,  3.1078e-01,  1.7634e-03, -8.6438e-02,
           1.4631e-02,  1.4118e-01,  3.7990e-01,  1.9662e-01, -1.0945e-01,
          -7.7468e-02, -5.7292e-01],
         [ 1.2919e-01, -1.0253e-01, -9.5933e-02,  2.2924e-01,  3.2998e-01,
           5.8037e-02, -7.3650e-02, -1.7082e-01,  6.8601e-01,  5.4636e-01,
          -4.2040e-01,  4.3306e-02,  4.1663e-01,  1.5448e-01,  5.5561e-01,
          -1.1771e-01,  9.1968e-02,  3.6486e-01,  2.3239e-01, -3.2314e-01,
          -4.3933e-01, -2.2322e-01,  2.6481e-01, -2.0067e-02, -5.4168e-02,
           1.2260e-02,  2.1199e-01,  3.6913e-01,  1.8654e-01, -1.3024e-01,
          -8.7320e-02, -5.8193e-01],
         [ 1.3144e-01, -8.8870e-02, -8.8436e-02,  1.8236e-01,  3.0643e-01,
           6.3703e-02, -9.7403e-02, -1.1881e-01,  6.6607e-01,  5.4134e-01,
          -3.8878e-01,  4.6343e-02,  3.9262e-01,  1.4557e-01,  5.8267e-01,
          -1.2354e-01,  5.8624e-02,  3.2410e-01,  2.5679e-01, -3.4527e-01,
          -4.3569e-01, -2.0096e-01,  3.1198e-01, -3.2756e-04, -8.7482e-02,
           1.7673e-02,  1.3877e-01,  3.8021e-01,  1.9715e-01, -1.0448e-01,
          -7.3744e-02, -5.7325e-01],
         [ 1.3292e-01, -8.9277e-02, -8.8004e-02,  1.8156e-01,  3.0811e-01,
           6.4380e-02, -9.6333e-02, -1.1914e-01,  6.6778e-01,  5.4167e-01,
          -3.8936e-01,  4.5697e-02,  3.9486e-01,  1.4496e-01,  5.8125e-01,
          -1.2381e-01,  6.1078e-02,  3.2757e-01,  2.5545e-01, -3.4465e-01,
          -4.3533e-01, -2.0192e-01,  3.1148e-01,  5.3450e-04, -8.7049e-02,
           1.6418e-02,  1.3977e-01,  3.8008e-01,  1.9693e-01, -1.0653e-01,
          -7.5280e-02, -5.7311e-01],
         [ 1.3224e-01, -8.9091e-02, -8.8201e-02,  1.8192e-01,  3.0734e-01,
           6.4071e-02, -9.6821e-02, -1.1899e-01,  6.6700e-01,  5.4152e-01,
          -3.8910e-01,  4.5992e-02,  3.9384e-01,  1.4524e-01,  5.8190e-01,
          -1.2369e-01,  5.9958e-02,  3.2599e-01,  2.5606e-01, -3.4493e-01,
          -4.3550e-01, -2.0148e-01,  3.1171e-01,  1.4108e-04, -8.7247e-02,
           1.6991e-02,  1.3931e-01,  3.8014e-01,  1.9703e-01, -1.0559e-01,
          -7.4579e-02, -5.7317e-01],
         [ 1.3186e-01, -8.8987e-02, -8.8312e-02,  1.8213e-01,  3.0691e-01,
           6.3897e-02, -9.7096e-02, -1.1890e-01,  6.6656e-01,  5.4144e-01,
          -3.8895e-01,  4.6158e-02,  3.9326e-01,  1.4539e-01,  5.8226e-01,
          -1.2361e-01,  5.9326e-02,  3.2509e-01,  2.5640e-01, -3.4509e-01,
          -4.3559e-01, -2.0123e-01,  3.1184e-01, -8.1073e-05, -8.7358e-02,
           1.7314e-02,  1.3906e-01,  3.8017e-01,  1.9709e-01, -1.0506e-01,
          -7.4184e-02, -5.7321e-01],
         [ 1.3387e-01, -6.7746e-02, -5.8114e-02,  8.1963e-02,  2.9050e-01,
           9.0037e-02, -1.1454e-01, -4.9067e-02,  6.3633e-01,  5.2845e-01,
          -3.4235e-01,  5.2611e-02,  3.9083e-01,  1.2014e-01,  5.9161e-01,
          -1.5516e-01,  3.6864e-02,  2.7965e-01,  2.8063e-01, -3.5761e-01,
          -4.3911e-01, -1.5322e-01,  3.9398e-01,  2.7107e-02, -1.3255e-01,
           2.1929e-02,  6.0093e-02,  4.1195e-01,  2.2459e-01, -9.7519e-02,
          -5.9495e-02, -5.7701e-01]]], grad_fn=<AddBackward0>) torch.Size([1, 14, 32])