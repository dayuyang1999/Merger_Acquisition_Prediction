
CUDA availability: True
batch number:  0
#### arr_b tensor([[[ 2.3377,  0.3885, -0.1004, -0.3454, -0.3454, -0.3454, -0.3454,
          -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454],
         [ 2.5483,  0.5025, -0.2912, -0.3454, -0.3454, -0.3454, -0.3454,
          -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454],
         [ 2.9324,  0.4868, -0.2853, -0.3454, -0.3454, -0.3454, -0.3454,
          -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454],
         [ 3.4636,  0.5199, -0.2864, -0.3454, -0.3454, -0.3454, -0.3454,
          -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454],
         [ 3.9420,  0.5391, -0.2616, -0.3454, -0.3454, -0.3454, -0.3454,
          -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454],
         [ 2.9595,  0.4217, -0.1004, -0.3454, -0.3454, -0.3454, -0.3454,
          -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454],
         [ 2.9595,  0.4217, -0.1004, -0.3454, -0.3454, -0.3454, -0.3454,
          -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454],
         [ 2.9595,  0.4217, -0.1004, -0.3454, -0.3454, -0.3454, -0.3454,
          -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454],
         [ 4.9210,  0.7784, -0.2412, -0.3454, -0.3454, -0.3454, -0.3454,
          -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454],
         [ 2.9595,  0.4217, -0.1004, -0.3454, -0.3454, -0.3454, -0.3454,
          -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454],
         [ 4.8315,  0.6861,  0.1330, -0.3454, -0.3454, -0.3454, -0.3454,
          -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454],
         [ 4.6289,  0.6416,  0.1774, -0.3454, -0.3454, -0.3454, -0.3454,
          -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454],
         [ 2.9595,  0.4217, -0.1004, -0.3454, -0.3454, -0.3454, -0.3454,
          -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454, -0.3454]]]) torch.Size([1, 13, 14])
#### mat_b tensor([[[-0.0405,  0.0551, -0.2674,  0.4066,  0.1237,  0.0330, -0.2309,
          -0.4389, -0.2721, -0.1617, -0.0408,  0.1128, -0.1093,  0.1812,
           0.1101, -0.0264,  0.2183,  0.1311, -0.1084, -0.0106,  0.3032,
          -0.0814, -0.3191,  0.0956,  0.1142,  0.0593,  0.1822,  0.2013,
           0.2152,  0.3085, -0.0764,  0.0028],
         [-0.0327, -0.0439, -0.1158,  0.3446, -0.0467, -0.1535, -0.0680,
          -0.5875, -0.1642, -0.1614,  0.3280,  0.1046, -0.1362,  0.0551,
           0.2688, -0.2764,  0.3654, -0.1503,  0.0786,  0.1507,  0.1259,
          -0.0368, -0.2153,  0.0544, -0.0681,  0.0564,  0.2846,  0.1740,
           0.2809,  0.1451, -0.0935, -0.0459],
         [ 0.0694,  0.0166,  0.0363,  0.3821, -0.1984, -0.0735, -0.0967,
          -0.5627, -0.0175,  0.1787,  0.1601, -0.1460,  0.0087,  0.3037,
           0.6260, -0.2767,  0.5286, -0.0612,  0.2365, -0.1631, -0.1023,
           0.0711, -0.1596,  0.1573,  0.0322,  0.3439,  0.2031,  0.0151,
           0.1633, -0.0056, -0.0416, -0.4264],
         [-0.1236,  0.1481,  0.2350,  0.2919,  0.1047, -0.1933,  0.1715,
          -0.9340,  0.0162,  0.1080,  0.2707,  0.1780,  0.0837, -0.0824,
           0.4760, -0.4746,  0.4150, -0.0168, -0.1872, -0.0468, -0.1018,
           0.0735, -0.3381,  0.1797,  0.1368,  0.3180,  0.0203, -0.0035,
           0.3103, -0.0570, -0.0617,  0.0305],
         [ 0.2582,  0.0918, -0.0019,  0.2593, -0.3938, -0.0853, -0.1381,
          -0.8635,  0.3467, -0.1227,  0.0578, -0.0547, -0.1199, -0.0191,
           0.3619, -0.1204,  0.5281,  0.0529, -0.1861,  0.1157, -0.0212,
           0.2197, -0.7505,  0.0247,  0.0416,  0.3966,  0.1588,  0.4139,
           0.4978, -0.0165,  0.0529, -0.2674],
         [ 0.0248,  0.2423,  0.1085,  0.3547, -0.1878, -0.1518, -0.0034,
          -0.8739,  0.1800, -0.1452,  0.3085,  0.1342, -0.2252,  0.0226,
           0.5024, -0.2974,  0.3847,  0.0143, -0.1260,  0.1602, -0.0598,
           0.0989, -0.5523,  0.0164,  0.1143,  0.2114,  0.0106,  0.1499,
           0.5714, -0.1560,  0.1739, -0.0716],
         [-0.1256,  0.1575, -0.0433,  0.5919,  0.0330,  0.2166,  0.0216,
          -0.7904, -0.0041, -0.0860,  0.0117,  0.0480, -0.0792,  0.2454,
           0.3696, -0.1394,  0.2473,  0.0429, -0.1884,  0.1171,  0.1166,
           0.1043, -0.2117,  0.2570,  0.0674,  0.0737,  0.0967,  0.0118,
           0.1537,  0.1631,  0.0366,  0.0849],
         [-0.1499, -0.1294,  0.0881,  0.5489,  0.1449, -0.0153,  0.0821,
          -0.5017, -0.1923,  0.0521,  0.3399,  0.0391,  0.1176,  0.3819,
           0.2503, -0.3768,  0.5845, -0.0147,  0.0861,  0.1586,  0.2448,
          -0.0758, -0.0525,  0.2496,  0.2051,  0.2801,  0.0223, -0.0845,
           0.1707, -0.0060, -0.1209, -0.2012],
         [-0.1095,  0.3688,  0.0431,  0.6103, -0.0623,  0.1329,  0.0362,
          -1.4500, -0.0872, -0.1512,  0.2019,  0.0211, -0.0779,  0.3078,
           0.7460, -0.2943,  0.4513, -0.1348, -0.1212, -0.0602, -0.2153,
           0.3423, -0.4357,  0.0039, -0.1259,  0.0307,  0.1284,  0.0443,
           0.4096,  0.1730, -0.3374,  0.0729],
         [-0.0283,  0.0163,  0.1115,  0.4927,  0.1192, -0.1841, -0.0511,
          -0.7216,  0.0374, -0.0693,  0.2518,  0.1327, -0.0345,  0.2407,
           0.4754, -0.4871,  0.6189, -0.1017,  0.0767,  0.0794,  0.0378,
           0.0797, -0.2625,  0.1017,  0.1700,  0.2218,  0.0610,  0.0863,
           0.3937,  0.0456, -0.1814, -0.1688],
         [-0.1547,  0.0327, -0.2105,  0.6258,  0.2168, -0.0025, -0.1403,
          -1.0842, -0.1753, -0.0941, -0.2067,  0.0792,  0.2002,  0.1250,
           0.0522,  0.1025,  0.3196,  0.0492, -0.2863,  0.1789,  0.4694,
           0.1003, -0.3580,  0.0027, -0.0434,  0.2433,  0.0843,  0.2160,
           0.1611,  0.6405, -0.5393,  0.2294],
         [-0.1326,  0.1711,  0.2634,  0.4489, -0.0241, -0.0277,  0.2190,
          -0.6117, -0.5283,  0.3251,  0.5264, -0.0412,  0.4247,  0.1698,
           0.5485, -0.3341,  0.5286,  0.0578,  0.1399,  0.0422, -0.0416,
          -0.1133,  0.0043,  0.5293,  0.2097,  0.0692,  0.3143, -0.2990,
          -0.0945, -0.0638,  0.0418, -0.1532],
         [-0.0988,  0.1007, -0.0219,  0.4232, -0.1115,  0.0984, -0.0287,
          -0.6159, -0.2672,  0.1064,  0.1567, -0.1612,  0.1492,  0.2317,
           0.3573, -0.0119,  0.4115, -0.0410,  0.0625,  0.0885,  0.1088,
          -0.0281, -0.1492,  0.2812, -0.0516,  0.0400,  0.1668, -0.1521,
           0.0898,  0.1128,  0.0152, -0.2790]]], grad_fn=<AddBackward0>) torch.Size([1, 13, 32])
batch number:  1
#### arr_b tensor([[[ 4.2813,  0.6045, -0.2607, -0.3513, -0.3513, -0.3513, -0.3513,
          -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513],
         [ 3.2198,  0.4776, -0.0866, -0.3513, -0.3513, -0.3513, -0.3513,
          -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513],
         [ 3.2198,  0.4776, -0.0866, -0.3513, -0.3513, -0.3513, -0.3513,
          -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513],
         [ 3.2198,  0.4776, -0.0866, -0.3513, -0.3513, -0.3513, -0.3513,
          -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513]]]) torch.Size([1, 4, 14])
#### mat_b tensor([[[ 0.1531,  0.5691, -0.4437,  0.3213,  0.2041, -0.3469,  0.0326,
          -1.6006, -0.3976,  0.0991,  0.3584, -0.2054, -0.4017, -0.0441,
           0.2364,  0.0488,  0.6814, -0.3794,  0.4157,  0.2370, -0.0761,
          -0.0851, -0.5866, -0.1874, -0.1957, -0.0658,  0.5158,  0.4091,
           0.1696,  0.1974, -0.6314,  0.4054],
         [ 0.3261,  0.4007, -0.4415,  0.1853,  0.2806, -0.2412, -0.1530,
          -1.0178, -0.4389, -0.1041,  0.1148, -0.1383, -0.2510, -0.0114,
           0.1471,  0.0620,  0.5762, -0.1180,  0.2440,  0.0269, -0.0210,
          -0.1856, -0.6621, -0.0304, -0.1437,  0.0238,  0.3332,  0.4492,
           0.0438,  0.0177, -0.5213,  0.2009],
         [ 0.4632,  0.1496, -0.3863,  0.2638,  0.3019, -0.0159,  0.2044,
          -0.7860, -0.2341, -0.0494,  0.3899, -0.0764, -0.2227,  0.1902,
           0.1389, -0.0802,  0.7926, -0.0973, -0.0358,  0.3179,  0.1255,
          -0.2527, -0.6151,  0.1276, -0.3163,  0.0635,  0.3870,  0.3779,
          -0.0045, -0.1283, -0.1735,  0.1064],
         [ 0.1650,  0.2350, -0.3219,  0.2446,  0.2437, -0.3745,  0.0821,
          -1.1197, -0.2882,  0.1071,  0.4262,  0.0378, -0.2722,  0.0752,
           0.4088, -0.0909,  0.7248, -0.2290,  0.3543,  0.1829, -0.1764,
          -0.1602, -0.5406, -0.1397,  0.0560,  0.0798,  0.3116,  0.3745,
           0.1383, -0.0286, -0.5133,  0.1964]]], grad_fn=<AddBackward0>) torch.Size([1, 4, 32])
batch number:  2
#### arr_b tensor([[[ 1.6107,  0.2177, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 1.8378,  0.2896, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 2.2109,  0.3706, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 2.5649,  0.4498, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 2.7934,  0.5735, -0.2877, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2103,  0.5564, -0.2813, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.7867,  0.5924, -0.2826, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 4.3058,  0.6133, -0.2556, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 5.3681,  0.8729, -0.2334, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 5.2710,  0.7727,  0.1726, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 5.0511,  0.7244,  0.2207, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 4.3120,  0.7036,  0.3016, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3324, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3956, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3668, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3505, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466]]]) torch.Size([1, 23, 14])
#### mat_b tensor([[[ 0.3149,  0.0889, -0.4884,  0.1501,  0.1287, -0.0575,  0.1403,
          -0.4675, -0.2684,  0.1621,  0.1885, -0.3410, -0.1689,  0.2351,
          -0.1447,  0.1430,  0.6118, -0.1535,  0.3216,  0.2671, -0.0148,
          -0.2943, -0.5914, -0.0428, -0.0966,  0.0526,  0.4554,  0.3958,
          -0.1864, -0.2115, -0.2790, -0.0300],
         [ 0.2596,  0.2662, -0.3504,  0.1684,  0.3170, -0.2294,  0.4112,
          -0.8294, -0.3675,  0.3155,  0.5328, -0.0841, -0.2083, -0.1054,
          -0.1095,  0.0057,  0.5751, -0.2519,  0.1408,  0.5027, -0.1108,
          -0.4021, -0.5497, -0.0902, -0.0354, -0.1201,  0.3920,  0.2721,
          -0.0522, -0.2782, -0.2591,  0.2615],
         [ 0.4890,  0.4711, -0.3709, -0.2019, -0.0171, -0.2525,  0.2203,
          -0.7178, -0.1719,  0.0056,  0.5013, -0.3331, -0.3385, -0.2861,
           0.0880,  0.2028,  0.6033, -0.2433,  0.2624,  0.2628, -0.3107,
          -0.0922, -0.6772, -0.1440, -0.4397, -0.3598,  0.6345,  0.2861,
          -0.0715, -0.2132, -0.1917,  0.2294],
         [ 0.6371,  0.5877, -0.5072, -0.1372,  0.2257, -0.3691,  0.1929,
          -0.9818, -0.3969,  0.2802,  0.4033, -0.4449, -0.1899, -0.1724,
           0.1052,  0.2607,  0.7599, -0.2975,  0.3279,  0.1920, -0.3991,
          -0.2445, -1.0106, -0.2224, -0.5426, -0.2800,  0.6515,  0.4821,
          -0.1212, -0.1839, -0.4994,  0.1652],
         [ 0.5202,  0.3581, -0.3578, -0.1848,  0.2046, -0.0491,  0.3020,
          -0.6798, -0.2788,  0.3831,  0.2617, -0.3468,  0.0081, -0.1065,
           0.1724,  0.0955,  0.6177, -0.1239,  0.2403, -0.1117, -0.4911,
          -0.1336, -0.6126, -0.1071, -0.3607, -0.2448,  0.5912,  0.1943,
          -0.3888, -0.0710, -0.5544,  0.2318],
         [ 0.4385,  0.6394, -0.6232, -0.0629,  0.3695, -0.5181,  0.3127,
          -1.2749, -0.2269,  0.2616,  0.4753, -0.4064, -0.5691, -0.3056,
          -0.2147,  0.2096,  0.9025, -0.3174,  0.3982,  0.3869, -0.2565,
          -0.3681, -1.0242, -0.1670, -0.4568, -0.0906,  0.6879,  0.7248,
           0.0659, -0.1447, -0.5696,  0.1752],
         [ 0.4632,  0.6000, -0.4361, -0.2768, -0.0663, -0.5228,  0.3325,
          -1.6573, -0.3164,  0.1610,  0.9417, -0.4695, -0.7037, -0.6345,
          -0.1688,  0.2116,  0.9140, -0.6349,  0.2421,  0.7439, -0.3835,
          -0.3287, -1.0375, -0.5072, -0.7081, -0.2668,  0.6335,  0.7948,
           0.1896, -0.4895, -0.3866,  0.4064],
         [ 0.5662,  0.5723, -0.5399,  0.1352, -0.0681, -0.4203,  0.0853,
          -1.3871, -0.2010,  0.4876,  0.6814, -0.7175, -0.6977,  0.0370,
           0.1265,  0.0988,  1.0778, -0.3466,  0.9505,  0.5429, -0.4868,
          -0.2571, -0.8205, -0.3053, -0.3364,  0.0435,  0.6670,  0.7393,
          -0.1506, -0.6506, -0.5466,  0.1930],
         [ 0.5791,  0.3724, -0.6715, -0.1096,  0.2359, -0.3379,  0.4297,
          -1.3040, -0.5123,  0.2423,  0.7760, -0.5118, -0.3122, -0.0183,
           0.0097,  0.2958,  1.1459, -0.3589,  0.6306,  0.3525, -0.4368,
          -0.5680, -1.0105, -0.2213, -0.4745, -0.0616,  0.5777,  0.6330,
          -0.2909, -0.3166, -0.8740,  0.0754],
         [ 0.4150,  0.3265, -0.3760,  0.1053,  0.0980, -0.2820,  0.3491,
          -1.1257, -0.3934,  0.3716,  0.7121, -0.4301, -0.2567, -0.1960,
          -0.1424,  0.3080,  0.8222, -0.2227,  0.4999,  0.8054, -0.1422,
          -0.5033, -0.8035, -0.1345, -0.1375, -0.1496,  0.3962,  0.5072,
          -0.2610, -0.5428, -0.4269,  0.2837],
         [ 0.3625,  0.2364, -0.3525,  0.1224,  0.5514, -0.5122,  0.3097,
          -1.3635, -0.5599,  0.4019,  0.5712, -0.0361, -0.1759, -0.3275,
          -0.0978,  0.2216,  0.5252, -0.4377,  0.4579,  0.3668, -0.2511,
          -0.3580, -0.6139, -0.5219, -0.2114, -0.1314,  0.3744,  0.4616,
          -0.1592, -0.0727, -1.0196,  0.7290],
         [ 0.1434,  0.6826, -0.6473,  0.1983,  0.8543, -0.6751,  0.7330,
          -1.8634, -0.8726,  0.8121,  1.0330, -0.3689, -0.3020, -0.2854,
          -0.3594,  0.1118,  1.2144, -0.6013,  0.6350,  0.8608, -0.0603,
          -0.4469, -0.6116, -0.4268, -0.3022, -0.3834,  0.9356,  0.4604,
          -0.2825,  0.0936, -1.0244,  1.0076],
         [ 0.5543,  0.6453, -0.4191, -0.0505,  0.0802, -0.5162,  0.2394,
          -1.3992, -0.6046,  0.4864,  0.5274, -0.6037, -0.1911, -0.3284,
           0.1314,  0.3802,  0.8090, -0.5849,  0.6414,  0.4875, -0.3990,
          -0.4377, -0.7922, -0.2359, -0.5015, -0.2541,  0.6948,  0.4499,
          -0.2219, -0.2755, -0.7250,  0.0043],
         [ 0.2132,  0.5394, -0.7196,  0.1974,  0.3740, -0.5102,  0.1873,
          -1.5951, -0.8320,  1.2177,  0.4766, -0.5618, -0.2596, -0.0615,
           0.4503,  0.1923,  1.0759, -0.5133,  0.6355,  0.4093, -0.4852,
          -0.2275, -0.7211, -0.3259, -0.1669, -0.3527,  0.9719,  0.5953,
          -0.3268,  0.0540, -0.5490,  0.1971],
         [ 0.5276,  0.5808, -0.7402, -0.0277,  0.0733, -0.7691,  0.6661,
          -2.4560, -0.3858,  0.9114,  1.1320, -0.8786, -0.7692, -0.4193,
           0.1853,  0.2624,  1.4325, -0.9417,  0.6738,  0.7389, -0.7922,
          -0.3439, -1.2236, -0.4750, -0.7672,  0.0991,  1.1192,  1.0997,
          -0.0544, -0.4658, -0.6675,  0.1942],
         [ 0.4328,  0.5367, -0.5921, -0.0840,  0.2654, -0.6031,  0.5370,
          -1.6140, -0.3580,  0.5181,  0.8335, -0.3800, -0.4618, -0.2966,
           0.0794,  0.1971,  1.0919, -0.5049,  0.4294,  0.5958, -0.5393,
          -0.4816, -1.1207, -0.2632, -0.3570, -0.1524,  0.5826,  0.6488,
           0.0055, -0.4363, -0.6027,  0.2350],
         [ 0.3639,  0.7196, -0.3259,  0.0710,  0.3345, -0.5660,  0.0832,
          -1.2836, -0.5051,  0.3699,  0.3143, -0.4618, -0.4091, -0.2841,
           0.0564,  0.1952,  0.7388, -0.5283,  0.6195,  0.3243, -0.3489,
          -0.3194, -0.7075, -0.3800, -0.2770, -0.2402,  0.6236,  0.4866,
          -0.0967, -0.1538, -0.6592,  0.3321],
         [ 0.4031,  0.4982, -0.4894, -0.0355,  0.3909, -0.4927,  0.4324,
          -1.6382, -0.4575,  0.4010,  0.7225, -0.4685, -0.3434, -0.3356,
           0.0776,  0.2611,  0.9548, -0.4272,  0.4007,  0.4508, -0.5409,
          -0.2485, -0.8025, -0.2953, -0.5343, -0.1048,  0.6285,  0.5924,
          -0.3286, -0.3350, -0.8781,  0.4653],
         [ 0.5777,  0.8222, -0.6991, -0.0514,  0.3133, -0.8744,  0.3520,
          -1.7714, -0.6742,  0.6597,  1.0040, -0.6912, -0.4233, -0.4662,
           0.3381,  0.5091,  1.2097, -0.5528,  0.7699,  0.5736, -0.7890,
          -0.3256, -1.0158, -0.0803, -0.7155, -0.4493,  0.9804,  0.6798,
          -0.2608, -0.2504, -0.8027,  0.2899],
         [ 0.4882,  0.2956, -0.3018, -0.1248,  0.1501, -0.3155,  0.2621,
          -0.9276, -0.3624,  0.0397,  0.7630, -0.2952, -0.3340, -0.1003,
          -0.1745, -0.1091,  0.9866, -0.4263,  0.6875,  0.6627, -0.1951,
          -0.5627, -0.6528, -0.3197, -0.3039, -0.2654,  0.3679,  0.3353,
          -0.1065, -0.6054, -0.6192,  0.2179],
         [ 0.4355,  0.5470, -0.2870,  0.0500,  0.5215, -0.4047,  0.3771,
          -1.6209, -0.5435,  0.3797,  0.5810, -0.2236, -0.2652, -0.3791,
          -0.0188,  0.1269,  0.7309, -0.5506,  0.4409,  0.4659, -0.4183,
          -0.3368, -0.6739, -0.4236, -0.4558, -0.2481,  0.5476,  0.4758,
          -0.1405, -0.2445, -0.8474,  0.4798],
         [ 0.4896,  0.6509, -0.4226, -0.0863,  0.0476, -0.6819,  0.4330,
          -1.4428, -0.3238,  0.7100,  0.6939, -0.4436, -0.3359, -0.5920,
           0.1376,  0.3225,  0.7265, -0.4680,  0.3871,  0.5013, -0.5716,
          -0.4104, -1.0709, -0.2430, -0.3824, -0.1815,  0.7165,  0.6330,
          -0.0665, -0.2748, -0.4640,  0.2005],
         [ 0.5877,  0.5174, -0.6858,  0.1037,  0.4273, -0.4554,  0.0770,
          -1.4357, -0.5938,  0.2115,  0.3467, -0.3350, -0.3977, -0.2100,
          -0.0839,  0.2720,  0.6489, -0.4008,  0.3860,  0.2886, -0.1051,
          -0.3230, -0.9890, -0.5082, -0.4545, -0.1172,  0.5177,  0.7419,
          -0.0211, -0.0364, -0.9322,  0.4439]]], grad_fn=<AddBackward0>) torch.Size([1, 23, 32])
batch number:  3
#### arr_b tensor([[[ 1.6416,  0.2271, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 1.8722,  0.3001, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.2511,  0.3824, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.6105,  0.4627, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.8426,  0.5884, -0.2861, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2659,  0.5711, -0.2796, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.8512,  0.6076, -0.2809, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 4.3783,  0.6288, -0.2535, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.4571,  0.8924, -0.2310, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.3584,  0.7907,  0.1813, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.1351,  0.7417,  0.2302, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 4.3846,  0.7205,  0.3123, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3435, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4078, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3785, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3619, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 1.5889,  0.3488, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459]]]) torch.Size([1, 24, 14])
#### mat_b tensor([[[ 0.5610,  0.5131, -0.5569, -0.0779,  0.2916, -0.1752,  0.2178,
          -0.8538, -0.4445,  0.1662,  0.4394, -0.2916, -0.4224, -0.2017,
          -0.2559,  0.3368,  0.6746, -0.1606,  0.2885,  0.6107, -0.1936,
          -0.4710, -0.8262, -0.2504, -0.2473, -0.3595,  0.5742,  0.5315,
          -0.2258, -0.4238, -0.3765,  0.3712],
         [ 0.7021,  0.5040, -0.4608, -0.2132, -0.0261, -0.2328,  0.1940,
          -0.9278, -0.2923,  0.4325,  0.4826, -0.3888, -0.4386, -0.3491,
           0.1037,  0.3033,  0.6142, -0.2504,  0.5539,  0.3908, -0.5078,
          -0.4154, -0.7828, -0.3308, -0.3596, -0.3653,  0.7068,  0.5145,
          -0.2447, -0.4516, -0.3207,  0.3234],
         [ 0.6185,  0.6022, -0.4117,  0.0143,  0.5622, -0.4426,  0.3869,
          -1.3629, -0.4450,  0.3341,  0.4944, -0.3675, -0.5338, -0.1736,
          -0.0030,  0.1814,  0.7997, -0.4837,  0.4086,  0.4910, -0.4489,
          -0.3934, -0.9026, -0.5245, -0.4744, -0.2023,  0.5102,  0.6120,
          -0.1620, -0.5404, -0.7813,  0.4584],
         [ 0.6559,  0.5360, -0.5452, -0.1737,  0.5073, -0.5026,  0.3910,
          -1.3833, -0.4490,  0.3566,  0.4500, -0.4908, -0.3645, -0.3881,
          -0.0942,  0.4071,  0.9204, -0.4442,  0.3730,  0.4191, -0.5133,
          -0.4288, -1.0884, -0.3935, -0.4903, -0.2092,  0.5524,  0.7749,
          -0.3495, -0.3782, -0.9234,  0.3133],
         [ 0.2602,  0.5159, -0.3512, -0.0107,  0.3776, -0.5381,  0.6012,
          -1.2605, -0.4961,  0.7688,  0.6765, -0.5638, -0.1915, -0.5663,
          -0.1127,  0.5318,  0.6732, -0.3871,  0.0687,  0.5347, -0.5530,
          -0.3225, -0.7694, -0.1314, -0.3623, -0.2231,  0.5358,  0.4353,
          -0.4192, -0.3435, -0.5224,  0.3967],
         [ 0.7329,  0.5256, -0.6073, -0.1455,  0.6787, -0.7865,  0.3572,
          -1.3663, -0.8450,  0.4963,  0.7210, -0.4077, -0.3622, -0.5370,
          -0.3131,  0.2811,  0.9831, -0.5052,  0.5883,  0.4315, -0.3124,
          -0.6414, -0.9387, -0.4958, -0.3309, -0.1867,  0.6766,  0.8232,
          -0.3601, -0.3169, -1.1577,  0.6770],
         [ 0.8603,  0.9217, -0.6479, -0.4084,  0.3190, -0.7688,  0.4966,
          -2.1051, -0.5145,  0.5834,  1.0897, -0.7146, -0.7891, -0.7399,
          -0.2530,  0.5614,  1.4087, -0.6999,  0.9658,  1.1046, -0.7319,
          -0.6844, -1.3882, -0.7175, -0.7687, -0.5229,  0.9227,  1.0375,
          -0.2752, -0.7626, -0.8613,  0.7520],
         [ 0.3765,  0.8702, -0.7740, -0.3104,  0.4985, -0.8052,  0.9380,
          -1.8656, -0.6912,  1.2757,  1.1411, -0.7818, -0.3411, -0.6259,
          -0.1991,  0.6230,  1.3805, -0.6902,  0.5212,  0.9527, -0.8409,
          -0.6861, -1.3660, -0.3239, -0.6320, -0.6595,  0.9977,  0.6436,
          -0.3499, -0.4410, -0.5900,  0.4422],
         [ 0.5673,  0.6938, -0.4500, -0.2255,  0.5281, -0.5023,  0.4710,
          -1.7100, -0.5390,  0.4060,  0.7931, -0.2556, -0.5512, -0.4589,
          -0.0356,  0.3221,  0.8123, -0.4126,  0.4687,  0.4640, -0.6850,
          -0.3792, -1.0522, -0.9150, -0.3300, -0.4030,  0.4078,  0.6225,
          -0.1839, -0.5523, -0.9938,  0.8995],
         [ 0.1294,  0.6114, -0.4312,  0.0917,  0.7752, -0.6265,  0.6195,
          -1.6433, -0.5726,  0.7798,  0.6464, -0.3841, -0.5383, -0.4197,
          -0.4396,  0.3163,  0.8717, -0.5431,  0.2449,  0.6537, -0.3899,
          -0.4525, -0.8503, -0.5687, -0.1635, -0.1029,  0.4917,  0.6668,
          -0.2179, -0.3662, -0.7761,  0.7357],
         [ 0.6963,  0.6574, -0.4276, -0.3153,  0.0295, -0.3143,  0.5027,
          -1.7888, -0.2254,  0.6880,  0.5398, -0.6025, -0.5130, -0.7269,
          -0.2598,  0.4160,  0.7271, -0.5552,  0.4169,  0.6381, -0.7308,
          -0.3426, -1.1849, -0.6724, -0.4587, -0.2606,  0.6962,  0.8109,
          -0.2665, -0.7826, -0.5997,  0.6392],
         [ 0.9506,  1.1263, -0.8024, -0.5274,  0.4757, -1.1313,  0.8409,
          -2.3131, -1.2011,  1.0256,  1.4525, -0.7719, -0.6956, -0.8716,
          -0.0419,  0.6780,  1.4108, -1.1069,  0.7710,  0.7347, -0.8757,
          -0.8438, -1.3796, -0.4974, -1.2897, -0.6172,  1.1539,  0.7610,
          -0.0331, -0.6977, -0.8309,  0.2294],
         [ 0.5517,  0.4766, -0.7988, -0.0784,  0.4417, -0.4185,  0.7082,
          -1.6028, -0.8867,  0.7809,  1.0581, -0.6598, -0.4551, -0.2593,
          -0.3121,  0.4950,  1.2061, -0.5184,  0.8097,  0.9303, -0.3316,
          -0.8587, -0.9652, -0.3453, -0.6055, -0.3573,  0.8837,  0.7160,
          -0.5419, -0.5164, -0.8335,  0.4793],
         [ 0.8457,  1.0954, -0.8915, -0.2962,  0.0680, -0.0565,  0.5808,
          -2.1766, -0.6836,  0.9419,  0.7926, -1.2369, -0.8779, -0.6077,
          -0.5246,  0.6042,  1.3144, -0.6823,  0.9682,  1.2367, -0.5740,
          -0.5044, -1.3389, -0.6207, -0.8207, -0.9546,  1.5510,  1.0810,
          -0.6235, -0.7907, -0.4943,  0.9547],
         [ 1.0926,  0.6657, -0.9970, -0.4320,  0.2672, -0.7588,  0.6075,
          -1.8534, -0.4941,  1.0947,  1.1125, -0.9340, -0.6703, -0.3984,
           0.2642,  0.8069,  1.5646, -0.6834,  0.8042,  0.4546, -1.2362,
          -0.6055, -1.7645, -0.3921, -1.0202, -0.3952,  1.0633,  1.1673,
          -0.2896, -0.4913, -0.7699,  0.0841],
         [ 0.9055,  0.7376, -0.6046, -0.1596,  0.5787, -0.5753,  0.6984,
          -1.7346, -0.7850,  0.6255,  0.8777, -0.4746, -0.3804, -0.5700,
          -0.1774,  0.0982,  1.0409, -0.6784,  0.6633,  0.6720, -0.4834,
          -0.6360, -1.1555, -0.5598, -0.5377, -0.5023,  0.8695,  0.7487,
          -0.3006, -0.5912, -1.0086,  0.6888],
         [ 0.8360,  0.6197, -0.6520,  0.0577,  0.5803, -0.7008,  0.7773,
          -1.7119, -0.4980,  0.5798,  1.0374, -0.4870, -0.5014, -0.4509,
          -0.1858,  0.2885,  1.0910, -0.6627,  0.8040,  0.8272, -0.4473,
          -0.6657, -0.9808, -0.4353, -0.5466, -0.3289,  0.8109,  0.6458,
          -0.3575, -0.4575, -0.9888,  0.6879],
         [ 0.7583,  0.7227, -0.8020, -0.2067,  0.6863, -0.6592,  0.4485,
          -1.7374, -0.6091,  0.5854,  0.6931, -0.5965, -0.4374, -0.4386,
          -0.1960,  0.5512,  1.1601, -0.4396,  0.5611,  0.4907, -0.6878,
          -0.4775, -1.2138, -0.4012, -0.8003, -0.2144,  0.7370,  0.8457,
          -0.4876, -0.4833, -1.0621,  0.6172],
         [ 0.7340,  0.8972, -0.8776, -0.2791,  0.2659, -0.4499,  0.4801,
          -1.9227, -0.7098,  0.2776,  0.8933, -1.0275, -0.6001, -0.7203,
          -0.8349,  0.9716,  1.3475, -0.6497,  0.5331,  1.3292, -0.4327,
          -0.5877, -1.4447, -0.5717, -0.8141, -0.7237,  1.1199,  1.1278,
          -0.5115, -0.4550, -0.9601,  0.7305],
         [ 0.7792,  0.9311, -0.7238, -0.3538,  0.4425, -0.7235,  0.2165,
          -1.2460, -0.7474,  0.5293,  0.5216, -0.6601, -0.3896, -0.4917,
           0.1773,  0.4741,  1.0852, -0.3738,  0.6176,  0.3021, -0.7510,
          -0.5099, -1.2050, -0.1078, -0.6076, -0.5298,  0.9082,  0.7623,
          -0.3890, -0.4222, -0.6893,  0.1560],
         [ 0.5200,  0.4640, -0.7002, -0.0776,  0.8117, -0.8616,  0.5063,
          -1.5537, -0.8080,  0.6206,  0.9913, -0.2532, -0.4551, -0.3348,
          -0.0725,  0.2574,  1.1574, -0.6163,  0.8276,  0.5436, -0.5015,
          -0.5832, -0.8887, -0.5498, -0.3247, -0.3842,  0.6046,  0.6556,
          -0.1759, -0.2754, -1.1120,  0.6645],
         [ 0.7177,  0.4868, -0.6317, -0.2544,  0.3817, -0.7057,  0.5658,
          -1.1787, -0.8338,  0.4913,  1.0520, -0.7348, -0.0936, -0.3828,
          -0.2102,  0.5895,  1.0737, -0.5306,  0.7375,  0.4858, -0.5700,
          -0.5710, -0.9304, -0.3148, -0.7398, -0.3239,  0.8354,  0.4810,
          -0.5360, -0.2541, -1.1446,  0.2603],
         [ 0.3848,  0.4179, -0.6302, -0.0435,  0.4377, -0.4876,  0.3337,
          -1.2357, -0.5958,  0.4435,  0.3250, -0.6064, -0.3939, -0.1358,
          -0.0931,  0.2127,  0.7527, -0.4454,  0.6905,  0.1552, -0.3206,
          -0.2113, -0.5247, -0.4246, -0.2775,  0.0405,  0.7815,  0.5356,
          -0.5025, -0.3033, -1.0562,  0.4174],
         [ 0.5852,  0.3675, -0.5179,  0.0038,  0.2989, -0.2498,  0.3071,
          -1.0939, -0.3241,  0.3894,  0.3495, -0.2242, -0.3389, -0.1407,
           0.0706,  0.1699,  0.5885, -0.3164,  0.3457,  0.3247, -0.4483,
          -0.3683, -0.6732, -0.3596, -0.2266, -0.0841,  0.5269,  0.4738,
          -0.3148, -0.4631, -0.5809,  0.3405]]], grad_fn=<AddBackward0>) torch.Size([1, 24, 32])
batch number:  4
#### arr_b tensor([[[ 1.6107,  0.2177, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 1.8378,  0.2896, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 2.2109,  0.3706, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 2.5649,  0.4498, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 2.7934,  0.5735, -0.2877, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2103,  0.5564, -0.2813, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.7867,  0.5924, -0.2826, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 4.3058,  0.6133, -0.2556, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 5.3681,  0.8729, -0.2334, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 5.2710,  0.7727,  0.1726, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 5.0511,  0.7244,  0.2207, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 4.3120,  0.7036,  0.3016, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3324, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3956, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3668, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3505, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466]]]) torch.Size([1, 23, 14])
#### mat_b tensor([[[ 0.7618,  0.5441, -0.6153, -0.1592,  0.2462, -0.3167,  0.4930,
          -1.2089, -0.5339,  0.2890,  0.8373, -0.4278, -0.5632, -0.1782,
          -0.0927,  0.3355,  0.8333, -0.3807,  0.6317,  0.6133, -0.4680,
          -0.6913, -0.9465, -0.5514, -0.4418, -0.3173,  0.4904,  0.5098,
          -0.2716, -0.7215, -0.6857,  0.4169],
         [ 0.5513,  0.5106, -0.5025, -0.0572,  0.6286, -0.0664,  0.7148,
          -1.0192, -0.6370,  0.4789,  0.6232, -0.2788, -0.2599, -0.2291,
          -0.2442,  0.1361,  0.6000, -0.2695,  0.1876,  0.3980, -0.3796,
          -0.4876, -0.7086, -0.3513, -0.2822, -0.5031,  0.5601,  0.2905,
          -0.4951, -0.4743, -0.6615,  0.7590],
         [ 0.9550,  0.7754, -0.7168, -0.3916,  0.3789, -0.4617,  0.4176,
          -1.3581, -0.5623,  0.2905,  0.8170, -0.6086, -0.7421, -0.4817,
          -0.3242,  0.5697,  1.0798, -0.4247,  0.7194,  0.8004, -0.5820,
          -0.6949, -1.2484, -0.5294, -0.6518, -0.5171,  0.7669,  0.8894,
          -0.3752, -0.7412, -0.8044,  0.6394],
         [ 0.4685,  0.6560, -0.5901, -0.0130,  0.3143, -0.3074,  0.4055,
          -1.2889, -0.6341,  0.4603,  0.7192, -0.6871, -0.5866, -0.1741,
          -0.3745,  0.3163,  0.9719, -0.5052,  0.6280,  0.8200, -0.3899,
          -0.6251, -1.0173, -0.5426, -0.3545, -0.4728,  0.5175,  0.7082,
          -0.2600, -0.7185, -0.5970,  0.3797],
         [ 0.4762,  0.8241, -0.3885, -0.4357,  0.4629, -0.7738,  0.3591,
          -1.4852, -0.5996,  0.7492,  0.6964, -0.5594, -0.4224, -0.7766,
          -0.1221,  0.5720,  0.8588, -0.4806,  0.5948,  0.4883, -0.8335,
          -0.3839, -1.0033, -0.8065, -0.4441, -0.5572,  0.5361,  0.5887,
          -0.3976, -0.4787, -0.9135,  0.7005],
         [ 0.5518,  0.8741, -0.7235, -0.4632,  0.5865, -0.6975,  0.6143,
          -1.7619, -0.5843,  0.5921,  0.8620, -0.5369, -0.6769, -0.6919,
          -0.3580,  0.6556,  1.0678, -0.4935,  0.7145,  0.6088, -0.8156,
          -0.4609, -1.1112, -0.8535, -0.4873, -0.5953,  0.7298,  0.7011,
          -0.4604, -0.5263, -1.1035,  1.0725],
         [ 0.5592,  1.1798, -0.7439, -0.3883,  0.5630, -0.9974,  0.9103,
          -2.0232, -1.0096,  1.4351,  1.2251, -1.0681, -0.6404, -0.9613,
          -0.4773,  0.8036,  1.3497, -0.9082,  0.6199,  1.1230, -0.9229,
          -0.7395, -1.4705, -0.5725, -0.8212, -0.7532,  1.2388,  1.0096,
          -0.4933, -0.6529, -0.7067,  0.6482],
         [ 1.1235,  1.1643, -0.8638, -0.6329,  0.5161, -1.0571,  1.0491,
          -2.0201, -0.9651,  1.1255,  1.4751, -0.7430, -0.9235, -1.0317,
          -0.0811,  0.5988,  1.3952, -0.9091,  0.7391,  0.7907, -1.0877,
          -0.8832, -1.5765, -0.5412, -1.1559, -0.7475,  1.3188,  1.0243,
          -0.2935, -0.8777, -0.7145,  0.7527],
         [ 0.6816,  0.8078, -0.9172, -0.3102,  0.6080, -0.9003,  0.6409,
          -1.9485, -0.7030,  0.8884,  0.8110, -0.6896, -0.9359, -0.5914,
          -0.2618,  0.5745,  1.1378, -0.8778,  0.8272,  0.5930, -0.6109,
          -0.5261, -1.1655, -0.7459, -0.6316, -0.3127,  1.1338,  0.9911,
          -0.1723, -0.4091, -0.8095,  0.6184],
         [ 1.3209,  0.8510, -0.7889, -0.6317,  0.0845, -0.3222,  0.3192,
          -1.4802, -0.5552,  0.4825,  0.7788, -0.8408, -0.7841, -0.5313,
          -0.1909,  0.6056,  1.2050, -0.7182,  0.6536,  0.6947, -0.7071,
          -0.5026, -1.3530, -0.8425, -1.1991, -0.7523,  1.1380,  0.9539,
          -0.3007, -0.5899, -0.6785,  0.4904],
         [ 0.8887,  0.9949, -0.6817, -0.1041,  0.8556, -0.9048,  0.6213,
          -2.1752, -0.7368,  0.9474,  0.9897, -0.8387, -0.8710, -0.6642,
          -0.2628,  0.4021,  1.3081, -0.7892,  0.8148,  0.8571, -0.9119,
          -0.7210, -1.2681, -0.7735, -0.7122, -0.3614,  0.7767,  1.1472,
          -0.6096, -0.9184, -1.2858,  0.8086],
         [ 1.1670,  1.5924, -1.4966, -0.8582,  0.9183, -1.5001,  1.1766,
          -3.2219, -1.4683,  1.4296,  1.8350, -1.6199, -1.0345, -1.2817,
          -0.6180,  0.8071,  2.3367, -1.3388,  1.5187,  1.4994, -1.2867,
          -1.0572, -1.8751, -0.9556, -1.5502, -1.0238,  1.9331,  1.6482,
          -1.0162, -1.1067, -1.8885,  1.2786],
         [ 0.7890,  1.2916, -0.7030, -0.6791,  0.2329, -0.8326,  0.3547,
          -1.7235, -0.9179,  0.5671,  0.9122, -0.9246, -0.6783, -1.0075,
          -0.2869,  0.7832,  1.0791, -0.7284,  0.9098,  0.9240, -0.9678,
          -0.5506, -1.2298, -0.6499, -0.8618, -0.9794,  1.3338,  0.8811,
          -0.4995, -0.7473, -0.7885,  0.6953],
         [ 1.0795,  1.1041, -1.0375, -0.4184,  0.4884, -0.9388,  0.4163,
          -2.4652, -0.7372,  0.9578,  1.1336, -0.9118, -1.3512, -0.3631,
          -0.1656,  0.3698,  1.7589, -1.1687,  1.3368,  0.9847, -1.1999,
          -0.5928, -1.6487, -1.6575, -0.5884, -0.7079,  1.2229,  1.6001,
          -0.1684, -0.9677, -1.3613,  1.0976],
         [ 0.0902,  0.7661, -0.4624, -0.3345,  0.7096, -1.1467,  0.9896,
          -1.5067, -1.1055,  1.3649,  1.0559, -0.8723, -0.1058, -0.6139,
          -0.6326,  0.4064,  1.4696, -1.0404,  0.7575,  0.9783, -0.5460,
          -0.9190, -0.9681, -0.5420, -0.1153, -0.5033,  0.7641,  0.4845,
          -0.4526, -0.4295, -1.1879,  0.5015],
         [ 0.7602,  0.7763, -0.5100, -0.2900,  0.4870, -0.4445,  0.7591,
          -1.8102, -0.5658,  0.6679,  1.0694, -0.6031, -0.8218, -0.7359,
          -0.4153,  0.4719,  1.2274, -0.6372,  0.4615,  1.2403, -0.5511,
          -0.7370, -0.9801, -0.6738, -0.7316, -0.5459,  0.7568,  0.8746,
          -0.5656, -0.8276, -0.7312,  0.8965],
         [ 0.5689,  0.3344, -0.7745, -0.1506,  0.8932, -0.7554,  0.8342,
          -1.4529, -1.1014,  0.8290,  1.2671, -0.3966, -0.4016, -0.3997,
          -0.5893,  0.2755,  1.2644, -0.7573,  0.8076,  0.8652, -0.1796,
          -0.9475, -0.6183, -0.5619, -0.4790, -0.3115,  0.8085,  0.5468,
          -0.5961, -0.4833, -0.9965,  0.7702],
         [ 0.6268,  0.8983, -0.6648, -0.3270,  0.7081, -0.9021,  0.6640,
          -1.8789, -0.8395,  0.9266,  0.8779, -0.5742, -0.5074, -0.6507,
           0.0237,  0.6706,  1.1163, -0.7005,  0.7259,  0.5051, -0.9994,
          -0.6244, -1.0091, -0.8016, -0.6207, -0.4913,  0.8044,  0.6136,
          -0.5845, -0.4253, -1.1982,  0.8048],
         [ 0.6801,  1.4134, -0.9046, -0.3518,  0.6843, -1.1917,  0.6963,
          -2.1474, -0.6771,  0.9104,  0.7441, -1.0997, -0.6524, -0.8795,
          -0.2753,  0.8263,  1.3676, -0.9882,  0.9483,  0.9526, -1.0332,
          -0.3389, -1.1684, -0.5895, -1.0601, -0.7681,  1.4558,  0.8748,
          -0.6323, -0.3511, -1.4059,  0.7276],
         [ 1.0122,  0.7109, -0.9789, -0.2680,  0.6974, -0.6977,  0.7086,
          -1.7043, -0.8438,  0.8834,  1.0776, -0.6320, -0.7152, -0.3815,
          -0.0911,  0.3448,  1.2959, -0.7655,  0.9844,  0.6707, -0.8067,
          -0.6745, -1.1072, -0.6207, -0.6507, -0.6602,  1.1984,  0.8802,
          -0.4715, -0.6233, -1.0315,  0.6368],
         [ 0.3485,  0.8473, -0.8526, -0.2851,  0.7132, -0.5479,  0.8176,
          -1.9416, -0.8806,  0.9392,  0.8401, -0.7986, -0.4450, -0.8156,
          -0.5759,  0.5851,  1.0201, -0.5471,  0.3495,  0.8813, -0.5852,
          -0.5687, -1.1018, -0.3583, -0.7807, -0.5535,  0.8719,  0.7202,
          -0.6411, -0.6420, -0.8181,  0.8149],
         [ 0.4363,  0.9034, -0.9363, -0.0823,  0.8328, -1.1821,  0.4943,
          -2.0477, -0.8905,  0.7273,  1.0120, -0.7612, -0.9675, -0.6422,
          -0.4940,  0.5938,  1.2113, -0.8715,  0.7987,  0.8224, -0.6356,
          -0.5864, -1.1824, -0.7383, -0.6143, -0.3382,  0.8101,  1.0343,
          -0.1545, -0.5175, -1.1586,  0.7034],
         [ 0.8502,  1.1755, -0.8758, -0.2294,  0.6427, -0.8114,  0.9068,
          -2.0875, -0.6364,  0.7895,  1.1338, -0.8603, -1.0757, -0.5442,
          -0.4464,  0.4476,  1.2532, -0.9069,  0.7244,  0.8491, -0.8556,
          -0.6550, -1.5738, -0.8057, -0.7674, -0.5190,  1.0857,  1.0932,
          -0.1873, -0.7641, -0.9677,  0.8017]]], grad_fn=<AddBackward0>) torch.Size([1, 23, 32])
batch number:  5
#### arr_b tensor([[[ 1.5976,  0.2143, -0.0821, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 1.8232,  0.2856, -0.0821, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 2.1937,  0.3661, -0.0821, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 2.5452,  0.4447, -0.0821, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 2.7722,  0.5675, -0.2877, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 3.1862,  0.5506, -0.2814, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 3.7586,  0.5863, -0.2826, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 4.2741,  0.6070, -0.2558, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 3.2154,  0.4805, -0.0821, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 3.2154,  0.4805, -0.0821, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 3.2154,  0.4805, -0.0821, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 5.3292,  0.8649, -0.2338, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 3.2154,  0.4805, -0.0821, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 5.2327,  0.7654,  0.1694, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 5.0143,  0.7175,  0.2172, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 3.2154,  0.4805, -0.0821, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 3.2154,  0.4805, -0.0821, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 3.2154,  0.4805, -0.0821, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 4.2803,  0.6967,  0.2975, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 3.2154,  0.3281, -0.0821, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462],
         [ 3.2154,  0.3909, -0.0821, -0.3462, -0.3462, -0.3462, -0.3462,
          -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462, -0.3462]]]) torch.Size([1, 21, 14])
#### mat_b tensor([[[ 0.5342,  0.3819, -0.6710, -0.0762,  0.4205, -0.1923,  0.7166,
          -1.2568, -0.6029,  0.7484,  0.7445, -0.4588, -0.4930, -0.1813,
          -0.2408,  0.4837,  0.7748, -0.3978,  0.4506,  0.6026, -0.5035,
          -0.6724, -0.7568, -0.3956, -0.4442, -0.1592,  0.5572,  0.5133,
          -0.5119, -0.6247, -0.6306,  0.4808],
         [ 0.9326,  0.9060, -0.7803, -0.4036,  0.5043, -0.6088,  0.5482,
          -1.2851, -0.9280,  0.7745,  0.8219, -0.8242, -0.5219, -0.4057,
          -0.2611,  0.4500,  1.0567, -0.5944,  0.7991,  0.5485, -0.7128,
          -0.7336, -1.1389, -0.5948, -0.6904, -0.6137,  0.9062,  0.6319,
          -0.5485, -0.8182, -0.9496,  0.4881],
         [ 0.9552,  0.6940, -0.9518, -0.3814,  0.4052, -0.2998,  0.6545,
          -1.3133, -1.0091,  1.0488,  0.8797, -0.8468, -0.4554, -0.2450,
          -0.2143,  0.5927,  1.0726, -0.6075,  0.7178,  0.6297, -0.6659,
          -0.7186, -1.0618, -0.5413, -0.7454, -0.6946,  1.0819,  0.6649,
          -0.6664, -0.6622, -0.7690,  0.5221],
         [ 0.9464,  0.6841, -0.9987, -0.3031,  0.5950, -0.7949,  0.7677,
          -2.0226, -0.7376,  0.9526,  0.9374, -0.9368, -0.6847, -0.6020,
          -0.2866,  0.6822,  1.2876, -0.8733,  0.8202,  0.8992, -0.8899,
          -0.6239, -1.1306, -0.8201, -0.9474, -0.3325,  1.1133,  1.0007,
          -0.8106, -0.8140, -1.2553,  0.8077],
         [ 0.8129,  1.0417, -1.0016, -0.2089,  0.7153, -0.7914,  0.4808,
          -1.7154, -0.8980,  0.4255,  0.6864, -1.0342, -0.9028, -0.7234,
          -0.6715,  0.5533,  1.1311, -0.7051,  0.7407,  0.6453, -0.4545,
          -0.6581, -1.1594, -0.6999, -0.6302, -0.4961,  0.9981,  1.1195,
          -0.6488, -0.4365, -1.3893,  0.7749],
         [ 1.3394,  1.2586, -1.2515, -0.5412,  0.9328, -0.9976,  0.9908,
          -2.5315, -1.2221,  1.1137,  1.4207, -1.0237, -1.1035, -0.8497,
          -0.4095,  0.7558,  1.7299, -1.0484,  1.1492,  1.1892, -0.9863,
          -1.0464, -1.7405, -1.0345, -1.2710, -0.9435,  1.2871,  1.3519,
          -0.5740, -0.9756, -1.4656,  1.0444],
         [ 0.8001,  1.0725, -1.1515, -0.5656,  0.9649, -0.9644,  0.8494,
          -2.2129, -1.1417,  1.1464,  1.3706, -0.7932, -0.8763, -0.9513,
          -0.7790,  0.7974,  1.5884, -0.7361,  1.0848,  1.4480, -0.7620,
          -1.0519, -1.4922, -1.1529, -0.6420, -1.0648,  1.0560,  1.1111,
          -0.7255, -0.9113, -1.2628,  1.3033],
         [ 1.3773,  1.1094, -1.2847, -0.9337,  0.3498, -0.9544,  1.1966,
          -2.4107, -1.1969,  1.6870,  1.6184, -1.2159, -0.9471, -0.9120,
          -0.2482,  0.6781,  1.8153, -1.2858,  1.0456,  0.8286, -1.2516,
          -0.9655, -1.5984, -0.9895, -1.5227, -0.7214,  1.6479,  1.1470,
          -0.5747, -0.9672, -1.0664,  0.5272],
         [ 1.0179,  0.9022, -1.0485, -0.3748,  0.3751, -0.3669,  0.8078,
          -1.5526, -1.1078,  1.1662,  0.7416, -1.1454, -0.4566, -0.4652,
          -0.4192,  0.8721,  1.0195, -0.8319,  0.8411,  0.6616, -0.6458,
          -0.6205, -1.2249, -0.6216, -0.8906, -0.9214,  1.5094,  0.7706,
          -0.7173, -0.5085, -0.8174,  0.5211],
         [ 1.2888,  1.3606, -1.0560, -0.7097,  0.7515, -0.9124,  0.6558,
          -1.8851, -1.1843,  0.8536,  1.1091, -1.0144, -0.8654, -0.6868,
          -0.1375,  0.8132,  1.4560, -0.9028,  0.8725,  0.7689, -1.1495,
          -0.8478, -1.7669, -0.8742, -1.1370, -1.0521,  1.2966,  1.2328,
          -0.5282, -0.6897, -1.2933,  0.5984],
         [ 1.2594,  1.0068, -1.0000, -0.3419,  0.8426, -0.7420,  0.8000,
          -1.8883, -0.9309,  0.8658,  1.0610, -0.7461, -1.1182, -0.5449,
          -0.4277,  0.0837,  1.4418, -1.1321,  0.9807,  0.8578, -0.6639,
          -0.7387, -1.1458, -0.9829, -0.9592, -0.7423,  1.5046,  1.1224,
          -0.3797, -0.7417, -1.0625,  0.7422],
         [ 1.0927,  1.7361, -1.5175, -0.9133,  0.9850, -1.6092,  1.6396,
          -3.3242, -1.3707,  1.7873,  2.1500, -1.8155, -1.4707, -1.3037,
          -1.2594,  1.0838,  2.4095, -1.5487,  1.7543,  1.6558, -1.3766,
          -1.4032, -2.2696, -1.3169, -1.5661, -0.9472,  1.8282,  1.7160,
          -0.8300, -1.2414, -1.9548,  1.1269],
         [ 1.0966,  0.7766, -1.3958, -0.5862,  0.4967, -0.8674,  1.2574,
          -2.0501, -1.0183,  0.7941,  1.6160, -1.0584, -0.9056, -0.7616,
          -0.5315,  0.7349,  1.7117, -0.9681,  1.0924,  1.0564, -0.8098,
          -1.1167, -1.2566, -0.6772, -1.0433, -0.6864,  1.4002,  0.9854,
          -0.9367, -0.7530, -1.4854,  0.6995],
         [ 0.8977,  1.7898, -1.3254, -0.7903,  1.2402, -1.5829,  1.7280,
          -3.3688, -1.0418,  1.7179,  1.8934, -1.5762, -1.4721, -1.2285,
          -0.9804,  1.0616,  2.2817, -1.5212,  1.2632,  1.5496, -1.7912,
          -1.0554, -2.3486, -1.4433, -1.3594, -1.0667,  1.5888,  1.6164,
          -0.7561, -1.2196, -1.9910,  1.3414],
         [ 1.3083,  1.6826, -1.1188, -1.0489,  1.0094, -1.0666,  0.9127,
          -2.2974, -2.0219,  1.1779,  1.3573, -1.4765, -0.4414, -1.0287,
          -0.4685,  0.7459,  1.8304, -1.1408,  1.2589,  0.7264, -1.1759,
          -1.1710, -1.8422, -1.0069, -1.5689, -1.4400,  1.4914,  0.9893,
          -0.8216, -0.7926, -1.9015,  0.4526],
         [ 0.8943,  0.9906, -0.6830, -0.4844,  0.7390, -0.4642,  0.6977,
          -1.8201, -0.9069,  0.8809,  0.8411, -0.5588, -0.6876, -0.7817,
          -0.4228,  0.2947,  0.8059, -0.5727,  0.7429,  0.4305, -0.7967,
          -0.4132, -1.0288, -1.1688, -0.5949, -0.7343,  0.9690,  0.7031,
          -0.5448, -0.7134, -1.1489,  1.3410],
         [ 0.6395,  0.7270, -0.5003, -0.2860,  0.7259, -0.6923,  0.8905,
          -1.6685, -1.0804,  1.1695,  0.9920, -0.8162, -0.1454, -0.6952,
          -0.4785,  0.7281,  1.0160, -0.8605,  0.7687,  1.0602, -0.5495,
          -0.8776, -0.8063, -0.6617, -0.8504, -0.6856,  0.8640,  0.4746,
          -0.7722, -0.4693, -1.2296,  0.6535],
         [ 1.4149,  0.9655, -1.1331, -0.5604,  0.8503, -0.6333,  0.9823,
          -1.9812, -0.8631,  0.6316,  0.9987, -0.9352, -0.8351, -0.8020,
          -0.6991,  0.8898,  1.3268, -0.8505,  0.5514,  0.6946, -0.7779,
          -0.7112, -1.6366, -0.8351, -1.2881, -0.7472,  1.1837,  1.1269,
          -0.7375, -0.6879, -1.4073,  1.0633],
         [ 1.4866,  1.0218, -1.8131, -0.8992,  0.6347, -0.8510,  0.8186,
          -2.7565, -1.5589,  1.2673,  1.5109, -1.7937, -0.9958, -0.8292,
          -0.8061,  1.1002,  2.0880, -1.1948,  1.5176,  1.0275, -1.0773,
          -1.1403, -1.8396, -1.1242, -1.7686, -0.7987,  1.8349,  1.6986,
          -1.2102, -0.8561, -1.9233,  0.6617],
         [ 0.9443,  0.9550, -1.2416, -0.4952,  0.7901, -0.8116,  1.1546,
          -2.2122, -1.3558,  1.3472,  1.5112, -1.1760, -0.7884, -0.7756,
          -0.7898,  0.9152,  1.6541, -0.9200,  1.1475,  1.2018, -0.8359,
          -1.2046, -1.4534, -0.7836, -0.9633, -0.7981,  1.3878,  1.1808,
          -0.9684, -0.9008, -1.2816,  0.9188],
         [ 0.9009,  1.1500, -0.9374, -0.6838,  0.4733, -1.1571,  1.0044,
          -2.1848, -1.0835,  1.3558,  1.5417, -1.1891, -0.8312, -0.8830,
          -0.3439,  0.9423,  1.5356, -1.0530,  1.1218,  1.0874, -1.1151,
          -1.0619, -1.5322, -0.7910, -1.1695, -0.6325,  1.1543,  1.0007,
          -0.5796, -0.8490, -1.1995,  0.5573]]], grad_fn=<AddBackward0>) torch.Size([1, 21, 32])
batch number:  6
#### arr_b tensor([[[ 1.6107,  0.2177, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 1.8378,  0.2896, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 2.2109,  0.3706, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 2.5649,  0.4498, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 2.7934,  0.5735, -0.2877, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2103,  0.5564, -0.2813, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.7867,  0.5924, -0.2826, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 4.3058,  0.6133, -0.2556, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 5.3681,  0.8729, -0.2334, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 5.2710,  0.7727,  0.1726, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 5.0511,  0.7244,  0.2207, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 4.3120,  0.7036,  0.3016, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3324, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3956, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3668, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3505, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466]]]) torch.Size([1, 23, 14])
#### mat_b tensor([[[ 0.6583,  0.4035, -0.9356, -0.4105,  0.6302, -0.7116,  0.6440,
          -1.3821, -1.0025,  0.6890,  1.0704, -0.5233, -0.5954, -0.4848,
          -0.5137,  0.3541,  1.0629, -0.7761,  0.7289,  0.6419, -0.3969,
          -0.7739, -0.7031, -0.6927, -0.6596, -0.3094,  0.8263,  0.5663,
          -0.4640, -0.5359, -1.0080,  0.5288],
         [ 1.1434,  1.0194, -0.8213, -0.5760,  0.5673, -0.8434,  0.8162,
          -1.8701, -0.7726,  0.7237,  1.2460, -0.7689, -1.1044, -0.8660,
          -0.4970,  0.5372,  1.3094, -0.8905,  0.6387,  1.1725, -0.7333,
          -0.9196, -1.4505, -0.9758, -0.9528, -0.6567,  0.8808,  1.0358,
          -0.3396, -1.1381, -0.8456,  0.7886],
         [ 1.1198,  1.1824, -0.8597, -0.4228,  0.7441, -0.7301,  0.9914,
          -1.9080, -0.9475,  0.7171,  1.3849, -0.7440, -1.0277, -0.8032,
          -0.6003,  0.6029,  1.1845, -0.8286,  0.9925,  1.1308, -0.8588,
          -0.8894, -1.3809, -1.1058, -0.8972, -0.9700,  1.0948,  0.9008,
          -0.4632, -0.9256, -1.1346,  1.1436],
         [ 0.7934,  0.6108, -1.1467, -0.4767,  0.7410, -0.8470,  0.9297,
          -1.7069, -0.9396,  0.6609,  1.1046, -0.6798, -0.7176, -0.7566,
          -0.5035,  0.7906,  1.2251, -0.7254,  0.8422,  0.5826, -0.6447,
          -0.7524, -0.8215, -0.5732, -0.8137, -0.3932,  0.9626,  0.7672,
          -0.8817, -0.4930, -1.3821,  0.9426],
         [ 1.2194,  1.2738, -1.4456, -0.5702,  1.0598, -0.6963,  1.2891,
          -2.1864, -1.3270,  1.2086,  1.4451, -1.1285, -1.0700, -0.6947,
          -0.7352,  0.8896,  1.6207, -0.9301,  0.9289,  1.1840, -0.9762,
          -1.1328, -1.7405, -0.9198, -0.9982, -1.2457,  1.4637,  1.1657,
          -0.8913, -0.9558, -1.3022,  1.2431],
         [ 1.0063,  1.4610, -0.6854, -0.7245,  1.2182, -1.3067,  0.9584,
          -2.1494, -1.3434,  1.4150,  1.1384, -1.0733, -0.7558, -1.2845,
          -0.6362,  0.7218,  1.5204, -1.0893,  1.1834,  1.0441, -1.1946,
          -0.9599, -1.3477, -1.1001, -1.1484, -1.1077,  1.3986,  0.9980,
          -0.7959, -0.9001, -1.5716,  1.0037],
         [ 1.6381,  1.4388, -1.9493, -0.9249,  0.8607, -0.9196,  0.9926,
          -2.7875, -1.4605,  1.2986,  1.4687, -1.8300, -1.3583, -1.1357,
          -0.9651,  1.2428,  2.0027, -1.1789,  1.3723,  1.0749, -1.2451,
          -1.0134, -1.9780, -1.1860, -1.8020, -1.1929,  2.0934,  1.8296,
          -1.2492, -0.8344, -1.8410,  1.1658],
         [ 1.2718,  1.5660, -1.6003, -0.9297,  1.3200, -1.5987,  1.5548,
          -3.0558, -1.6549,  1.5599,  2.2288, -1.6988, -1.2355, -1.4528,
          -0.8728,  0.9187,  2.3912, -1.4729,  1.5769,  1.5341, -1.4501,
          -1.2843, -1.9093, -1.2770, -1.5634, -1.4597,  1.7884,  1.5798,
          -1.2211, -1.0394, -2.1689,  1.3465],
         [ 1.5546,  1.0267, -1.2797, -0.6326,  0.9431, -1.0020,  0.9364,
          -2.4045, -0.9332,  1.3395,  1.3214, -1.0619, -1.3694, -0.7382,
          -0.5034,  0.6689,  1.8913, -1.2960,  1.1803,  1.1273, -1.3197,
          -1.0630, -1.4713, -1.1075, -1.1844, -0.6007,  1.5190,  1.6089,
          -0.9881, -1.2712, -1.4436,  1.1693],
         [ 1.5600,  1.2356, -1.3140, -0.9054,  0.9154, -0.9556,  0.7666,
          -2.2558, -1.2980,  1.4846,  1.2137, -1.3480, -0.6967, -1.0139,
          -0.7430,  0.8793,  1.6801, -1.1920,  1.2948,  0.9978, -1.1486,
          -1.0150, -1.7239, -1.2022, -1.5253, -1.1091,  1.6761,  1.2577,
          -1.0029, -0.7569, -1.5414,  0.9126],
         [ 1.3331,  1.5105, -1.4479, -0.7979,  1.1378, -1.2620,  1.3523,
          -2.6022, -1.5846,  1.1903,  1.8710, -1.3511, -1.1069, -1.0896,
          -0.8541,  0.8698,  1.8938, -1.3360,  1.1788,  1.2595, -1.2369,
          -1.0313, -1.6686, -1.2382, -1.4543, -1.2424,  1.7885,  1.2775,
          -0.9393, -1.0080, -1.8113,  1.4736],
         [ 1.0699,  2.2290, -1.8194, -0.7796,  1.5534, -1.8522,  2.0204,
          -3.5927, -1.5945,  2.3153,  2.2807, -2.0612, -1.7743, -1.5096,
          -1.8185,  1.3504,  2.6246, -1.8164,  1.5821,  2.4303, -1.4993,
          -1.4833, -2.5397, -1.5465, -1.6350, -1.4511,  2.3479,  2.0170,
          -1.0725, -1.4637, -1.8359,  1.8052],
         [ 1.2390,  1.2659, -1.5359, -0.5811,  1.0456, -1.0878,  1.2488,
          -2.6772, -1.5397,  1.3696,  1.5669, -1.4647, -1.0402, -1.2471,
          -1.0960,  1.2291,  1.8269, -1.2481,  1.1329,  1.7198, -0.9482,
          -1.2350, -1.7618, -1.0396, -1.2476, -1.2409,  1.6997,  1.5404,
          -1.1700, -1.0233, -1.6520,  1.2746],
         [ 1.8959,  1.4674, -1.9334, -1.0808,  1.6055, -2.0604,  1.4258,
          -3.4754, -1.5743,  1.5333,  1.9508, -1.3139, -1.4575, -1.8718,
          -1.5202,  1.4887,  2.3489, -1.7063,  1.2770,  1.7393, -1.0369,
          -1.6578, -2.5214, -1.5708, -1.7674, -0.8984,  1.6436,  2.0399,
          -0.9178, -1.1548, -2.2384,  1.5527],
         [ 0.9468,  0.9207, -1.3888, -0.6161,  1.5145, -1.5855,  0.9072,
          -2.5397, -1.6082,  1.9734,  1.6204, -0.9656, -0.5943, -0.9797,
          -0.1166,  0.8643,  1.5467, -1.1170,  1.6407,  0.7150, -1.6290,
          -0.7625, -1.2909, -1.3243, -1.1788, -0.9699,  1.4373,  0.9975,
          -1.2278, -0.6531, -1.9683,  1.2993],
         [ 0.8076,  1.1606, -1.0962, -0.5044,  1.2886, -1.7486,  0.8948,
          -2.4456, -1.2111,  1.0477,  1.4569, -1.0804, -1.3603, -1.1432,
          -0.7723,  0.9620,  1.6978, -1.2619,  1.2120,  1.1851, -0.9508,
          -1.0044, -1.5800, -1.1164, -0.9455, -0.6285,  1.1956,  1.5142,
          -0.4068, -0.8871, -1.4542,  0.9294],
         [ 0.7608,  1.1187, -1.0396, -0.7055,  1.0475, -0.9299,  1.4407,
          -2.3629, -1.3156,  1.3486,  1.4642, -1.2757, -0.8453, -1.1688,
          -0.8912,  1.0030,  1.4864, -0.9612,  0.5489,  1.1026, -1.0533,
          -0.8929, -1.6932, -0.9174, -1.2197, -0.9195,  1.2975,  1.1914,
          -0.8599, -1.0474, -1.2075,  1.2643],
         [ 1.4053,  1.3702, -1.1902, -0.8780,  0.9658, -1.3650,  1.0734,
          -2.6775, -1.2347,  1.0417,  1.7442, -0.9804, -1.5127, -1.3670,
          -0.8729,  0.9375,  1.8846, -1.2909,  1.3432,  1.6048, -1.0223,
          -1.3131, -1.6273, -1.5512, -1.1799, -0.9896,  1.4355,  1.4643,
          -0.7446, -1.1909, -1.5268,  1.4343],
         [ 1.2287,  1.4851, -1.4776, -0.7347,  1.7078, -1.4686,  1.5644,
          -3.2922, -1.8195,  1.9214,  1.5954, -1.3431, -1.0817, -1.4713,
          -1.3125,  1.4623,  1.9190, -1.4919,  1.2333,  1.7614, -1.1628,
          -1.3516, -1.9364, -1.6105, -1.1277, -1.1987,  1.6904,  1.6033,
          -1.3691, -1.0244, -2.2421,  1.9504],
         [ 0.8286,  0.7553, -1.0173, -0.4894,  1.4171, -1.1375,  1.2125,
          -2.0738, -1.2955,  1.3498,  1.2300, -0.6316, -0.5525, -1.1085,
          -1.0798,  0.6855,  1.4714, -1.0899,  0.8112,  1.3006, -0.4995,
          -0.9496, -1.0965, -1.1023, -0.8910, -0.7928,  1.1994,  0.9045,
          -0.9095, -0.6089, -1.5375,  1.4099],
         [ 1.5744,  1.1668, -1.2635, -1.0290,  0.5651, -1.1546,  1.1129,
          -2.4712, -1.1391,  1.1370,  1.7832, -1.2469, -1.2209, -1.2195,
          -0.8684,  0.9697,  1.9662, -1.2604,  1.4058,  1.7185, -0.9735,
          -1.3963, -1.7384, -1.2175, -1.3096, -0.9403,  1.3939,  1.4652,
          -0.9102, -1.3360, -1.6274,  1.0572],
         [ 1.0623,  1.1218, -1.1885, -0.5952,  0.7359, -1.3206,  0.5198,
          -1.9345, -1.1935,  1.2334,  1.2119, -1.2243, -1.2450, -0.7975,
          -0.3715,  0.5917,  1.6886, -1.2956,  1.2076,  1.0111, -1.0135,
          -0.6952, -1.1630, -1.1519, -1.1152, -0.7355,  1.6267,  1.4120,
          -0.7618, -0.7196, -1.3757,  0.8008],
         [ 1.0572,  1.2637, -1.4064, -0.5634,  1.0212, -1.0364,  0.8064,
          -2.1749, -1.5741,  1.8035,  1.0967, -1.1625, -0.8893, -0.9470,
          -0.5931,  1.0252,  1.4986, -0.9853,  1.1531,  1.0312, -1.0186,
          -0.8916, -1.4022, -1.0601, -0.9641, -1.1006,  1.7062,  1.1862,
          -0.9794, -0.6901, -1.2315,  1.1068]]], grad_fn=<AddBackward0>) torch.Size([1, 23, 32])
batch number:  7
#### arr_b tensor([[[ 4.2813,  0.6045, -0.2607, -0.3513, -0.3513, -0.3513, -0.3513,
          -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513],
         [ 3.2198,  0.4776, -0.0866, -0.3513, -0.3513, -0.3513, -0.3513,
          -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513],
         [ 3.2198,  0.4776, -0.0866, -0.3513, -0.3513, -0.3513, -0.3513,
          -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513],
         [ 3.2198,  0.4776, -0.0866, -0.3513, -0.3513, -0.3513, -0.3513,
          -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513, -0.3513]]]) torch.Size([1, 4, 14])
#### mat_b tensor([[[ 1.5778,  1.2975, -1.4714, -1.0154,  1.6725, -1.9416,  1.3635,
          -2.8123, -1.9227,  1.5005,  1.8868, -1.0860, -1.3226, -1.4913,
          -1.3307,  0.8108,  2.4497, -1.8465,  1.9401,  1.8447, -0.7649,
          -1.7189, -1.5215, -1.6809, -1.3558, -1.1396,  1.7361,  1.6521,
          -0.9099, -1.0513, -2.5341,  1.2664],
         [ 1.7906,  1.4145, -1.6500, -0.8665,  1.2853, -1.3840,  1.5450,
          -2.9278, -1.4779,  1.4848,  2.0928, -1.3901, -1.5712, -1.0403,
          -0.6043,  1.2704,  2.1755, -1.4583,  1.6004,  1.4216, -1.6541,
          -1.5642, -2.3330, -1.4000, -1.4791, -1.3196,  1.5914,  1.8598,
          -0.9245, -1.3922, -1.8455,  1.4474],
         [ 1.3248,  1.4258, -1.3510, -0.8476,  0.9165, -1.3540,  1.0610,
          -2.9569, -1.2027,  1.5871,  1.5833, -1.1470, -1.5657, -1.4729,
          -0.8397,  1.0709,  1.7062, -1.2278,  1.4132,  1.4429, -1.2804,
          -1.2048, -1.8942, -1.6526, -1.1137, -0.9114,  1.4056,  1.6376,
          -0.6400, -1.2828, -1.3778,  1.3227],
         [ 1.4504,  1.6837, -1.6403, -1.0179,  1.0917, -0.9879,  1.4496,
          -2.6301, -1.4355,  1.4948,  1.8369, -1.4568, -1.3868, -1.3883,
          -1.2064,  1.3042,  2.0347, -1.0202,  1.3563,  1.8520, -1.2988,
          -1.4209, -2.0900, -1.2900, -1.2377, -1.7566,  1.7382,  1.4985,
          -1.2353, -1.3936, -1.5183,  1.6171]]], grad_fn=<AddBackward0>) torch.Size([1, 4, 32])
batch number:  8
#### arr_b tensor([[[ 2.5955,  0.5142, -0.2933, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 2.9864,  0.4982, -0.2873, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 3.5268,  0.5319, -0.2885, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 4.0135,  0.5514, -0.2632, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 3.0140,  0.4320, -0.0992, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 3.0140,  0.4320, -0.0992, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 3.0140,  0.4320, -0.0992, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 5.0095,  0.7949, -0.2424, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 3.0140,  0.4320, -0.0992, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 4.9184,  0.7009,  0.1383, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 4.7123,  0.6557,  0.1834, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 3.0140,  0.4320, -0.0992, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 3.0140,  0.4320, -0.0992, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 3.0140,  0.4320, -0.0992, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 4.0193,  0.6361,  0.2592, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 3.0140,  0.2881, -0.0992, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 3.0140,  0.3474, -0.0992, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485],
         [ 3.0140,  0.3203, -0.0992, -0.3485, -0.3485, -0.3485, -0.3485,
          -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485, -0.3485]]]) torch.Size([1, 18, 14])
#### mat_b tensor([[[ 1.3298,  0.9854, -1.5582, -0.8067,  0.9904, -0.8810,  1.3517,
          -2.1588, -1.8570,  1.5661,  1.8778, -1.4244, -0.9152, -0.7233,
          -0.9404,  0.9073,  1.9509, -1.2795,  1.2049,  1.3165, -1.1124,
          -1.2529, -1.3741, -1.2188, -1.3240, -1.1290,  1.7196,  1.2992,
          -1.2144, -1.2095, -1.6980,  1.2682],
         [ 1.6671,  1.6024, -1.3287, -1.3589,  0.7273, -1.3324,  1.0409,
          -2.5015, -1.4577,  1.8315,  1.7031, -1.6183, -1.1273, -1.5504,
          -1.0342,  1.3374,  2.0178, -1.5571,  1.6494,  1.5108, -1.7259,
          -1.1325, -1.9312, -1.6677, -1.5894, -1.6592,  2.0188,  1.6103,
          -1.0415, -1.2781, -1.5721,  1.4666],
         [ 1.8871,  1.9882, -1.5681, -0.8153,  1.3527, -2.0454,  1.5121,
          -3.0693, -1.6604,  2.1422,  2.0359, -1.9380, -1.5830, -1.6339,
          -0.8750,  1.4053,  2.3784, -1.7184,  1.7758,  1.7973, -2.0144,
          -1.6632, -2.4219, -1.6434, -1.3516, -1.5005,  1.8588,  2.0304,
          -1.3436, -1.6936, -2.2516,  1.3235],
         [ 1.6003,  2.0057, -1.4683, -1.0285,  0.9741, -1.7580,  1.2056,
          -3.2242, -1.0058,  1.8461,  1.4459, -1.8848, -2.0043, -1.7701,
          -1.3039,  1.3245,  2.0136, -1.7334,  1.7183,  1.9092, -1.5235,
          -1.1297, -2.5352, -1.7062, -1.3255, -1.2378,  2.0399,  2.2592,
          -0.6216, -1.5169, -1.5047,  1.1831],
         [ 1.2906,  1.2995, -1.4998, -0.8070,  1.3758, -1.0581,  1.8355,
          -2.8177, -1.7581,  1.7540,  2.0593, -1.4649, -1.2094, -0.9851,
          -1.0217,  1.3981,  2.0346, -1.2963,  1.4888,  1.6920, -1.5152,
          -1.7496, -1.8583, -1.3835, -1.3362, -1.1508,  1.5052,  1.3873,
          -1.5592, -1.4783, -1.9659,  1.4585],
         [ 1.7900,  1.3143, -1.5948, -1.2595,  0.9667, -1.2672,  1.1314,
          -2.7195, -1.3659,  1.4717,  1.8256, -1.3992, -1.4707, -1.5315,
          -0.8972,  1.1846,  2.0643, -1.2716,  1.3140,  1.5222, -1.6125,
          -1.1920, -1.7555, -1.4761, -1.6639, -1.1550,  1.8286,  1.7243,
          -1.4300, -1.7061, -1.6303,  1.5917],
         [ 1.6219,  1.2206, -1.2381, -1.3485,  1.3313, -1.1069,  1.0334,
          -2.0924, -1.6357,  1.5909,  1.2458, -1.1609, -0.8049, -1.3531,
          -0.9376,  0.8859,  1.6996, -1.2202,  1.0820,  0.7308, -1.2358,
          -1.0992, -1.5026, -1.4375, -1.4602, -1.1142,  1.7475,  1.1803,
          -1.3430, -0.8709, -1.8097,  1.3947],
         [ 2.1073,  1.7306, -2.2338, -1.1203,  1.9999, -1.5867,  2.5636,
          -3.1595, -2.1133,  2.1561,  3.0889, -1.5696, -1.6904, -1.3930,
          -1.3914,  1.1547,  2.9417, -1.8300,  1.6380,  2.1679, -1.6485,
          -2.0128, -2.2870, -1.5896, -1.9366, -2.1480,  2.3359,  1.8150,
          -1.5552, -1.6616, -2.1907,  2.3043],
         [ 1.1886,  1.2437, -1.4980, -0.9972,  1.5075, -1.8606,  1.3965,
          -2.5666, -1.7905,  1.3833,  2.0466, -1.0235, -1.2702, -1.4663,
          -1.0901,  0.9523,  1.9727, -1.5563,  1.0805,  1.2464, -1.1647,
          -1.1966, -1.6654, -1.3937, -1.4058, -1.0208,  1.5754,  1.4129,
          -0.6809, -1.0764, -1.6798,  1.4890],
         [ 2.1616,  2.8866, -1.8236, -1.9445,  1.5432, -2.2275,  1.6294,
          -3.8109, -2.2891,  2.6172,  2.3343, -2.1489, -1.6132, -2.7077,
          -1.2686,  2.1672,  2.5550, -1.5281,  2.0896,  1.9878, -2.7728,
          -1.6999, -2.8328, -1.8524, -2.1595, -2.2892,  2.5028,  2.0283,
          -1.9202, -2.3185, -2.3068,  2.4383],
         [ 1.9864,  1.9915, -1.8646, -1.3507,  0.9601, -1.5085,  1.1553,
          -3.4755, -1.8187,  1.6508,  1.6185, -2.0985, -1.7440, -1.7783,
          -0.8436,  1.3437,  2.1209, -1.7947,  1.9013,  1.8056, -1.8143,
          -1.2471, -2.7300, -1.8827, -1.6738, -1.8847,  2.3144,  2.3786,
          -1.1107, -1.8294, -1.9302,  1.3265],
         [ 1.6025,  1.3192, -1.4151, -1.2155,  0.7213, -0.6768,  1.0358,
          -1.9912, -1.5215,  1.5750,  1.4255, -1.7228, -0.8919, -0.9822,
          -1.0790,  1.4318,  1.7248, -0.9936,  1.2534,  1.1035, -1.2734,
          -1.1282, -2.0921, -1.3299, -1.5092, -1.3850,  1.7548,  1.3872,
          -1.1741, -1.1606, -1.2676,  1.0344],
         [ 1.4870,  1.8449, -1.9557, -1.0469,  1.2397, -1.3340,  1.4182,
          -2.9465, -1.8189,  1.7128,  1.7590, -1.8033, -1.3067, -1.1896,
          -0.9703,  1.1083,  2.1396, -1.3173,  1.8216,  1.5079, -1.3734,
          -1.6205, -2.0248, -1.1611, -1.5716, -1.3656,  1.7342,  1.3977,
          -1.4448, -1.4903, -2.0422,  1.2449],
         [ 1.6040,  1.9264, -1.7429, -1.0699,  1.1816, -1.2980,  1.6209,
          -2.5179, -1.7121,  2.0327,  1.5765, -1.7725, -1.0152, -1.6321,
          -1.2700,  1.4600,  1.8843, -1.2230,  1.3696,  1.6763, -1.3481,
          -1.4047, -2.0509, -1.1215, -1.4415, -1.7635,  2.2554,  1.3703,
          -1.5907, -1.2684, -1.6582,  1.6459],
         [ 1.1370,  1.7319, -1.4918, -1.3967,  1.0203, -1.6225,  1.4839,
          -2.7887, -1.4856,  1.6902,  2.1873, -1.3298, -1.4039, -2.0703,
          -1.3488,  1.3681,  2.0243, -1.4072,  1.1056,  2.0248, -1.2617,
          -1.3698, -1.7494, -1.5010, -1.4814, -1.6138,  1.8194,  1.4331,
          -1.0447, -1.1211, -1.3224,  1.6938],
         [ 1.7039,  2.0997, -1.8686, -1.3845,  1.3609, -1.5962,  1.7953,
          -3.1800, -1.7383,  1.8778,  2.0654, -1.7684, -1.6988, -1.7084,
          -1.3317,  1.4624,  2.1720, -1.5597,  1.5962,  1.7082, -1.7485,
          -1.5911, -2.5367, -1.4307, -1.6555, -1.5369,  2.1989,  1.8450,
          -1.2769, -1.6391, -1.8504,  1.7755],
         [ 1.6119,  1.9214, -1.9612, -1.3650,  1.2753, -1.5889,  1.5575,
          -2.9231, -1.6872,  1.3698,  2.0131, -1.7506, -1.6986, -1.6560,
          -1.2844,  1.6306,  2.2376, -1.4056,  1.2708,  1.5068, -1.5512,
          -1.3649, -2.2861, -1.2845, -1.8462, -1.4896,  2.1264,  1.9326,
          -1.0553, -1.1235, -1.9960,  1.4079],
         [ 1.4301,  1.6976, -1.5168, -0.9535,  1.6325, -1.7387,  1.4128,
          -2.7335, -1.7715,  1.5925,  1.9481, -1.3894, -1.4043, -1.5267,
          -1.3144,  1.1887,  1.9341, -1.3407,  1.1666,  1.2781, -1.2635,
          -1.3617, -1.9854, -1.5026, -1.3402, -1.1183,  1.4893,  1.5588,
          -0.9520, -1.0904, -2.0743,  1.6023]]], grad_fn=<AddBackward0>) torch.Size([1, 18, 32])
batch number:  9
#### arr_b tensor([[[ 1.6416,  0.2271, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 1.8722,  0.3001, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.2511,  0.3824, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.6105,  0.4627, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.8426,  0.5884, -0.2861, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2659,  0.5711, -0.2796, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.8512,  0.6076, -0.2809, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 4.3783,  0.6288, -0.2535, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.4571,  0.8924, -0.2310, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.3584,  0.7907,  0.1813, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.1351,  0.7417,  0.2302, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 4.3846,  0.7205,  0.3123, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3435, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4078, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3785, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3619, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 1.5889,  0.3488, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459]]]) torch.Size([1, 24, 14])
#### mat_b tensor([[[ 1.3877,  1.2149, -1.5306, -1.0352,  0.9944, -1.0195,  1.2085,
          -2.0864, -1.5635,  1.0887,  1.6249, -1.3643, -1.0586, -1.0055,
          -0.9676,  1.1060,  1.6170, -0.9538,  1.0071,  0.9574, -1.1360,
          -1.2977, -1.8460, -1.0276, -1.3331, -0.9361,  1.3659,  1.2742,
          -1.0188, -1.2607, -1.6004,  1.0238],
         [ 1.3309,  1.5322, -1.3954, -0.5335,  1.0954, -0.8182,  1.1842,
          -2.0495, -1.2530,  1.1585,  1.4403, -1.1566, -1.4255, -0.9336,
          -0.9961,  0.9533,  1.5126, -0.8521,  1.0636,  1.3997, -1.1195,
          -1.1926, -1.7754, -1.2004, -0.8873, -1.3967,  1.3629,  1.3093,
          -0.8726, -1.3343, -1.2640,  1.3723],
         [ 1.8058,  1.5986, -1.8676, -1.1295,  1.3111, -1.5875,  1.6115,
          -2.9347, -1.8035,  1.7956,  2.0334, -1.6647, -1.3392, -1.3114,
          -1.2798,  1.4429,  2.1685, -1.6129,  1.8939,  1.8948, -1.4846,
          -1.7804, -2.2185, -1.6122, -1.5841, -1.2498,  1.9065,  1.6949,
          -1.4641, -1.6681, -2.2183,  1.4935],
         [ 1.4617,  1.6348, -1.8373, -0.8088,  1.4335, -1.3791,  1.5481,
          -2.6430, -1.7792,  1.7324,  1.7374, -1.4889, -1.4786, -1.2913,
          -1.1857,  1.3672,  2.0290, -1.3606,  1.3316,  1.7475, -1.1831,
          -1.5079, -1.8951, -1.4021, -1.0717, -1.5359,  1.7232,  1.6639,
          -1.3193, -1.1593, -2.0452,  1.7189],
         [ 1.5012,  1.7163, -1.4695, -1.0485,  1.3853, -1.7285,  1.4362,
          -2.8241, -1.6435,  2.0534,  1.8480, -1.6687, -1.3118, -1.5745,
          -0.6280,  1.5610,  2.1492, -1.3666,  1.5470,  1.4015, -1.9413,
          -1.3754, -2.0908, -1.3539, -1.6783, -1.4985,  1.5213,  1.6278,
          -1.2864, -1.3450, -2.0000,  1.3405],
         [ 1.9275,  1.9649, -1.7090, -1.3300,  1.6384, -1.9623,  1.9154,
          -3.2991, -1.9582,  2.2993,  2.4775, -1.7728, -1.3084, -1.8868,
          -1.0986,  1.3509,  2.5802, -1.8159,  2.0122,  1.9807, -1.9756,
          -1.9521, -2.2876, -1.9134, -1.9208, -1.8653,  2.0544,  1.6351,
          -1.5533, -1.5957, -2.3463,  1.6658],
         [ 1.7764,  1.7394, -2.0187, -1.1794,  0.8916, -1.4987,  1.4340,
          -2.8303, -1.7124,  1.1018,  2.2875, -2.0798, -1.6205, -1.3358,
          -1.3450,  1.9987,  2.2483, -1.3515,  1.8275,  1.8163, -1.7636,
          -1.6684, -2.4418, -1.4368, -1.6507, -1.3998,  1.8068,  1.9011,
          -1.5798, -1.5828, -2.3773,  1.4845],
         [ 2.0999,  1.9593, -2.0983, -1.1391,  1.6236, -2.4289,  1.0605,
          -3.1736, -2.2431,  2.2275,  1.7767, -2.1434, -1.5035, -1.8768,
          -0.9564,  1.8279,  2.2298, -1.7631,  1.8450,  1.4195, -1.8066,
          -1.3262, -2.2587, -1.8706, -1.8501, -1.3129,  2.4761,  2.3205,
          -1.6010, -1.2638, -2.5485,  1.4133],
         [ 2.1725,  2.1384, -1.8832, -1.2800,  1.9723, -2.1987,  1.8172,
          -3.6273, -2.4154,  2.3504,  2.7322, -1.9106, -1.8075, -2.0021,
          -1.4361,  1.4315,  2.6626, -2.0005,  2.1325,  2.2766, -1.9762,
          -2.0441, -2.5582, -2.0385, -1.9345, -1.8192,  2.1941,  2.2960,
          -1.6527, -2.0539, -2.6194,  2.0571],
         [ 2.4324,  1.7270, -2.0918, -1.4358,  1.2174, -1.6785,  1.6667,
          -3.4134, -1.7874,  1.9924,  1.9817, -1.8365, -1.9570, -1.8366,
          -1.2718,  1.5276,  2.5945, -2.2340,  1.9376,  2.0201, -1.7115,
          -1.7612, -2.4006, -1.8925, -1.9584, -1.6517,  2.6864,  2.5467,
          -1.3758, -1.6387, -2.0964,  1.5626],
         [ 2.1817,  2.0942, -1.6217, -1.3148,  1.6741, -2.0355,  1.9423,
          -3.6076, -2.0041,  2.0133,  2.8566, -1.8092, -1.9403, -2.0890,
          -1.5356,  1.6369,  2.6115, -1.8822,  2.1227,  2.4060, -2.0266,
          -2.0541, -2.5044, -2.2132, -1.8433, -1.8445,  2.0322,  2.1071,
          -1.4099, -2.1091, -2.3873,  2.1846],
         [ 2.4307,  2.9528, -2.1299, -2.0104,  2.0031, -2.0213,  2.5757,
          -4.3162, -2.7140,  2.3168,  3.2658, -2.2502, -2.5016, -2.9776,
          -2.6375,  1.9645,  3.1962, -2.5393,  2.2020,  3.3567, -1.8818,
          -2.4404, -2.6763, -2.5762, -2.4906, -3.0545,  3.3629,  2.5056,
          -1.8221, -2.0834, -2.4367,  2.8181],
         [ 1.4917,  1.7658, -1.8547, -1.3335,  0.9978, -1.5904,  1.1951,
          -2.8825, -1.7851,  1.9172,  1.5748, -1.7192, -1.3022, -1.5895,
          -0.6282,  1.4237,  1.9847, -1.6108,  1.3630,  1.1184, -1.9025,
          -1.0876, -2.2670, -1.4077, -1.7915, -1.6169,  2.1825,  1.7501,
          -0.9094, -1.2282, -1.4200,  0.9221],
         [ 2.1102,  2.7472, -2.3530, -1.9057,  2.3405, -2.7733,  2.3025,
          -4.6390, -2.6891,  2.3979,  3.2533, -2.9329, -2.3274, -2.6755,
          -2.7652,  2.0588,  3.6094, -2.7836,  2.3031,  2.8613, -2.3397,
          -2.2322, -3.5641, -2.7452, -2.9353, -2.1937,  2.8536,  3.1206,
          -1.6237, -1.9369, -3.4686,  2.1634],
         [ 1.9735,  1.9805, -2.1465, -1.3294,  1.8733, -1.6218,  2.4632,
          -3.9805, -2.4388,  2.7964,  2.8421, -2.4567, -1.9388, -2.0931,
          -1.7489,  1.2865,  2.9470, -2.3058,  1.6220,  2.3049, -1.9083,
          -1.7055, -1.9170, -2.0600, -2.3830, -1.8600,  3.0388,  2.2479,
          -2.3770, -1.7078, -2.4967,  2.3086],
         [ 2.1418,  2.0161, -1.7566, -1.5374,  1.6268, -1.9308,  1.6104,
          -3.3416, -2.0191,  1.9264,  2.6167, -1.5952, -1.7535, -1.9607,
          -1.5349,  1.6123,  2.4631, -1.7768,  2.1556,  2.3099, -1.9986,
          -1.9812, -2.5648, -2.0210, -1.7582, -1.8682,  2.1441,  2.1122,
          -1.4728, -2.0443, -2.2298,  2.2431],
         [ 1.3320,  1.4719, -1.5316, -1.3395,  1.2996, -1.8429,  1.6570,
          -3.0771, -1.5987,  1.4714,  2.3493, -1.3890, -1.4632, -1.8387,
          -1.5183,  1.5479,  2.1147, -1.7558,  1.5264,  2.0087, -1.5315,
          -1.5207, -2.1712, -1.9715, -1.2737, -1.5845,  1.5039,  1.6848,
          -0.8339, -1.2320, -2.3141,  1.8482],
         [ 1.3190,  2.1084, -1.4928, -1.5559,  1.2790, -1.8664,  1.2725,
          -3.1097, -1.5225,  2.0568,  1.7249, -1.3018, -1.2455, -2.1154,
          -1.1356,  1.6095,  1.8933, -1.2959,  1.3730,  1.6146, -1.8444,
          -1.2267, -2.0857, -1.7916, -1.6017, -1.5323,  1.5639,  1.4113,
          -1.0689, -1.3733, -1.8723,  1.9300],
         [ 2.5606,  2.4533, -1.8762, -1.6646,  1.5717, -2.2587,  2.1788,
          -4.4629, -2.1248,  2.2200,  2.9008, -2.1603, -2.0155, -2.7175,
          -2.0198,  1.9940,  2.9819, -2.4835,  2.4640,  3.0967, -2.1536,
          -2.3981, -2.9726, -2.6993, -2.2198, -2.2063,  2.5280,  2.5380,
          -1.6844, -2.2350, -2.8424,  2.5148],
         [ 1.5743,  1.6862, -1.6843, -1.0128,  1.6319, -1.4002,  1.6848,
          -2.4065, -1.9603,  1.6285,  2.1757, -1.8653, -1.2107, -1.4175,
          -1.3659,  1.7439,  2.1262, -1.2744,  1.3696,  1.5747, -1.4234,
          -1.4817, -1.9312, -1.1058, -1.8260, -1.7262,  2.0818,  1.3649,
          -1.5711, -0.9070, -1.9090,  1.5940],
         [ 2.2154,  2.0383, -1.8273, -1.4410,  1.8623, -2.2042,  2.0012,
          -3.6757, -2.2531,  2.1819,  2.7544, -1.9571, -1.9380, -2.0400,
          -1.5096,  1.2799,  3.0176, -2.2860,  1.9725,  2.4778, -1.6996,
          -2.1148, -2.3431, -2.0992, -2.2603, -1.7078,  2.3031,  2.1660,
          -1.5500, -1.9282, -2.5391,  1.8749],
         [ 1.6285,  1.6029, -1.6970, -1.0178,  1.5952, -1.6040,  1.0343,
          -2.9282, -1.8326,  2.3020,  1.4859, -1.4419, -1.2814, -1.4236,
          -0.4223,  1.3016,  1.8059, -1.2558,  1.6171,  0.9868, -1.8598,
          -1.2677, -1.9484, -1.5585, -1.3750, -1.3003,  1.5730,  1.5865,
          -1.4740, -1.2684, -2.0249,  1.4385],
         [ 1.8552,  2.0950, -1.9422, -1.3766,  1.9140, -1.9921,  1.9137,
          -3.8073, -2.0400,  2.2238,  2.2595, -1.9736, -1.8407, -1.8673,
          -1.3953,  1.9085,  2.5532, -1.9254,  2.1056,  2.0682, -2.0894,
          -1.7607, -2.7199, -1.9712, -2.1798, -1.6407,  2.2243,  2.2062,
          -1.5941, -1.7173, -2.4895,  2.0173],
         [ 1.4419,  1.6173, -1.3788, -0.9448,  1.1790, -1.4061,  1.0385,
          -2.3038, -1.6536,  1.4808,  1.4327, -1.1260, -1.2227, -1.4003,
          -0.7989,  1.1790,  1.5088, -1.1957,  1.2954,  1.1402, -1.3293,
          -1.3323, -1.6343, -1.3954, -1.0713, -1.2905,  1.6677,  1.3473,
          -1.0199, -1.0725, -1.6002,  1.2795]]], grad_fn=<AddBackward0>) torch.Size([1, 24, 32])
batch number:  10
#### arr_b tensor([[[ 2.8578,  0.3947, -0.1121, -0.3499, -0.3499, -0.3499, -0.3499,
          -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499],
         [ 4.7615,  0.7408, -0.2487, -0.3499, -0.3499, -0.3499, -0.3499,
          -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499],
         [ 2.8578,  0.3947, -0.1121, -0.3499, -0.3499, -0.3499, -0.3499,
          -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499],
         [ 4.6746,  0.6512,  0.1145, -0.3499, -0.3499, -0.3499, -0.3499,
          -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499],
         [ 4.4779,  0.6081,  0.1575, -0.3499, -0.3499, -0.3499, -0.3499,
          -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499],
         [ 2.8578,  0.3947, -0.1121, -0.3499, -0.3499, -0.3499, -0.3499,
          -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499],
         [ 2.8578,  0.3947, -0.1121, -0.3499, -0.3499, -0.3499, -0.3499,
          -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499],
         [ 2.8578,  0.3947, -0.1121, -0.3499, -0.3499, -0.3499, -0.3499,
          -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499],
         [ 3.8168,  0.5894,  0.2298, -0.3499, -0.3499, -0.3499, -0.3499,
          -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499],
         [ 2.8578,  0.2574, -0.1121, -0.3499, -0.3499, -0.3499, -0.3499,
          -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499],
         [ 2.8578,  0.3140, -0.1121, -0.3499, -0.3499, -0.3499, -0.3499,
          -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499, -0.3499]]]) torch.Size([1, 11, 14])
#### mat_b tensor([[[ 1.3955,  1.7858, -1.8223, -1.0991,  1.5044, -1.8164,  1.3685,
          -2.8636, -1.7432,  1.7046,  1.6756, -1.8087, -1.8650, -1.4299,
          -1.2849,  1.2843,  1.9977, -1.7406,  1.4681,  1.2064, -1.4989,
          -1.0311, -2.1592, -1.8514, -1.4991, -1.3100,  2.1668,  2.0190,
          -0.8376, -1.2302, -1.8609,  1.4866],
         [ 1.9520,  2.7891, -2.1886, -1.8463,  1.7115, -2.0578,  2.4538,
          -3.5325, -2.7290,  2.8532,  2.6937, -2.3510, -1.7254, -2.2888,
          -1.6141,  2.3243,  2.5805, -1.8184,  1.9370,  1.8932, -2.3646,
          -2.3741, -2.6222, -1.1511, -1.8525, -2.0897,  2.9490,  1.8372,
          -2.0312, -2.0528, -1.8014,  1.9599],
         [ 1.3601,  2.1191, -1.7522, -1.2376,  1.5849, -1.9820,  1.3636,
          -2.8607, -1.9084,  1.8815,  1.7113, -1.4846, -1.6228, -1.8176,
          -1.1771,  1.8564,  1.6654, -1.5631,  1.6887,  1.3043, -1.6999,
          -1.3331, -2.2695, -1.4511, -1.4868, -1.6610,  2.0925,  1.6344,
          -0.9171, -1.0063, -1.6527,  1.5558],
         [ 2.2684,  3.0468, -2.7292, -1.8829,  2.0657, -2.9824,  2.4560,
          -4.3632, -2.9611,  2.8157,  3.0067, -2.8358, -2.1884, -2.8093,
          -1.9769,  2.7315,  2.9852, -2.5576,  2.6180,  2.4896, -2.5862,
          -1.9439, -3.0722, -2.6330, -2.4889, -2.5724,  3.4847,  2.5470,
          -2.2414, -1.5966, -3.4785,  2.7487],
         [ 2.4047,  2.9276, -2.1823, -2.0453,  1.7383, -2.5089,  1.5329,
          -3.6345, -2.4936,  2.0452,  2.2193, -2.0386, -2.0618, -2.6978,
          -1.8060,  2.6405,  2.6054, -1.9708,  2.3467,  2.3984, -2.2069,
          -1.8262, -3.1390, -2.5649, -2.1603, -2.5519,  2.7962,  2.6212,
          -1.4014, -1.4610, -2.9530,  2.2306],
         [ 1.6911,  1.7374, -2.0186, -1.3109,  1.2674, -1.4436,  1.4404,
          -2.8823, -2.0819,  2.3208,  1.8548, -2.2339, -1.3433, -1.7488,
          -1.3349,  1.7626,  2.2484, -1.6433,  1.6717,  1.6847, -1.7324,
          -1.3897, -2.2034, -1.5195, -1.9363, -1.9093,  2.5192,  1.9630,
          -1.7476, -1.3440, -1.7417,  1.4909],
         [ 2.0800,  2.0712, -2.0040, -1.2690,  1.3752, -1.9224,  1.8973,
          -3.3310, -1.7676,  1.6697,  2.5116, -2.1019, -2.0043, -2.0037,
          -1.5288,  2.0187,  2.4340, -1.6504,  1.9324,  2.2862, -1.8537,
          -1.7053, -2.5122, -1.8383, -1.9036, -1.8131,  2.2112,  2.0605,
          -1.5570, -1.8675, -2.3403,  2.0530],
         [ 1.6662,  1.7446, -2.0040, -0.6483,  1.6195, -1.5728,  1.3648,
          -2.8459, -1.9927,  2.2975,  1.8905, -1.8738, -1.8736, -1.1077,
          -1.1325,  1.2375,  2.3797, -1.5623,  1.8201,  2.0018, -1.6971,
          -1.6418, -2.2477, -1.6000, -1.3379, -1.5086,  2.0420,  2.2208,
          -1.4650, -1.8639, -1.8995,  1.4351],
         [ 2.2916,  2.1081, -2.3258, -1.6307,  1.3286, -1.8414,  1.7118,
          -3.7800, -1.9551,  2.2516,  2.6794, -2.0666, -2.2377, -2.0523,
          -1.2404,  1.7895,  2.5829, -1.7518,  1.8854,  2.0808, -2.2586,
          -1.5715, -2.9526, -2.0479, -2.2065, -1.9540,  2.2494,  2.5414,
          -1.1781, -2.1955, -2.0565,  1.9715],
         [ 2.3295,  2.0514, -2.2099, -1.6742,  1.6430, -1.9748,  1.8817,
          -3.5743, -2.3858,  2.2483,  2.6116, -2.1287, -1.8844, -1.9641,
          -1.4926,  1.4634,  2.9585, -1.9987,  2.0779,  2.2268, -1.7295,
          -2.2273, -2.4443, -1.9088, -2.2736, -1.6504,  2.2789,  2.1806,
          -1.8843, -2.1423, -2.5547,  1.6722],
         [ 1.7852,  1.6900, -2.0519, -1.2890,  1.1620, -1.3915,  1.5130,
          -2.6974, -2.1317,  2.1260,  2.0647, -1.9741, -1.5558, -1.5922,
          -1.2826,  1.5818,  2.2604, -1.7220,  1.5466,  1.8964, -1.6522,
          -1.4908, -1.9682, -1.5508, -1.9883, -1.8327,  2.6912,  1.8779,
          -1.7299, -1.4384, -1.6776,  1.5344]]], grad_fn=<AddBackward0>) torch.Size([1, 11, 32])
batch number:  11
          -2.3493,  2.9109,  3.2716, -2.7220,  2.1676,  2.8607, -2.9835,
          -2.3531, -3.5834, -2.6802, -2.7969, -2.2136,  2.8290,  3.0252,
          -2.2231, -2.5999, -3.5974,  2.8456],
         [ 2.4543,  2.5208, -2.6083, -1.8440,  1.7532, -1.8923,  2.0815,
          -3.7031, -2.5254,  2.1794,  2.7742, -2.6104, -2.2089, -1.7516,
          -1.8043,  2.1368,  3.0496, -2.0227,  2.3925,  2.2022, -2.1204,
          -2.2695, -2.9949, -2.0001, -2.5090, -1.9586,  2.6264,  2.5379,
          -2.0362, -1.8722, -3.0544,  2.0242],
         [ 2.1032,  1.7115, -1.9608, -1.8716,  1.6395, -2.0362,  2.0471,
          -3.4886, -2.1046,  1.8193,  3.0971, -1.9943, -1.7210, -2.0709,
          -1.8441,  1.4867,  2.9822, -2.0569,  2.3712,  2.6630, -1.5654,
          -2.2748, -2.2141, -2.1428, -2.4685, -1.7334,  2.1605,  1.7979,
          -1.7800, -2.0234, -2.5697,  1.9032],
         [ 2.4460,  2.5433, -2.4865, -1.4999,  1.9449, -2.1285,  2.2631,
          -4.1268, -2.6533,  2.7853,  2.6668, -2.5924, -2.1628, -2.2948,
          -2.0369,  2.2021,  3.0809, -2.3863,  2.0933,  2.9841, -2.0321,
          -2.3345, -3.0036, -2.2283, -2.2184, -2.3599,  2.7145,  2.8124,
          -2.0364, -2.1612, -2.9045,  2.3932],
         [ 2.0015,  3.2007, -2.4332, -2.0886,  2.4814, -2.6497,  2.2599,
          -3.8081, -3.1495,  3.0681,  2.5915, -2.0775, -2.1240, -2.8365,
          -1.8673,  2.5937,  2.4897, -1.9906,  2.1388,  2.1110, -2.4351,
          -2.3586, -2.9914, -1.6195, -1.8033, -2.5878,  3.2966,  2.3130,
          -2.0500, -1.9282, -1.9796,  2.8042],
         [ 1.8381,  2.0896, -1.6605, -1.1535,  2.1126, -1.6940,  2.3802,
          -3.2147, -2.1022,  2.3423,  2.1480, -2.1474, -1.5670, -1.9683,
          -2.1397,  1.5993,  2.5224, -1.8621,  1.7166,  2.3555, -1.6103,
          -1.8887, -2.3045, -1.9541, -1.7408, -1.9605,  2.2958,  1.8656,
          -1.9483, -1.8146, -2.6711,  2.3934],
         [ 2.6419,  3.4693, -3.3198, -2.2356,  3.1115, -3.8267,  2.8162,
          -5.5871, -3.7774,  3.7445,  3.8811, -3.4279, -2.9421, -2.6723,
          -2.9178,  2.5565,  4.3624, -3.4222,  3.9558,  3.5689, -2.8914,
          -3.1009, -3.7454, -3.8061, -3.0816, -2.4728,  3.5930,  3.4425,
          -2.6159, -2.9253, -4.6110,  3.1732],
         [ 3.8286,  3.5976, -3.2807, -2.8218,  2.8675, -3.2794,  3.2096,
          -5.6959, -3.5879,  3.1415,  4.0575, -3.0701, -3.4825, -3.1326,
          -2.2171,  2.6263,  4.6101, -3.6481,  3.1322,  3.7051, -2.9934,
          -3.1950, -4.0660, -3.3924, -3.8983, -3.2752,  4.0564,  3.8040,
          -2.1856, -3.0123, -3.8285,  3.0845],
         [ 2.2726,  1.6855, -1.6215, -1.2112,  1.6648, -2.0263,  1.9518,
          -3.0940, -1.8458,  1.6167,  2.7677, -1.1756, -1.9029, -1.8130,
          -1.4822,  1.3538,  2.2759, -1.9715,  1.9136,  2.3951, -1.5361,
          -1.9314, -2.2183, -2.4799, -1.6866, -1.6586,  1.8743,  1.9726,
          -1.1119, -1.8721, -2.4421,  2.4773],
         [ 1.7568,  1.9487, -1.7811, -1.8849,  1.2758, -1.7148,  2.0841,
          -2.9767, -2.0627,  2.2480,  2.0240, -2.2601, -1.0064, -2.0812,
          -1.6841,  2.1782,  2.3046, -1.6521,  1.5685,  1.4646, -2.2218,
          -1.7390, -2.8931, -1.7741, -2.0180, -1.7255,  2.0502,  1.7598,
          -1.7823, -1.6696, -2.5256,  1.4610],
         [ 2.2921,  2.3769, -2.2319, -2.0009,  1.6211, -2.3463,  2.2185,
          -4.1935, -2.0247,  2.2643,  2.8798, -2.3689, -2.1677, -2.7659,
          -2.0710,  2.2566,  2.8288, -2.1759,  2.0794,  2.7640, -2.2339,
          -2.1310, -3.2706, -2.3250, -2.2141, -2.0711,  2.4496,  2.5999,
          -1.6493, -2.2330, -2.5926,  2.2422],
         [ 2.6281,  2.4763, -2.4504, -2.2374,  2.6161, -2.4075,  2.9219,
          -4.2759, -3.0822,  2.9674,  3.3310, -2.6389, -2.2208, -2.7113,
          -2.5794,  1.9709,  3.7853, -2.8490,  2.5675,  3.2559, -2.0030,
          -2.9195, -3.0945, -2.3453, -2.7851, -2.6760,  3.3524,  2.6933,
          -2.3862, -2.3740, -2.8097,  2.7195],
         [ 2.5708,  2.2888, -2.2662, -1.6636,  1.4876, -1.8714,  1.4227,
          -3.2441, -1.9728,  2.3404,  1.9586, -2.4667, -2.0030, -1.6778,
          -1.3444,  1.8971,  3.0676, -1.9959,  2.1869,  1.9357, -2.2229,
          -1.8252, -2.7756, -2.0215, -2.4384, -1.8532,  2.6901,  2.5724,
          -1.7467, -1.7591, -2.4592,  1.6454],
         [ 2.9729,  2.2285, -2.7100, -1.6742,  1.9751, -2.2851,  2.1600,
          -4.1872, -2.4306,  2.9260,  2.6836, -2.4940, -2.2799, -2.1258,
          -1.6784,  2.2139,  3.0312, -2.3901,  2.5700,  2.4426, -2.4528,
          -2.3058, -3.2559, -2.3616, -2.2679, -1.9775,  2.9556,  2.9257,
          -2.0932, -2.3745, -2.8867,  2.3149],
         [ 2.5391,  2.5504, -2.1908, -1.8541,  1.6882, -2.0810,  2.0460,
          -3.2917, -2.0162,  2.2977,  2.1634, -2.3891, -2.0093, -2.2608,
          -1.8035,  1.7701,  2.8245, -2.1598,  2.1391,  2.1996, -1.9763,
          -2.0155, -2.8107, -1.8567, -2.1957, -2.1962,  2.9698,  2.1990,
          -1.9198, -1.8714, -2.4456,  2.0121],
         [ 1.9980,  1.5777, -2.0786, -0.8364,  1.7479, -1.1683,  1.6605,
          -3.2348, -1.9198,  2.2845,  1.9178, -1.5722, -1.6985, -1.1948,
          -0.9093,  1.0765,  2.1061, -1.5938,  1.3433,  1.7067, -1.6650,
          -1.6817, -2.1303, -1.6569, -1.7629, -1.4429,  1.8695,  1.9051,
          -1.6667, -1.8662, -1.7963,  1.7348],
         [ 1.5500,  1.1681, -1.5993, -0.9023,  1.2001, -1.2414,  1.2662,
          -2.3961, -1.5024,  1.3950,  1.8596, -1.3629, -1.3282, -1.0124,
          -0.9611,  1.0563,  1.8943, -1.4788,  1.6260,  1.6522, -1.2678,
          -1.4028, -1.6378, -1.4483, -1.5331, -1.2038,  1.7035,  1.5234,
          -1.1704, -1.2555, -1.8194,  1.3864]]], grad_fn=<AddBackward0>) torch.Size([1, 24, 32])
batch number:  12
#### arr_b tensor([[[ 1.6416,  0.2271, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 1.8722,  0.3001, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.2511,  0.3824, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.6105,  0.4627, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.8426,  0.5884, -0.2861, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2659,  0.5711, -0.2796, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.8512,  0.6076, -0.2809, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 4.3783,  0.6288, -0.2535, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.4571,  0.8924, -0.2310, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.3584,  0.7907,  0.1813, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.1351,  0.7417,  0.2302, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 4.3846,  0.7205,  0.3123, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3435, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4078, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3785, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3619, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 1.5889,  0.3488, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459]]]) torch.Size([1, 24, 14])
#### mat_b tensor([[[ 1.0884,  1.4966, -1.4962, -0.9473,  1.3168, -1.3162,  1.0822,
          -1.7754, -1.6522,  1.6318,  1.2601, -1.3492, -1.1675, -1.1698,
          -1.1168,  1.2861,  1.7268, -1.1311,  1.4198,  1.2745, -1.2657,
          -1.1952, -1.7840, -1.1885, -0.9973, -1.5797,  1.6877,  1.4537,
          -1.0834, -1.0147, -1.4782,  1.3290],
         [ 2.1167,  1.9381, -1.8852, -1.3431,  1.4305, -1.4776,  1.5957,
          -2.6271, -1.6398,  1.4925,  2.0997, -1.6239, -1.9885, -1.5132,
          -1.4180,  1.2860,  2.2878, -1.5032,  1.5792,  1.8578, -1.6198,
          -1.6662, -2.3702, -1.8617, -1.6708, -1.8437,  1.9626,  1.8499,
          -1.2457, -1.9202, -1.9370,  1.8117],
         [ 2.3830,  1.9688, -2.2189, -1.7594,  1.6080, -1.6756,  1.9065,
          -3.1474, -2.3572,  1.8201,  2.3543, -2.1626, -1.8256, -1.8013,
          -1.7483,  1.7213,  2.8690, -1.8495,  1.9589,  2.0405, -1.6213,
          -2.2759, -2.4905, -1.8327, -2.3489, -1.6943,  2.3003,  2.0471,
          -1.8745, -2.0160, -2.5201,  1.6482],
         [ 2.5200,  2.2212, -2.4178, -1.6134,  1.6970, -1.6849,  1.6503,
          -3.3338, -2.3081,  2.3247,  2.0574, -2.3198, -1.8187, -1.6374,
          -1.3297,  1.3712,  2.6885, -1.7812,  1.8314,  1.7336, -2.0261,
          -1.8762, -2.9226, -2.1341, -2.1642, -1.8265,  2.4019,  2.4327,
          -1.8225, -2.1973, -2.5017,  1.7831],
         [ 2.0517,  2.1086, -1.9370, -1.8584,  2.0678, -1.8862,  2.2192,
          -3.3819, -2.5227,  2.2977,  2.5169, -1.7847, -1.8331, -2.3208,
          -2.1184,  1.5259,  2.6686, -2.2107,  1.6362,  2.4641, -1.5819,
          -2.3478, -2.4598, -1.8433, -1.9556, -2.1275,  2.5773,  2.0866,
          -1.5726, -1.9608, -2.0306,  2.0334],
         [ 2.1026,  2.5002, -2.5166, -2.1386,  1.6828, -2.3762,  2.1500,
          -3.6309, -2.4165,  2.7922,  2.6523, -2.6039, -1.6175, -2.3093,
          -1.9110,  2.3416,  3.1203, -1.9987,  2.2126,  2.0385, -2.3009,
          -2.0825, -3.0970, -1.9522, -2.7238, -2.0128,  2.5284,  2.2064,
          -1.7111, -1.7409, -2.7153,  1.6448],
         [ 1.8968,  2.8857, -1.8236, -2.5641,  1.5792, -2.0333,  1.9819,
          -3.4281, -2.0089,  1.9672,  2.2145, -2.5612, -1.7921, -2.9736,
          -1.9959,  2.5275,  2.3361, -1.6200,  1.5633,  1.6189, -2.5025,
          -1.4864, -3.0929, -1.8674, -2.4632, -2.3606,  2.6995,  2.0915,
          -1.7288, -1.6295, -2.1943,  2.0712],
         [ 2.4963,  2.2690, -2.5633, -1.7196,  2.5949, -1.8161,  2.7193,
          -4.3811, -2.5085,  3.3970,  2.7966, -2.5762, -1.9202, -2.1494,
          -2.1654,  1.9237,  3.0943, -2.3102,  2.4615,  2.6841, -2.1451,
          -2.2848, -2.7620, -2.4820, -2.7192, -2.2708,  3.0026,  2.3202,
          -2.6192, -2.0626, -2.9024,  2.9010],
         [ 2.7777,  2.6783, -2.2387, -2.3514,  2.0041, -1.9560,  2.2070,
          -3.7379, -2.4819,  2.4584,  2.4428, -2.3951, -1.9164, -2.6237,
          -1.8112,  2.0680,  2.9151, -2.0576,  1.8739,  1.8980, -2.4916,
          -2.2632, -3.0018, -2.1252, -2.6802, -2.2237,  2.8717,  2.3539,
          -2.3802, -2.0451, -2.7465,  2.2689],
         [ 2.1431,  2.0774, -2.1652, -1.3300,  1.4330, -2.0020,  2.3590,
          -3.9110, -2.1182,  2.8369,  2.6473, -2.4343, -1.6995, -2.0123,
          -1.8362,  1.5020,  2.5715, -2.3322,  2.0960,  2.2220, -1.9157,
          -2.0404, -2.4755, -2.2681, -2.0445, -1.4671,  2.3982,  2.0608,
          -1.7657, -2.0350, -2.6671,  1.8120],
         [ 2.2727,  2.4240, -2.4686, -1.9207,  2.1013, -1.9532,  2.1212,
          -3.4747, -2.4768,  2.0690,  2.4884, -2.5420, -1.9193, -2.3580,
          -1.9389,  2.2641,  2.6852, -1.6163,  1.9857,  1.7043, -2.3515,
          -1.8006, -2.9923, -1.8216, -2.5096, -2.1385,  2.7045,  2.4943,
          -2.3846, -1.9497, -2.8776,  2.4467],
         [ 2.7769,  3.7600, -2.4027, -2.7919,  2.7026, -3.9048,  3.0296,
          -5.0859, -3.1537,  4.1016,  3.7741, -3.4557, -2.5357, -3.7730,
          -2.8102,  1.7136,  4.3948, -3.5724,  2.7799,  3.5441, -2.9561,
          -2.8837, -3.6624, -3.1387, -3.3920, -2.7874,  3.6497,  3.0409,
          -2.2804, -3.1050, -3.4028,  2.6416],
         [ 2.2946,  2.9370, -2.1696, -1.7553,  2.3996, -2.9326,  1.9033,
          -3.9840, -2.7884,  2.6846,  2.5033, -2.4477, -2.4014, -2.4409,
          -1.7831,  2.1866,  3.0623, -2.5248,  2.6003,  2.4566, -2.3278,
          -2.2292, -2.8449, -2.7175, -2.2776, -2.3079,  2.8568,  2.5693,
          -1.6982, -1.9660, -3.0165,  2.1875],
         [ 3.3178,  3.1909, -3.4145, -1.7919,  2.3345, -2.6506,  2.2620,
          -4.7641, -3.3059,  3.3128,  3.2971, -3.9785, -3.1931, -1.9554,
          -2.4752,  2.6424,  3.9973, -2.8666,  3.4568,  2.6903, -2.9757,
          -2.6533, -3.8506, -2.9627, -3.2630, -2.2520,  3.6183,  3.7719,
          -2.7451, -2.8863, -3.9356,  2.3359],
         [ 2.6341,  3.0747, -2.9549, -2.0833,  3.1256, -3.3008,  3.2198,
          -5.4928, -3.5186,  3.7530,  3.2467, -3.0537, -2.4887, -3.1914,
          -2.8874,  3.2863,  3.8933, -3.1956,  2.7125,  3.5337, -2.7704,
          -2.8640, -3.5778, -3.3247, -2.7637, -2.5918,  3.4573,  3.2826,
          -2.8854, -2.5180, -4.0199,  3.7028],
         [ 2.4942,  1.8382, -2.3765, -1.4213,  1.3351, -1.8763,  1.8258,
          -3.5077, -2.2760,  2.1747,  2.4992, -2.6208, -2.1760, -1.5301,
          -1.5422,  1.4292,  3.0573, -2.4821,  2.1050,  2.2735, -1.7664,
          -1.8844, -2.4538, -2.2796, -2.4083, -1.6043,  2.5518,  2.6307,
          -1.7239, -2.1232, -2.8739,  1.5720],
         [ 3.0095,  2.7463, -2.6597, -1.8992,  1.7942, -1.9877,  2.1536,
          -4.0211, -2.4471,  2.6732,  2.8725, -2.5837, -2.5837, -2.2068,
          -1.7658,  2.1459,  2.8904, -2.0842,  2.4028,  2.3185, -2.6049,
          -2.0114, -3.3184, -2.6738, -2.4691, -2.4990,  2.9765,  2.7474,
          -1.9202, -2.6374, -2.6208,  2.6936],
         [ 2.1142,  2.4311, -2.0310, -1.8666,  1.5030, -1.4960,  1.7915,
          -2.8967, -2.5549,  1.9407,  2.0077, -1.8463, -1.3666, -1.6688,
          -0.9624,  1.8455,  2.3380, -1.4582,  1.7152,  1.2198, -2.4315,
          -1.8298, -2.5098, -1.7160, -2.0859, -2.0300,  2.3142,  1.8085,
          -1.8018, -1.7584, -2.5578,  1.6530],
         [ 2.4334,  2.9744, -2.9551, -2.1094,  2.1748, -3.0114,  2.6737,
          -4.5237, -3.0432,  2.7272,  3.6415, -3.4957, -2.9465, -2.4924,
          -2.5191,  2.1579,  4.0541, -3.0714,  3.0883,  3.1306, -2.4667,
          -2.5497, -3.1604, -2.6598, -3.1653, -2.3203,  3.5462,  3.1287,
          -2.4864, -2.5218, -3.5424,  2.2507],
         [ 2.1849,  2.3086, -2.6916, -2.0058,  1.6634, -1.9107,  2.6604,
          -3.5880, -2.5082,  2.5857,  3.0262, -2.3061, -2.1274, -2.0449,
          -2.1344,  2.0916,  3.3163, -2.1724,  1.8546,  2.6118, -1.9373,
          -2.4194, -2.5822, -1.7317, -2.4107, -2.0507,  2.8357,  2.1600,
          -1.9950, -2.1152, -2.3478,  2.2107],
         [ 2.7248,  1.8270, -2.7757, -1.6055,  1.5498, -1.6638,  2.0437,
          -3.4210, -2.0347,  2.1990,  2.2188, -2.3059, -1.8552, -1.7379,
          -1.7178,  1.7607,  3.0034, -1.8684,  2.2886,  2.1298, -1.4777,
          -2.1388, -2.5855, -1.8639, -2.6567, -1.5301,  2.6551,  2.1593,
          -2.0631, -1.7923, -2.6519,  1.5535],
         [ 1.9368,  3.0047, -1.8172, -1.7654,  1.4459, -1.9495,  1.8981,
          -3.3509, -2.2581,  2.3999,  2.2930, -2.1869, -1.9624, -2.4139,
          -1.6295,  2.0147,  2.2661, -1.7963,  1.3406,  2.2552, -2.1451,
          -1.6839, -2.7757, -1.9714, -1.9625, -2.4091,  2.5793,  1.9983,
          -1.3645, -2.0386, -1.6165,  2.0812],
         [ 2.2712,  2.1293, -1.9751, -1.5640,  1.8624, -2.0113,  2.1315,
          -3.3620, -2.4596,  2.1349,  3.0308, -1.8603, -2.1271, -2.1312,
          -2.1157,  1.9286,  2.9177, -2.1845,  2.0651,  3.0768, -1.8877,
          -2.3584, -2.4532, -2.2457, -2.1772, -2.2440,  2.5619,  2.2223,
          -1.7863, -2.3496, -2.1848,  2.5592],
         [ 1.2311,  1.3897, -1.5066, -1.0688,  1.5044, -1.7405,  1.1874,
          -2.3523, -2.0088,  1.6264,  1.6692, -1.2931, -1.1286, -1.3613,
          -1.1354,  1.1043,  1.9375, -1.4713,  1.6431,  1.3110, -1.2134,
          -1.5276, -1.6204, -1.4913, -1.1671, -1.2083,  1.5120,  1.4306,
          -1.0939, -1.2269, -1.9579,  1.1902]]], grad_fn=<AddBackward0>) torch.Size([1, 24, 32])
batch number:  13
#### arr_b tensor([[[ 1.6416,  0.2271, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 1.8722,  0.3001, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.2511,  0.3824, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.6105,  0.4627, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.8426,  0.5884, -0.2861, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2659,  0.5711, -0.2796, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.8512,  0.6076, -0.2809, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 4.3783,  0.6288, -0.2535, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.4571,  0.8924, -0.2310, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.3584,  0.7907,  0.1813, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.1351,  0.7417,  0.2302, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 4.3846,  0.7205,  0.3123, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3435, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4078, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3785, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3619, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 1.5889,  0.3488, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459]]]) torch.Size([1, 24, 14])
#### mat_b tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan]]],
       grad_fn=<AddBackward0>) torch.Size([1, 24, 32])
          -5.1727, -2.8126,  3.1727,  3.4579, -2.9365, -2.3652, -3.1676,
Traceback (most recent call last):
  File "main.py", line 89, in <module>
    main()
  File "main.py", line 85, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 48, in train
    loss, timing_loss, choice_loss  = model(arr_b.float(), arr_c.float(), arr_delta_time.float(), event_data, non_event_data, estimate_length, choice_data_dict)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 199, in forward
    event_choice_loss = self.choice_net(mat_b, mat_c, choice_data_dict, self.s_year, self.e_year)*1000
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 359, in forward
    choice_l = F.binary_cross_entropy(torch.sigmoid(logits_i), true_tar_idxs_i)  # inputs are both (N_i_2, N_i_1)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/functional.py", line 2759, in binary_cross_entropy
    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
RuntimeError: all elements of input should be between 0 and 1