CUDA availability: True
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(2.0975, grad_fn=<SumBackward0>)
Epoch 0. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 2.0975
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(1.1790, grad_fn=<SumBackward0>)
Epoch 1. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 1.1790
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(0.3982, grad_fn=<SumBackward0>)
Epoch 2. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 0.3982
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(0.0469, grad_fn=<SumBackward0>)
Epoch 3. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 0.0469
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(0.0062, grad_fn=<SumBackward0>)
Epoch 4. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 0.0062
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(0.0106, grad_fn=<SumBackward0>)
Epoch 5. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 0.0106
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(0.0160, grad_fn=<SumBackward0>)
Epoch 6. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 0.0160
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(0.0231, grad_fn=<SumBackward0>)
Epoch 7. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 0.0231
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(0.0314, grad_fn=<SumBackward0>)
/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
Epoch 8. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 0.0314
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(0.0448, grad_fn=<SumBackward0>)
Epoch 9. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 0.0448
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(0.0476, grad_fn=<SumBackward0>)
Epoch 10. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 0.0476
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(0.0543, grad_fn=<SumBackward0>)
Epoch 11. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 0.0543
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(0.0503, grad_fn=<SumBackward0>)
Epoch 12. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 0.0503
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(0.0543, grad_fn=<SumBackward0>)
Epoch 13. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 0.0543
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(0.0543, grad_fn=<SumBackward0>)
Epoch 14. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 0.0543
tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor([nan], dtype=torch.float64, grad_fn=<AddBackward0>) tensor(0.0543, grad_fn=<SumBackward0>)
Epoch 15. Total Loss: nan. Timing MLE loss: nan. Choice BCE loss 0.0543
Traceback (most recent call last):
  File "main.py", line 88, in <module>
    main()
  File "main.py", line 84, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 48, in train
    loss, timing_loss, choice_loss  = model(arr_b.float(), arr_c.float(), arr_delta_time.float(), event_data, non_event_data, estimate_length, choice_data_dict)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 189, in forward
    event_choice_loss = self.choice_net(mat_b, mat_c, choice_data_dict, self.s_year, self.e_year)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 339, in forward
    choice_l = self.loss(F.sigmoid(logits_i), true_tar_idxs_i)  # inputs are both (N_i_2, N_i_1)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 613, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/functional.py", line 2759, in binary_cross_entropy
    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
RuntimeError: all elements of input should be between 0 and 1