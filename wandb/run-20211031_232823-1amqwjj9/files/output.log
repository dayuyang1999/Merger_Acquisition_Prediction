
CUDA availability: True
  1%|██                                                                                                                                              | 7/496 [00:01<01:12,  6.79it/s]
-1
-1
### event lambdas:  tensor([[[0.9124, 1.1647, 1.1868, 0.9458, 1.1689, 0.7143, 1.3012, 1.5925,
          0.7238],
         [0.7588, 0.9859, 1.0061, 0.7885, 0.9898, 0.5848, 1.1110, 1.3823,
          0.5930],
         [0.9216, 1.1752, 1.1973, 0.9551, 1.1794, 0.7221, 1.3123, 1.6046,
          0.7316],
         [0.9216, 1.1752, 1.1973, 0.9551, 1.1794, 0.7221, 1.3123, 1.6046,
          0.7316],
         [0.6240, 0.8250, 0.8430, 0.6500, 0.8284, 0.4739, 0.9377, 1.1867,
          0.4809],
         [0.9967, 1.2610, 1.2840, 1.0319, 1.2654, 0.7866, 1.4028, 1.7032,
          0.7967],
         [0.9588, 1.2178, 1.2404, 0.9931, 1.2221, 0.7539, 1.3572, 1.6536,
          0.7638],
         [0.6262, 0.8276, 0.8457, 0.6522, 0.8310, 0.4756, 0.9406, 1.1900,
          0.4826],
         [0.6237, 0.8247, 0.8427, 0.6497, 0.8281, 0.4736, 0.9374, 1.1863,
          0.4806]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(6.2722, grad_fn=<NegBackward>) non event loss:  tensor([35001126.0088], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(3.8029, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[0.1106, 0.1376, 0.1647, 0.2855, 0.2767, 0.2300, 0.2466, 0.2526,
          0.4375, 0.2709, 0.3348, 0.2714],
         [0.0280, 0.0352, 0.0426, 0.0772, 0.0745, 0.0609, 0.0657, 0.0674,
          0.1251, 0.0728, 0.0922, 0.0730],
         [0.0631, 0.0790, 0.0951, 0.1690, 0.1635, 0.1346, 0.1448, 0.1485,
          0.2668, 0.1599, 0.2002, 0.1602],
         [0.0717, 0.0897, 0.1078, 0.1906, 0.1845, 0.1522, 0.1636, 0.1678,
          0.2993, 0.1805, 0.2254, 0.1808],
         [0.0383, 0.0481, 0.0581, 0.1046, 0.1011, 0.0828, 0.0893, 0.0916,
          0.1683, 0.0988, 0.1247, 0.0990],
         [0.0234, 0.0295, 0.0357, 0.0648, 0.0626, 0.0511, 0.0551, 0.0566,
          0.1055, 0.0612, 0.0775, 0.0613],
         [0.0348, 0.0437, 0.0528, 0.0954, 0.0922, 0.0754, 0.0813, 0.0834,
          0.1538, 0.0900, 0.1137, 0.0902],
         [0.0694, 0.0868, 0.1044, 0.1848, 0.1789, 0.1475, 0.1586, 0.1626,
          0.2906, 0.1749, 0.2186, 0.1752],
         [0.0353, 0.0444, 0.0536, 0.0967, 0.0935, 0.0765, 0.0825, 0.0846,
          0.1559, 0.0914, 0.1153, 0.0915],
         [0.0744, 0.0929, 0.1117, 0.1972, 0.1909, 0.1576, 0.1693, 0.1736,
          0.3091, 0.1867, 0.2330, 0.1871],
         [0.0484, 0.0607, 0.0732, 0.1311, 0.1268, 0.1041, 0.1120, 0.1149,
          0.2092, 0.1239, 0.1558, 0.1241],
         [0.0361, 0.0453, 0.0547, 0.0987, 0.0954, 0.0781, 0.0842, 0.0864,
          0.1590, 0.0932, 0.1177, 0.0934]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(323.4598, grad_fn=<NegBackward>) non event loss:  tensor([9321425.8448], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(2.0918, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[0.0147, 0.0198, 0.0162, 0.0172, 0.0217, 0.0296, 0.0241, 0.0161,
          0.0174, 0.0085, 0.0085, 0.0136, 0.0139, 0.0140, 0.0151],
         [0.0140, 0.0189, 0.0154, 0.0164, 0.0207, 0.0282, 0.0230, 0.0153,
          0.0166, 0.0081, 0.0081, 0.0130, 0.0132, 0.0133, 0.0144],
         [0.0134, 0.0182, 0.0148, 0.0157, 0.0199, 0.0271, 0.0221, 0.0147,
          0.0160, 0.0078, 0.0078, 0.0125, 0.0127, 0.0128, 0.0139],
         [0.0132, 0.0178, 0.0145, 0.0154, 0.0195, 0.0266, 0.0217, 0.0145,
          0.0157, 0.0076, 0.0077, 0.0122, 0.0125, 0.0126, 0.0136],
         [0.0228, 0.0308, 0.0251, 0.0267, 0.0337, 0.0458, 0.0374, 0.0250,
          0.0271, 0.0132, 0.0133, 0.0211, 0.0216, 0.0217, 0.0235],
         [0.0093, 0.0125, 0.0102, 0.0109, 0.0138, 0.0187, 0.0153, 0.0102,
          0.0110, 0.0054, 0.0054, 0.0086, 0.0088, 0.0088, 0.0096],
         [0.0206, 0.0279, 0.0227, 0.0242, 0.0306, 0.0415, 0.0339, 0.0226,
          0.0245, 0.0120, 0.0120, 0.0191, 0.0196, 0.0197, 0.0213],
         [0.0165, 0.0223, 0.0182, 0.0193, 0.0245, 0.0333, 0.0271, 0.0181,
          0.0196, 0.0096, 0.0096, 0.0153, 0.0156, 0.0157, 0.0170],
         [0.0183, 0.0247, 0.0202, 0.0214, 0.0271, 0.0368, 0.0300, 0.0201,
          0.0217, 0.0106, 0.0106, 0.0170, 0.0173, 0.0174, 0.0189],
         [0.0117, 0.0158, 0.0129, 0.0137, 0.0173, 0.0236, 0.0192, 0.0128,
          0.0139, 0.0067, 0.0068, 0.0108, 0.0111, 0.0111, 0.0120],
         [0.0176, 0.0239, 0.0194, 0.0207, 0.0261, 0.0355, 0.0290, 0.0194,
          0.0210, 0.0102, 0.0103, 0.0164, 0.0167, 0.0168, 0.0182],
         [0.0134, 0.0181, 0.0148, 0.0157, 0.0199, 0.0271, 0.0220, 0.0147,
          0.0159, 0.0078, 0.0078, 0.0124, 0.0127, 0.0128, 0.0138],
         [0.0176, 0.0237, 0.0194, 0.0206, 0.0260, 0.0354, 0.0288, 0.0193,
          0.0209, 0.0102, 0.0102, 0.0163, 0.0166, 0.0167, 0.0181],
         [0.0203, 0.0275, 0.0224, 0.0238, 0.0301, 0.0409, 0.0334, 0.0223,
          0.0242, 0.0118, 0.0118, 0.0189, 0.0193, 0.0194, 0.0210],
         [0.0207, 0.0280, 0.0228, 0.0242, 0.0306, 0.0416, 0.0339, 0.0227,
          0.0246, 0.0120, 0.0120, 0.0192, 0.0196, 0.0197, 0.0213]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(915.2816, grad_fn=<NegBackward>) non event loss:  tensor([2732018.5805], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.7150, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[0.0020, 0.0023, 0.0024, 0.0051],
         [0.0021, 0.0023, 0.0024, 0.0052],
         [0.0023, 0.0026, 0.0027, 0.0057],
         [0.0019, 0.0022, 0.0023, 0.0049]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(94.0546, grad_fn=<NegBackward>) non event loss:  tensor([60727.7700], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0105, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[0.0004, 0.0004, 0.0005, 0.0003, 0.0005],
         [0.0005, 0.0004, 0.0005, 0.0004, 0.0005],
         [0.0007, 0.0006, 0.0008, 0.0005, 0.0007],
         [0.0004, 0.0004, 0.0005, 0.0003, 0.0004],
         [0.0005, 0.0004, 0.0005, 0.0004, 0.0005]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(191.6599, grad_fn=<NegBackward>) non event loss:  tensor([11537.8108], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0117, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[1.2823e-04, 1.7625e-04, 1.4653e-04, 6.2366e-05, 2.1357e-04],
         [1.0243e-04, 1.4079e-04, 1.1705e-04, 4.9817e-05, 1.7060e-04],
         [1.2743e-04, 1.7515e-04, 1.4562e-04, 6.1976e-05, 2.1224e-04],
         [4.6644e-05, 6.4114e-05, 5.3303e-05, 2.2686e-05, 7.7691e-05],
         [1.0705e-04, 1.4714e-04, 1.2233e-04, 5.2066e-05, 1.7830e-04]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(229.9515, grad_fn=<NegBackward>) non event loss:  tensor([1723.5003], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0181, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[6.8798e-05, 3.5913e-05, 1.8108e-05, 2.0048e-05, 3.7879e-05,
          4.1650e-05, 1.2853e-05],
         [4.7078e-05, 2.4575e-05, 1.2391e-05, 1.3718e-05, 2.5920e-05,
          2.8500e-05, 8.7953e-06],
         [7.5947e-05, 3.9645e-05, 1.9989e-05, 2.2131e-05, 4.1815e-05,
          4.5978e-05, 1.4189e-05],
         [6.0668e-05, 3.1670e-05, 1.5968e-05, 1.7679e-05, 3.3403e-05,
          3.6728e-05, 1.1334e-05],
         [4.5405e-05, 2.3702e-05, 1.1951e-05, 1.3231e-05, 2.4999e-05,
          2.7488e-05, 8.4829e-06],
         [3.0535e-05, 1.5940e-05, 8.0368e-06, 8.8979e-06, 1.6812e-05,
          1.8486e-05, 5.7048e-06],
         [4.8846e-05, 2.5498e-05, 1.2856e-05, 1.4234e-05, 2.6894e-05,
          2.9571e-05, 9.1258e-06]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(525.4282, grad_fn=<NegBackward>) non event loss:  tensor([509.6398], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0364, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[1.7943e-05, 1.5239e-05, 2.8639e-06, 2.9908e-06, 5.9356e-06],
         [2.4249e-05, 2.0595e-05, 3.8704e-06, 4.0420e-06, 8.0217e-06],
         [1.9107e-05, 1.6228e-05, 3.0496e-06, 3.1848e-06, 6.3206e-06],
         [1.8617e-05, 1.5812e-05, 2.9715e-06, 3.1032e-06, 6.1587e-06],
         [1.4320e-05, 1.2163e-05, 2.2857e-06, 2.3870e-06, 4.7373e-06]]],
       grad_fn=<SoftplusBackward>)

  4%|██████▎                                                                                                                                        | 22/496 [00:03<00:57,  8.18it/s]
-1
-1
### event lambdas:  tensor([[[2.5177e-05, 1.7317e-06, 2.9727e-06, 5.8192e-07],
         [2.2610e-05, 1.5551e-06, 2.6696e-06, 5.2258e-07],
         [1.7110e-05, 1.1768e-06, 2.0202e-06, 3.9546e-07],
         [1.5620e-05, 1.0744e-06, 1.8443e-06, 3.6103e-07]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(207.6405, grad_fn=<NegBackward>) non event loss:  tensor([45.6647], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0504, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[1.2897e-06, 1.9114e-06, 1.9281e-06, 7.3768e-07, 2.1807e-06,
          2.2297e-06],
         [2.2853e-06, 3.3869e-06, 3.4164e-06, 1.3071e-06, 3.8641e-06,
          3.9508e-06],
         [1.1672e-06, 1.7299e-06, 1.7449e-06, 6.6760e-07, 1.9736e-06,
          2.0179e-06],
         [2.2774e-06, 3.3752e-06, 3.4046e-06, 1.3026e-06, 3.8507e-06,
          3.9371e-06],
         [1.1976e-06, 1.7749e-06, 1.7904e-06, 6.8498e-07, 2.0250e-06,
          2.0704e-06],
         [9.6227e-07, 1.4261e-06, 1.4385e-06, 5.5038e-07, 1.6270e-06,
          1.6636e-06]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(476.2989, grad_fn=<NegBackward>) non event loss:  tensor([44.8995], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1198, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[2.5984e-06, 3.2982e-06, 2.6281e-07, 1.7599e-06, 3.3458e-07,
          1.7758e-06],
         [2.6809e-06, 3.4030e-06, 2.7115e-07, 1.8158e-06, 3.4521e-07,
          1.8322e-06],
         [2.4093e-06, 3.0582e-06, 2.4368e-07, 1.6318e-06, 3.1023e-07,
          1.6466e-06],
         [1.6316e-06, 2.0710e-06, 1.6502e-07, 1.1051e-06, 2.1009e-07,
          1.1151e-06],
         [2.2319e-06, 2.8330e-06, 2.2573e-07, 1.5116e-06, 2.8738e-07,
          1.5253e-06],
         [1.3574e-06, 1.7230e-06, 1.3729e-07, 9.1935e-07, 1.7478e-07,
          9.2768e-07]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(500.0850, grad_fn=<NegBackward>) non event loss:  tensor([39.7213], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1026, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[9.3377e-07, 6.6554e-07, 2.5211e-07, 2.6031e-07, 3.7003e-07,
          7.8694e-08],
         [6.5003e-07, 4.6331e-07, 1.7550e-07, 1.8121e-07, 2.5759e-07,
          5.4781e-08],
         [7.0690e-07, 5.0384e-07, 1.9086e-07, 1.9707e-07, 2.8012e-07,
          5.9574e-08],
         [6.4671e-07, 4.6094e-07, 1.7461e-07, 1.8028e-07, 2.5627e-07,
          5.4501e-08],
         [9.3301e-07, 6.6500e-07, 2.5191e-07, 2.6010e-07, 3.6972e-07,
          7.8629e-08],
         [9.2461e-07, 6.5901e-07, 2.4964e-07, 2.5776e-07, 3.6640e-07,
          7.7921e-08]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(543.8846, grad_fn=<NegBackward>) non event loss:  tensor([8.2716], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0845, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[2.5610e-06, 4.8430e-07, 5.5565e-07, 1.9622e-07, 5.3028e-07,
          6.2913e-08, 8.0768e-08],
         [2.3113e-06, 4.3708e-07, 5.0147e-07, 1.7709e-07, 4.7857e-07,
          5.6779e-08, 7.2893e-08],
         [2.7011e-06, 5.1081e-07, 5.8606e-07, 2.0696e-07, 5.5930e-07,
          6.6356e-08, 8.5189e-08],
         [2.1521e-06, 4.0697e-07, 4.6693e-07, 1.6489e-07, 4.4561e-07,
          5.2868e-08, 6.7872e-08],
         [1.6951e-06, 3.2055e-07, 3.6778e-07, 1.2988e-07, 3.5098e-07,
          4.1641e-08, 5.3459e-08],
         [3.6311e-06, 6.8668e-07, 7.8784e-07, 2.7822e-07, 7.5187e-07,
          8.9203e-08, 1.1452e-07],
         [1.5835e-06, 2.9945e-07, 3.4357e-07, 1.2133e-07, 3.2788e-07,
          3.8901e-08, 4.9941e-08]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(737.7538, grad_fn=<NegBackward>) non event loss:  tensor([23.6695], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1241, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[7.4918e-07, 4.0531e-07, 4.2097e-07, 1.4351e-08, 7.6665e-08,
          9.8206e-08],
         [3.6990e-07, 2.0012e-07, 2.0785e-07, 7.0859e-09, 3.7853e-08,
          4.8488e-08],
         [7.3363e-07, 3.9690e-07, 4.1222e-07, 1.4053e-08, 7.5073e-08,
          9.6167e-08],
         [6.5364e-07, 3.5362e-07, 3.6728e-07, 1.2521e-08, 6.6888e-08,
          8.5681e-08],
         [1.0721e-06, 5.8004e-07, 6.0244e-07, 2.0538e-08, 1.0971e-07,
          1.4054e-07],
         [5.4420e-07, 2.9442e-07, 3.0579e-07, 1.0425e-08, 5.5689e-08,
          7.1336e-08]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(569.4445, grad_fn=<NegBackward>) non event loss:  tensor([5.3349], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0905, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[3.2605e-07, 3.1965e-07, 3.5747e-07, 2.5290e-07, 1.6508e-07,
          7.0759e-08, 6.1122e-08, 6.0831e-08],
         [5.1652e-07, 5.0638e-07, 5.6629e-07, 4.0064e-07, 2.6152e-07,
          1.1209e-07, 9.6828e-08, 9.6367e-08],
         [4.5376e-07, 4.4485e-07, 4.9748e-07, 3.5196e-07, 2.2974e-07,
          9.8474e-08, 8.5062e-08, 8.4657e-08],
         [3.1027e-07, 3.0417e-07, 3.4016e-07, 2.4066e-07, 1.5709e-07,
          6.7334e-08, 5.8163e-08, 5.7886e-08],
         [4.9317e-07, 4.8348e-07, 5.4069e-07, 3.8252e-07, 2.4969e-07,
          1.0703e-07, 9.2450e-08, 9.2010e-08],
         [3.8904e-07, 3.8139e-07, 4.2652e-07, 3.0175e-07, 1.9697e-07,
          8.4428e-08, 7.2929e-08, 7.2582e-08],
         [3.1223e-07, 3.0610e-07, 3.4232e-07, 2.4218e-07, 1.5809e-07,
          6.7760e-08, 5.8532e-08, 5.8253e-08],
         [3.3498e-07, 3.2840e-07, 3.6726e-07, 2.5983e-07, 1.6960e-07,
          7.2697e-08, 6.2796e-08, 6.2497e-08]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(991.3443, grad_fn=<NegBackward>) non event loss:  tensor([4.4232], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0827, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[1.9154e-08, 1.9151e-08, 9.5120e-09, 3.2427e-08, 3.1992e-09,
          2.6717e-08, 2.6657e-08, 2.8313e-08, 2.8295e-08, 1.9136e-08],
         [2.0205e-08, 2.0202e-08, 1.0034e-08, 3.4207e-08, 3.3747e-09,
          2.8183e-08, 2.8120e-08, 2.9867e-08, 2.9848e-08, 2.0186e-08],
         [2.4330e-08, 2.4326e-08, 1.2082e-08, 4.1190e-08, 4.0637e-09,
          3.3937e-08, 3.3860e-08, 3.5964e-08, 3.5941e-08, 2.4307e-08],
         [3.1390e-08, 3.1385e-08, 1.5589e-08, 5.3143e-08, 5.2429e-09,
          4.3785e-08, 4.3686e-08, 4.6400e-08, 4.6371e-08, 3.1360e-08],
         [2.5562e-08, 2.5558e-08, 1.2694e-08, 4.3276e-08, 4.2695e-09,
          3.5656e-08, 3.5575e-08, 3.7785e-08, 3.7762e-08, 2.5538e-08],
         [4.6632e-08, 4.6624e-08, 2.3158e-08, 7.8947e-08, 7.7886e-09,
          6.5045e-08, 6.4898e-08, 6.8930e-08, 6.8887e-08, 4.6587e-08],
         [2.7406e-08, 2.7401e-08, 1.3610e-08, 4.6397e-08, 4.5774e-09,
          3.8227e-08, 3.8141e-08, 4.0510e-08, 4.0485e-08, 2.7379e-08],
         [1.2976e-08, 1.2974e-08, 6.4438e-09, 2.1968e-08, 2.1673e-09,
          1.8099e-08, 1.8059e-08, 1.9180e-08, 1.9168e-08, 1.2963e-08],
         [2.6864e-08, 2.6859e-08, 1.3341e-08, 4.5480e-08, 4.4869e-09,
          3.7471e-08, 3.7387e-08, 3.9709e-08, 3.9684e-08, 2.6838e-08],
         [2.6316e-08, 2.6312e-08, 1.3069e-08, 4.4552e-08, 4.3954e-09,
          3.6707e-08, 3.6624e-08, 3.8900e-08, 3.8875e-08, 2.6291e-08]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(1756.3772, grad_fn=<NegBackward>) non event loss:  tensor([5.1899], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1519, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[4.8491e-07, 4.4980e-07, 2.9802e-07, 1.4009e-07, 4.2143e-09],
         [2.2056e-07, 2.0459e-07, 1.3556e-07, 6.3721e-08, 1.9169e-09],
         [3.5750e-07, 3.3162e-07, 2.1972e-07, 1.0328e-07, 3.1070e-09],
         [2.4884e-07, 2.3082e-07, 1.5294e-07, 7.1890e-08, 2.1626e-09],
         [3.2697e-07, 3.0330e-07, 2.0096e-07, 9.4463e-08, 2.8417e-09]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(406.9973, grad_fn=<NegBackward>) non event loss:  tensor([1.0959], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0769, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[6.1591e-08, 6.1596e-08, 1.8654e-09, 5.3368e-09, 5.4271e-09,
          1.2838e-08],
         [4.4982e-08, 4.4986e-08, 1.3624e-09, 3.8977e-09, 3.9636e-09,
          9.3763e-09],
         [4.1576e-08, 4.1579e-08, 1.2592e-09, 3.6025e-09, 3.6635e-09,
          8.6662e-09],
         [6.7047e-08, 6.7052e-08, 2.0306e-09, 5.8096e-09, 5.9079e-09,
          1.3975e-08],
         [6.2516e-08, 6.2522e-08, 1.8934e-09, 5.4170e-09, 5.5087e-09,
          1.3031e-08],
         [4.3132e-08, 4.3136e-08, 1.3063e-09, 3.7374e-09, 3.8006e-09,
          8.9906e-09]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(663.1216, grad_fn=<NegBackward>) non event loss:  tensor([1.2492], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0869, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[3.0247e-07, 7.4996e-08, 7.4888e-08, 4.8411e-08, 2.4047e-08,
          2.5768e-08, 1.6205e-08, 1.6162e-08, 1.8925e-08, 5.5411e-09,
          7.4629e-09, 8.8243e-09],
         [3.2438e-07, 8.0429e-08, 8.0313e-08, 5.1918e-08, 2.5789e-08,
          2.7635e-08, 1.7379e-08, 1.7333e-08, 2.0296e-08, 5.9425e-09,
          8.0036e-09, 9.4635e-09],
         [2.8565e-07, 7.0826e-08, 7.0724e-08, 4.5719e-08, 2.2710e-08,
          2.4336e-08, 1.5304e-08, 1.5264e-08, 1.7872e-08, 5.2330e-09,
          7.0480e-09, 8.3336e-09],
         [4.1172e-07, 1.0208e-07, 1.0194e-07, 6.5896e-08, 3.2733e-08,
          3.5076e-08, 2.2058e-08, 2.2000e-08, 2.5760e-08, 7.5424e-09,
          1.0158e-08, 1.2011e-08],
         [2.7074e-07, 6.7127e-08, 6.7031e-08, 4.3332e-08, 2.1524e-08,
          2.3065e-08, 1.4505e-08, 1.4466e-08, 1.6939e-08, 4.9597e-09,
          6.6799e-09, 7.8985e-09],
         [3.5835e-07, 8.8851e-08, 8.8723e-08, 5.7354e-08, 2.8490e-08,
          3.0529e-08, 1.9199e-08, 1.9148e-08, 2.2421e-08, 6.5647e-09,
          8.8417e-09, 1.0455e-08],
         [3.8542e-07, 9.5562e-08, 9.5424e-08, 6.1686e-08, 3.0642e-08,
          3.2835e-08, 2.0649e-08, 2.0594e-08, 2.4114e-08, 7.0606e-09,
          9.5095e-09, 1.1244e-08],
         [2.0409e-07, 5.0603e-08, 5.0530e-08, 3.2665e-08, 1.6226e-08,
          1.7387e-08, 1.0934e-08, 1.0905e-08, 1.2769e-08, 3.7388e-09,
          5.0356e-09, 5.9542e-09],
         [2.9450e-07, 7.3019e-08, 7.2914e-08, 4.7135e-08, 2.3414e-08,
          2.5089e-08, 1.5778e-08, 1.5736e-08, 1.8426e-08, 5.3950e-09,
          7.2663e-09, 8.5917e-09],
         [2.3124e-07, 5.7334e-08, 5.7251e-08, 3.7010e-08, 1.8384e-08,
          1.9700e-08, 1.2389e-08, 1.2356e-08, 1.4468e-08, 4.2361e-09,
          5.7054e-09, 6.7461e-09],
         [2.1533e-07, 5.3390e-08, 5.3313e-08, 3.4464e-08, 1.7120e-08,
          1.8345e-08, 1.1536e-08, 1.1506e-08, 1.3473e-08, 3.9447e-09,
          5.3129e-09, 6.2821e-09],
         [4.0372e-07, 1.0010e-07, 9.9955e-08, 6.4616e-08, 3.2097e-08,
          3.4394e-08, 2.1629e-08, 2.1572e-08, 2.5260e-08, 7.3958e-09,
          9.9611e-09, 1.1778e-08]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(2516.8130, grad_fn=<NegBackward>) non event loss:  tensor([1.4246], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1178, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[3.0906e-08, 3.0349e-08, 1.1853e-09, 1.7601e-09, 2.8359e-08],
         [6.4494e-08, 6.3332e-08, 2.4734e-09, 3.6729e-09, 5.9179e-08],
         [2.7857e-08, 2.7355e-08, 1.0683e-09, 1.5864e-09, 2.5561e-08],
         [3.4962e-08, 3.4332e-08, 1.3408e-09, 1.9910e-09, 3.2081e-08],
         [2.9933e-08, 2.9394e-08, 1.1479e-09, 1.7046e-09, 2.7466e-08]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(459.8465, grad_fn=<NegBackward>) non event loss:  tensor([0.3153], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0812, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[1.2664e-09, 1.3256e-09, 5.1694e-10],
         [1.7518e-09, 1.8338e-09, 7.1511e-10],
         [9.7922e-10, 1.0251e-09, 3.9972e-10]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(186.7327, grad_fn=<NegBackward>) non event loss:  tensor([0.0031], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0278, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[3.4658e-08, 1.1884e-08, 1.3030e-08, 9.7821e-09, 2.0949e-09,
          4.6123e-10],
         [6.3444e-08, 2.1754e-08, 2.3852e-08, 1.7907e-08, 3.8349e-09,
          8.4432e-10],
         [5.6036e-08, 1.9214e-08, 2.1067e-08, 1.5816e-08, 3.3871e-09,
          7.4573e-10],
         [4.1130e-08, 1.4103e-08, 1.5463e-08, 1.1609e-08, 2.4861e-09,
          5.4737e-10],
         [4.4293e-08, 1.5188e-08, 1.6652e-08, 1.2502e-08, 2.6773e-09,
          5.8945e-10],
         [1.8565e-08, 6.3655e-09, 6.9794e-09, 5.2398e-09, 1.1221e-09,
          2.4706e-10]]], grad_fn=<SoftplusBackward>)

  7%|█████████▊                                                                                                                                     | 34/496 [00:05<01:13,  6.25it/s]
-1
-1
### event lambdas:  tensor([[[6.7070e-09, 2.3014e-10, 3.8451e-10, 3.6821e-09, 1.8412e-09,
          5.7191e-09],
         [5.3487e-09, 1.8353e-10, 3.0664e-10, 2.9365e-09, 1.4683e-09,
          4.5609e-09],
         [3.4849e-09, 1.1958e-10, 1.9979e-10, 1.9132e-09, 9.5666e-10,
          2.9716e-09],
         [3.4988e-09, 1.2006e-10, 2.0059e-10, 1.9209e-09, 9.6047e-10,
          2.9835e-09],
         [3.1958e-09, 1.0966e-10, 1.8322e-10, 1.7545e-09, 8.7729e-10,
          2.7251e-09],
         [9.6173e-09, 3.3000e-10, 5.5136e-10, 5.2799e-09, 2.6401e-09,
          8.2007e-09]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(738.6974, grad_fn=<NegBackward>) non event loss:  tensor([0.1772], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1373, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[2.7696e-09, 2.2119e-09, 1.5303e-10, 9.2339e-10, 1.2769e-09],
         [6.5784e-09, 5.2538e-09, 3.6346e-10, 2.1932e-09, 3.0329e-09],
         [3.8631e-09, 3.0852e-09, 2.1344e-10, 1.2879e-09, 1.7810e-09],
         [5.3216e-09, 4.2501e-09, 2.9403e-10, 1.7742e-09, 2.4535e-09],
         [2.8932e-09, 2.3106e-09, 1.5985e-10, 9.6459e-10, 1.3339e-09]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(508.1080, grad_fn=<NegBackward>) non event loss:  tensor([0.1027], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1206, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[1.2356e-08, 5.8300e-09, 1.7120e-09, 3.7548e-09, 3.6212e-09],
         [1.3536e-08, 6.3869e-09, 1.8755e-09, 4.1135e-09, 3.9671e-09],
         [1.6201e-08, 7.6443e-09, 2.2447e-09, 4.9233e-09, 4.7482e-09],
         [1.0761e-08, 5.0773e-09, 1.4909e-09, 3.2701e-09, 3.1537e-09],
         [1.3535e-08, 6.3865e-09, 1.8754e-09, 4.1132e-09, 3.9669e-09]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(479.3829, grad_fn=<NegBackward>) non event loss:  tensor([0.1092], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0869, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[1.3820e-08, 9.1734e-09, 5.6715e-09, 4.7361e-09, 3.3908e-09,
          3.2947e-09, 3.0690e-10],
         [1.2936e-08, 8.5868e-09, 5.3088e-09, 4.4333e-09, 3.1740e-09,
          3.0840e-09, 2.8727e-10],
         [1.5455e-08, 1.0259e-08, 6.3426e-09, 5.2965e-09, 3.7921e-09,
          3.6845e-09, 3.4321e-10],
         [6.3010e-09, 4.1826e-09, 2.5859e-09, 2.1594e-09, 1.5460e-09,
          1.5022e-09, 1.3993e-10],
         [1.1776e-08, 7.8167e-09, 4.8327e-09, 4.0357e-09, 2.8894e-09,
          2.8074e-09, 2.6151e-10],
         [1.9713e-08, 1.3085e-08, 8.0899e-09, 6.7556e-09, 4.8368e-09,
          4.6996e-09, 4.3776e-10],
         [2.0005e-08, 1.3279e-08, 8.2100e-09, 6.8559e-09, 4.9085e-09,
          4.7693e-09, 4.4426e-10]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(951.1058, grad_fn=<NegBackward>) non event loss:  tensor([0.0940], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0988, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[7.8805e-09, 2.4945e-09, 1.1298e-09, 2.5523e-09],
         [6.4194e-09, 2.0320e-09, 9.2030e-10, 2.0791e-09],
         [7.1430e-09, 2.2611e-09, 1.0240e-09, 2.3135e-09],
         [6.0105e-09, 1.9026e-09, 8.6168e-10, 1.9467e-09]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(317.7191, grad_fn=<NegBackward>) non event loss:  tensor([0.0239], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0715, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[1.0598e-08, 1.0968e-08, 3.1635e-09, 1.3561e-09, 2.4385e-09,
          1.3752e-09, 9.5515e-10, 2.4264e-09],
         [1.6874e-08, 1.7464e-08, 5.0372e-09, 2.1593e-09, 3.8827e-09,
          2.1897e-09, 1.5209e-09, 3.8636e-09],
         [1.5820e-08, 1.6373e-08, 4.7225e-09, 2.0244e-09, 3.6401e-09,
          2.0529e-09, 1.4258e-09, 3.6222e-09],
         [2.7705e-08, 2.8673e-08, 8.2703e-09, 3.5452e-09, 6.3748e-09,
          3.5951e-09, 2.4970e-09, 6.3433e-09],
         [1.8271e-08, 1.8910e-08, 5.4542e-09, 2.3380e-09, 4.2041e-09,
          2.3710e-09, 1.6468e-09, 4.1834e-09],
         [2.0999e-08, 2.1733e-08, 6.2685e-09, 2.6871e-09, 4.8318e-09,
          2.7250e-09, 1.8926e-09, 4.8080e-09],
         [1.5212e-08, 1.5744e-08, 4.5409e-09, 1.9466e-09, 3.5002e-09,
          1.9740e-09, 1.3710e-09, 3.4829e-09],
         [1.1712e-08, 1.2122e-08, 3.4963e-09, 1.4988e-09, 2.6950e-09,
          1.5199e-09, 1.0556e-09, 2.6817e-09]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(1232.0552, grad_fn=<NegBackward>) non event loss:  tensor([0.1927], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0813, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[6.6916e-09, 1.5380e-09, 1.2057e-09, 6.7414e-10, 4.2950e-10,
          1.3842e-10, 1.0483e-10, 2.7273e-10, 3.0479e-10],
         [6.5959e-09, 1.5160e-09, 1.1885e-09, 6.6450e-10, 4.2336e-10,
          1.3645e-10, 1.0333e-10, 2.6883e-10, 3.0043e-10],
         [4.8721e-09, 1.1198e-09, 8.7790e-10, 4.9084e-10, 3.1272e-10,
          1.0079e-10, 7.6324e-11, 1.9858e-10, 2.2191e-10],
         [3.9018e-09, 8.9678e-10, 7.0307e-10, 3.9309e-10, 2.5044e-10,
          8.0715e-11, 6.1124e-11, 1.5903e-10, 1.7772e-10],
         [5.9497e-09, 1.3675e-09, 1.0721e-09, 5.9940e-10, 3.8189e-10,
          1.2308e-10, 9.3205e-11, 2.4250e-10, 2.7100e-10],
         [6.2514e-09, 1.4368e-09, 1.1264e-09, 6.2980e-10, 4.0125e-10,
          1.2932e-10, 9.7931e-11, 2.5479e-10, 2.8474e-10],
         [3.4653e-09, 7.9644e-10, 6.2441e-10, 3.4911e-10, 2.2242e-10,
          7.1684e-11, 5.4285e-11, 1.4124e-10, 1.5784e-10],
         [5.2201e-09, 1.1998e-09, 9.4060e-10, 5.2590e-10, 3.3505e-10,
          1.0798e-10, 8.1775e-11, 2.1276e-10, 2.3776e-10],
         [4.8377e-09, 1.1119e-09, 8.7171e-10, 4.8738e-10, 3.1051e-10,
          1.0008e-10, 7.5786e-11, 1.9718e-10, 2.2035e-10]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(1748.1436, grad_fn=<NegBackward>) non event loss:  tensor([0.0243], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0950, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[2.0756e-09, 3.1606e-09, 1.4478e-09, 5.6627e-10, 1.5813e-10,
          6.8404e-11, 8.2539e-11, 5.3075e-10, 4.4697e-10, 7.9330e-10,
          9.6597e-10, 2.5252e-10, 1.3976e-11],
         [2.1881e-09, 3.3319e-09, 1.5263e-09, 5.9696e-10, 1.6671e-10,
          7.2112e-11, 8.7013e-11, 5.5952e-10, 4.7120e-10, 8.3630e-10,
          1.0183e-09, 2.6621e-10, 1.4734e-11],
         [2.0996e-09, 3.1971e-09, 1.4646e-09, 5.7281e-10, 1.5996e-10,
          6.9195e-11, 8.3493e-11, 5.3689e-10, 4.5214e-10, 8.0247e-10,
          9.7713e-10, 2.5544e-10, 1.4138e-11],
         [4.5750e-09, 6.9664e-09, 3.1912e-09, 1.2481e-09, 3.4855e-10,
          1.5077e-10, 1.8193e-10, 1.1699e-09, 9.8520e-10, 1.7486e-09,
          2.1291e-09, 5.5660e-10, 3.0806e-11],
         [2.5189e-09, 3.8355e-09, 1.7570e-09, 6.8719e-10, 1.9190e-10,
          8.3012e-11, 1.0016e-10, 6.4409e-10, 5.4242e-10, 9.6271e-10,
          1.1722e-09, 3.0645e-10, 1.6961e-11],
         [2.2973e-09, 3.4982e-09, 1.6025e-09, 6.2675e-10, 1.7502e-10,
          7.5711e-11, 9.1356e-11, 5.8745e-10, 4.9472e-10, 8.7804e-10,
          1.0692e-09, 2.7950e-10, 1.5469e-11],
         [2.2231e-09, 3.3852e-09, 1.5507e-09, 6.0652e-10, 1.6937e-10,
          7.3266e-11, 8.8406e-11, 5.6848e-10, 4.7875e-10, 8.4969e-10,
          1.0346e-09, 2.7047e-10, 1.4970e-11],
         [2.3550e-09, 3.5859e-09, 1.6427e-09, 6.4248e-10, 1.7942e-10,
          7.7611e-11, 9.3648e-11, 6.0219e-10, 5.0713e-10, 9.0007e-10,
          1.0960e-09, 2.8651e-10, 1.5858e-11],
         [2.3682e-09, 3.6061e-09, 1.6519e-09, 6.4610e-10, 1.8043e-10,
          7.8047e-11, 9.4175e-11, 6.0557e-10, 5.0999e-10, 9.0514e-10,
          1.1021e-09, 2.8812e-10, 1.5947e-11],
         [2.9363e-09, 4.4712e-09, 2.0482e-09, 8.0109e-10, 2.2371e-10,
          9.6771e-11, 1.1677e-10, 7.5085e-10, 6.3233e-10, 1.1223e-09,
          1.3665e-09, 3.5724e-10, 1.9772e-11],
         [2.9446e-09, 4.4837e-09, 2.0539e-09, 8.0333e-10, 2.2433e-10,
          9.7041e-11, 1.1709e-10, 7.5295e-10, 6.3410e-10, 1.1254e-09,
          1.3704e-09, 3.5824e-10, 1.9828e-11],
         [1.9277e-09, 2.9354e-09, 1.3447e-09, 5.2592e-10, 1.4687e-10,
          6.3530e-11, 7.6658e-11, 4.9294e-10, 4.1513e-10, 7.3678e-10,
          8.9714e-10, 2.3453e-10, 1.2981e-11],
         [2.1095e-09, 3.2121e-09, 1.4715e-09, 5.7551e-10, 1.6071e-10,
          6.9520e-11, 8.3886e-11, 5.3941e-10, 4.5427e-10, 8.0625e-10,
          9.8173e-10, 2.5665e-10, 1.4204e-11]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(3639.7058, grad_fn=<NegBackward>) non event loss:  tensor([0.0702], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1635, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[4.8341e-10, 1.0172e-09, 2.1061e-10],
         [2.4370e-10, 5.1278e-10, 1.0617e-10],
         [2.6198e-10, 5.5123e-10, 1.1414e-10]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(197.2049, grad_fn=<NegBackward>) non event loss:  tensor([0.0002], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0390, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[4.6931e-09, 2.2397e-09, 2.7044e-09, 1.8313e-09, 1.4559e-10],
         [4.4981e-09, 2.1467e-09, 2.5921e-09, 1.7552e-09, 1.3954e-10],
         [7.9904e-09, 3.8133e-09, 4.6046e-09, 3.1179e-09, 2.4788e-10],
         [2.3635e-09, 1.1279e-09, 1.3620e-09, 9.2223e-10, 7.3318e-11],
         [5.6518e-09, 2.6972e-09, 3.2569e-09, 2.2054e-09, 1.7533e-10]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(508.0066, grad_fn=<NegBackward>) non event loss:  tensor([0.0500], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0795, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[7.3096e-09, 6.3556e-09, 1.1003e-09, 1.1937e-09, 2.1684e-09,
          6.5528e-10, 3.2694e-10, 3.7165e-10, 3.3484e-10, 5.3194e-11,
          3.8782e-10, 3.9254e-10],
         [1.1701e-08, 1.0174e-08, 1.7612e-09, 1.9108e-09, 3.4711e-09,
          1.0489e-09, 5.2334e-10, 5.9491e-10, 5.3599e-10, 8.5149e-11,
          6.2079e-10, 6.2836e-10],
         [8.6918e-09, 7.5575e-09, 1.3083e-09, 1.4194e-09, 2.5785e-09,
          7.7920e-10, 3.8876e-10, 4.4193e-10, 3.9816e-10, 6.3253e-11,
          4.6115e-10, 4.6677e-10],
         [1.1701e-08, 1.0174e-08, 1.7612e-09, 1.9108e-09, 3.4711e-09,
          1.0489e-09, 5.2334e-10, 5.9491e-10, 5.3599e-10, 8.5149e-11,
          6.2079e-10, 6.2836e-10],
         [8.2984e-09, 7.2154e-09, 1.2491e-09, 1.3552e-09, 2.4618e-09,
          7.4393e-10, 3.7117e-10, 4.2193e-10, 3.8014e-10, 6.0390e-11,
          4.4028e-10, 4.4565e-10],
         [9.4693e-09, 8.2334e-09, 1.4253e-09, 1.5464e-09, 2.8091e-09,
          8.4890e-10, 4.2354e-10, 4.8146e-10, 4.3378e-10, 6.8911e-11,
          5.0240e-10, 5.0853e-10],
         [7.8758e-09, 6.8479e-09, 1.1855e-09, 1.2862e-09, 2.3364e-09,
          7.0604e-10, 3.5227e-10, 4.0044e-10, 3.6078e-10, 5.7314e-11,
          4.1786e-10, 4.2295e-10],
         [1.0256e-08, 8.9178e-09, 1.5438e-09, 1.6749e-09, 3.0426e-09,
          9.1945e-10, 4.5874e-10, 5.2147e-10, 4.6983e-10, 7.4638e-11,
          5.4416e-10, 5.5079e-10],
         [5.7700e-09, 5.0169e-09, 8.6851e-10, 9.4227e-10, 1.7117e-09,
          5.1726e-10, 2.5808e-10, 2.9337e-10, 2.6432e-10, 4.1990e-11,
          3.0613e-10, 3.0986e-10],
         [8.8974e-09, 7.7362e-09, 1.3393e-09, 1.4530e-09, 2.6395e-09,
          7.9763e-10, 3.9796e-10, 4.5238e-10, 4.0758e-10, 6.4749e-11,
          4.7206e-10, 4.7782e-10],
         [6.7092e-09, 5.8336e-09, 1.0099e-09, 1.0957e-09, 1.9903e-09,
          6.0146e-10, 3.0009e-10, 3.4112e-10, 3.0734e-10, 4.8825e-11,
          3.5596e-10, 3.6030e-10],
         [1.6466e-08, 1.4317e-08, 2.4785e-09, 2.6890e-09, 4.8847e-09,
          1.4761e-09, 7.3649e-10, 8.3720e-10, 7.5429e-10, 1.1983e-10,
          8.7362e-10, 8.8427e-10]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(2995.6216, grad_fn=<NegBackward>) non event loss:  tensor([0.0939], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1184, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[3.8807e-09, 9.3661e-10, 8.2195e-11, 6.4077e-11, 4.4527e-11,
          7.5949e-12, 8.5921e-12],
         [4.3043e-09, 1.0388e-09, 9.1167e-11, 7.1071e-11, 4.9387e-11,
          8.4238e-12, 9.5300e-12],
         [3.7155e-09, 8.9674e-10, 7.8696e-11, 6.1350e-11, 4.2632e-11,
          7.2716e-12, 8.2264e-12],
         [2.9766e-09, 7.1841e-10, 6.3047e-11, 4.9150e-11, 3.4154e-11,
          5.8256e-12, 6.5905e-12],
         [3.3906e-09, 8.1831e-10, 7.1814e-11, 5.5984e-11, 3.8903e-11,
          6.6357e-12, 7.5070e-12],
         [3.5856e-09, 8.6540e-10, 7.5946e-11, 5.9206e-11, 4.1142e-11,
          7.0175e-12, 7.9389e-12],
         [4.1896e-09, 1.0112e-09, 8.8738e-11, 6.9178e-11, 4.8071e-11,
          8.1994e-12, 9.2761e-12]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(1134.7709, grad_fn=<NegBackward>) non event loss:  tensor([0.0077], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0659, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[1.8582e-09, 2.7364e-09, 2.6275e-09, 1.1859e-09, 1.4362e-09,
          6.9617e-10],
         [1.7615e-09, 2.5941e-09, 2.4909e-09, 1.1243e-09, 1.3615e-09,
          6.5996e-10],
         [2.6922e-09, 3.9646e-09, 3.8068e-09, 1.7182e-09, 2.0808e-09,
          1.0086e-09],
         [2.2776e-09, 3.3542e-09, 3.2207e-09, 1.4536e-09, 1.7604e-09,
          8.5332e-10],
         [1.9941e-09, 2.9366e-09, 2.8197e-09, 1.2727e-09, 1.5413e-09,
          7.4708e-10],
         [2.0392e-09, 3.0030e-09, 2.8835e-09, 1.3015e-09, 1.5761e-09,
          7.6398e-10]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(725.3551, grad_fn=<NegBackward>) non event loss:  tensor([0.0257], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0619, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[2.9274e-09, 3.6552e-11, 2.7104e-10, 3.9093e-10, 7.8343e-11,
          3.0486e-10],
         [4.0943e-09, 5.1122e-11, 3.7909e-10, 5.4675e-10, 1.0957e-10,
          4.2638e-10],
         [2.2700e-09, 2.8343e-11, 2.1017e-10, 3.0313e-10, 6.0749e-11,
          2.3639e-10],
         [2.3550e-09, 2.9405e-11, 2.1805e-10, 3.1449e-10, 6.3025e-11,
          2.4525e-10],
         [1.7407e-09, 2.1734e-11, 1.6116e-10, 2.3245e-10, 4.6583e-11,
          1.8127e-10],
         [2.2698e-09, 2.8340e-11, 2.1015e-10, 3.0310e-10, 6.0743e-11,
  9%|████████████▍                                                                                                                                  | 43/496 [00:07<01:15,  5.96it/s]
Traceback (most recent call last):
  File "main.py", line 156, in <module>
    main()
  File "main.py", line 152, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 110, in train
    loss.backward() # required_graph = True
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/autograd/__init__.py", line 145, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt
##### event loss: tensor(800.7871, grad_fn=<NegBackward>) non event loss:  tensor([0.0568], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1330, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[5.2909e-09, 2.9580e-09, 1.0357e-09, 1.0404e-09, 4.0522e-10],
         [2.5793e-09, 1.4420e-09, 5.0491e-10, 5.0717e-10, 1.9754e-10],
         [1.9728e-09, 1.1029e-09, 3.8618e-10, 3.8791e-10, 1.5109e-10],
         [2.3596e-09, 1.3192e-09, 4.6191e-10, 4.6398e-10, 1.8072e-10],
         [1.8542e-09, 1.0366e-09, 3.6296e-10, 3.6459e-10, 1.4201e-10]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(526.2778, grad_fn=<NegBackward>) non event loss:  tensor([0.0086], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0653, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[5.6923e-10, 3.1255e-10, 7.8053e-11, 1.1753e-10, 1.7534e-10,
          2.3000e-10, 2.3374e-10, 8.1187e-12],
         [6.7992e-10, 3.7332e-10, 9.3230e-11, 1.4039e-10, 2.0943e-10,
          2.7473e-10, 2.7919e-10, 9.6974e-12],
         [8.6335e-10, 4.7404e-10, 1.1838e-10, 1.7826e-10, 2.6594e-10,
          3.4885e-10, 3.5451e-10, 1.2314e-11],
         [9.1180e-10, 5.0064e-10, 1.2503e-10, 1.8827e-10, 2.8086e-10,
          3.6842e-10, 3.7440e-10, 1.3005e-11],
         [5.6053e-10, 3.0777e-10, 7.6860e-11, 1.1574e-10, 1.7266e-10,
          2.2649e-10, 2.3016e-10, 7.9946e-12],
         [1.0189e-09, 5.5944e-10, 1.3971e-10, 2.1038e-10, 3.1385e-10,
          4.1169e-10, 4.1838e-10, 1.4532e-11],
         [1.1201e-09, 6.1500e-10, 1.5358e-10, 2.3127e-10, 3.4501e-10,
          4.5258e-10, 4.5992e-10, 1.5975e-11],
         [5.2542e-10, 2.8849e-10, 7.2045e-11, 1.0849e-10, 1.6184e-10,
          2.1230e-10, 2.1575e-10, 7.4938e-12]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(1435.6235, grad_fn=<NegBackward>) non event loss:  tensor([0.0246], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1164, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[2.8582e-09, 3.2727e-10, 2.6133e-10, 4.7094e-10, 5.5574e-10,
          1.0920e-10, 1.8137e-10, 3.9077e-10],
         [2.7945e-09, 3.1998e-10, 2.5550e-10, 4.6045e-10, 5.4336e-10,
          1.0677e-10, 1.7733e-10, 3.8207e-10],
         [5.2294e-09, 5.9878e-10, 4.7813e-10, 8.6165e-10, 1.0168e-09,
          1.9979e-10, 3.3184e-10, 7.1497e-10],
         [3.5283e-09, 4.0400e-10, 3.2259e-10, 5.8135e-10, 6.8603e-10,
          1.3480e-10, 2.2389e-10, 4.8239e-10],
         [3.3389e-09, 3.8231e-10, 3.0527e-10, 5.5014e-10, 6.4919e-10,
          1.2756e-10, 2.1187e-10, 4.5649e-10],
         [3.9183e-09, 4.4866e-10, 3.5825e-10, 6.4561e-10, 7.6186e-10,
          1.4970e-10, 2.4864e-10, 5.3571e-10],
         [3.9820e-09, 4.5595e-10, 3.6408e-10, 6.5611e-10, 7.7425e-10,
          1.5213e-10, 2.5268e-10, 5.4442e-10],
         [1.5277e-09, 1.7493e-10, 1.3968e-10, 2.5172e-10, 2.9705e-10,
          5.8368e-11, 9.6945e-11, 2.0887e-10]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(1379.4281, grad_fn=<NegBackward>) non event loss:  tensor([0.0417], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1523, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[9.4940e-11, 2.8949e-10, 1.8447e-10, 3.1951e-10, 2.8634e-10],
         [6.7397e-11, 2.0551e-10, 1.3095e-10, 2.2682e-10, 2.0327e-10],
         [1.2116e-10, 3.6945e-10, 2.3542e-10, 4.0776e-10, 3.6544e-10],
         [1.0104e-10, 3.0810e-10, 1.9633e-10, 3.4005e-10, 3.0475e-10],
         [1.0985e-10, 3.3496e-10, 2.1345e-10, 3.6970e-10, 3.3132e-10]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(555.9141, grad_fn=<NegBackward>) non event loss:  tensor([0.0152], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1054, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[9.8875e-10, 1.0470e-09, 6.5495e-10, 4.7226e-10, 7.6069e-10],
         [7.3238e-10, 7.7554e-10, 4.8513e-10, 3.4981e-10, 5.6345e-10],
         [3.8328e-10, 4.0586e-10, 2.5388e-10, 1.8306e-10, 2.9487e-10],
         [5.7064e-10, 6.0427e-10, 3.7799e-10, 2.7256e-10, 4.3902e-10],
         [4.5790e-10, 4.8488e-10, 3.0331e-10, 2.1871e-10, 3.5228e-10]]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(537.9797, grad_fn=<NegBackward>) non event loss:  tensor([0.0083], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1015, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[1.3470e-08, 3.0799e-09, 6.4395e-09, 2.6466e-09, 3.3312e-09,
          2.4498e-09, 1.2559e-09, 1.1290e-09, 1.3270e-09, 8.1560e-10,
          9.5580e-10, 1.2633e-10, 4.8830e-10, 4.2067e-10, 9.9468e-10,
          2.5057e-10, 2.2005e-10, 2.1649e-10, 6.0933e-10, 4.8675e-10,
          1.7128e-11, 1.3636e-11, 5.8671e-10, 5.8090e-11, 6.5141e-11,
          3.3959e-10],
         [7.1776e-09, 1.6412e-09, 3.4314e-09, 1.4103e-09, 1.7751e-09,
          1.3054e-09, 6.6922e-10, 6.0158e-10, 7.0712e-10, 4.3460e-10,
          5.0931e-10, 6.7317e-11, 2.6020e-10, 2.2416e-10, 5.3003e-10,
          1.3352e-10, 1.1726e-10, 1.1536e-10, 3.2469e-10, 2.5937e-10,
          9.1271e-12, 7.2663e-12, 3.1264e-10, 3.0954e-11, 3.4711e-11,
          1.8096e-10],
         [8.1549e-09, 1.8647e-09, 3.8987e-09, 1.6023e-09, 2.0168e-09,
          1.4832e-09, 7.6035e-10, 6.8350e-10, 8.0341e-10, 4.9378e-10,
          5.7867e-10, 7.6483e-11, 2.9563e-10, 2.5469e-10, 6.0221e-10,
          1.5170e-10, 1.3322e-10, 1.3107e-10, 3.6891e-10, 2.9469e-10,
          1.0370e-11, 8.2558e-12, 3.5521e-10, 3.5169e-11, 3.9438e-11,
          2.0560e-10],
         [7.9876e-09, 1.8264e-09, 3.8187e-09, 1.5695e-09, 1.9755e-09,
          1.4528e-09, 7.4475e-10, 6.6948e-10, 7.8693e-10, 4.8365e-10,
          5.6680e-10, 7.4914e-11, 2.8957e-10, 2.4946e-10, 5.8985e-10,
          1.4859e-10, 1.3049e-10, 1.2838e-10, 3.6134e-10, 2.8864e-10,
          1.0157e-11, 8.0864e-12, 3.4792e-10, 3.4448e-11, 3.8629e-11,
          2.0138e-10],
         [1.6055e-08, 3.6711e-09, 7.6755e-09, 3.1546e-09, 3.9706e-09,
          2.9201e-09, 1.4969e-09, 1.3456e-09, 1.5817e-09, 9.7213e-10,
          1.1393e-09, 1.5058e-10, 5.8202e-10, 5.0141e-10, 1.1856e-09,
          2.9866e-10, 2.6228e-10, 2.5804e-10, 7.2628e-10, 5.8017e-10,
          2.0416e-11, 1.6254e-11, 6.9932e-10, 6.9239e-11, 7.7643e-11,
          4.0477e-10],
         [9.1296e-09, 2.0875e-09, 4.3646e-09, 1.7938e-09, 2.2579e-09,
          1.6605e-09, 8.5122e-10, 7.6519e-10, 8.9943e-10, 5.5280e-10,
          6.4783e-10, 8.5624e-11, 3.3096e-10, 2.8513e-10, 6.7418e-10,
          1.6983e-10, 1.4915e-10, 1.4673e-10, 4.1300e-10, 3.2991e-10,
          1.1609e-11, 9.2425e-12, 3.9766e-10, 3.9373e-11, 4.4151e-11,
          2.3017e-10],
         [7.7973e-09, 1.7829e-09, 3.7277e-09, 1.5321e-09, 1.9284e-09,
          1.4182e-09, 7.2701e-10, 6.5353e-10, 7.6818e-10, 4.7213e-10,
          5.5329e-10, 7.3129e-11, 2.8267e-10, 2.4352e-10, 5.7580e-10,
          1.4505e-10, 1.2738e-10, 1.2532e-10, 3.5273e-10, 2.8177e-10,
          9.9152e-12, 7.8938e-12, 3.3963e-10, 3.3627e-11, 3.7708e-11,
          1.9658e-10],
         [1.0433e-08, 2.3856e-09, 4.9877e-09, 2.0499e-09, 2.5802e-09,
          1.8975e-09, 9.7274e-10, 8.7443e-10, 1.0278e-09, 6.3171e-10,
          7.4031e-10, 9.7848e-11, 3.7821e-10, 3.2583e-10, 7.7043e-10,
          1.9408e-10, 1.7044e-10, 1.6768e-10, 4.7195e-10, 3.7701e-10,
          1.3267e-11, 1.0562e-11, 4.5443e-10, 4.4993e-11, 5.0454e-11,
          2.6303e-10],
         [9.5532e-09, 2.1844e-09, 4.5672e-09, 1.8771e-09, 2.3627e-09,
          1.7375e-09, 8.9072e-10, 8.0070e-10, 9.4117e-10, 5.7845e-10,
          6.7789e-10, 8.9598e-11, 3.4632e-10, 2.9836e-10, 7.0547e-10,
          1.7771e-10, 1.5607e-10, 1.5354e-10, 4.3216e-10, 3.4522e-10,
          1.2148e-11, 9.6714e-12, 4.1612e-10, 4.1200e-11, 4.6200e-11,
          2.4085e-10],
         [6.1385e-09, 1.4036e-09, 2.9347e-09, 1.2061e-09, 1.5181e-09,
          1.1165e-09, 5.7234e-10, 5.1449e-10, 6.0475e-10, 3.7169e-10,
          4.3558e-10, 5.7571e-11, 2.2253e-10, 1.9171e-10, 4.5330e-10,
          1.1419e-10, 1.0028e-10, 9.8658e-11, 2.7769e-10, 2.2182e-10,
          7.8057e-12, 6.2144e-12, 2.6738e-10, 2.6473e-11, 2.9686e-11,
          1.5476e-10],
         [1.2498e-08, 2.8577e-09, 5.9750e-09, 2.4557e-09, 3.0909e-09,
          2.2731e-09, 1.1653e-09, 1.0475e-09, 1.2313e-09, 7.5675e-10,
          8.8685e-10, 1.1722e-10, 4.5307e-10, 3.9032e-10, 9.2292e-10,
          2.3249e-10, 2.0417e-10, 2.0087e-10, 5.6537e-10, 4.5163e-10,
          1.5893e-11, 1.2653e-11, 5.4438e-10, 5.3899e-11, 6.0441e-11,
          3.1509e-10],
         [7.2141e-09, 1.6496e-09, 3.4489e-09, 1.4175e-09, 1.7841e-09,
          1.3121e-09, 6.7263e-10, 6.0465e-10, 7.1072e-10, 4.3681e-10,
          5.1191e-10, 6.7659e-11, 2.6152e-10, 2.2530e-10, 5.3273e-10,
          1.3420e-10, 1.1785e-10, 1.1595e-10, 3.2634e-10, 2.6069e-10,
          9.1735e-12, 7.3033e-12, 3.1423e-10, 3.1112e-11, 3.4888e-11,
          1.8188e-10],
         [6.0768e-09, 1.3895e-09, 2.9052e-09, 1.1940e-09, 1.5029e-09,
          1.1052e-09, 5.6658e-10, 5.0932e-10, 5.9867e-10, 3.6795e-10,
          4.3120e-10, 5.6993e-11, 2.2029e-10, 1.8978e-10, 4.4874e-10,
          1.1304e-10, 9.9274e-11, 9.7666e-11, 2.7490e-10, 2.1959e-10,
          7.7273e-12, 6.1519e-12, 2.6469e-10, 2.6207e-11, 2.9388e-11,
          1.5320e-10],
         [7.6481e-09, 1.7488e-09, 3.6564e-09, 1.5027e-09, 1.8915e-09,
          1.3910e-09, 7.1309e-10, 6.4102e-10, 7.5348e-10, 4.6309e-10,
          5.4270e-10, 7.1729e-11, 2.7725e-10, 2.3886e-10, 5.6478e-10,
          1.4227e-10, 1.2494e-10, 1.2292e-10, 3.4598e-10, 2.7637e-10,
          9.7254e-12, 7.7427e-12, 3.3313e-10, 3.2983e-11, 3.6987e-11,
          1.9282e-10],
         [1.2189e-08, 2.7872e-09, 5.8275e-09, 2.3950e-09, 3.0146e-09,
          2.2170e-09, 1.1365e-09, 1.0216e-09, 1.2009e-09, 7.3807e-10,
          8.6495e-10, 1.1432e-10, 4.4189e-10, 3.8069e-10, 9.0014e-10,
          2.2675e-10, 1.9913e-10, 1.9591e-10, 5.5141e-10, 4.4048e-10,
          1.5500e-11, 1.2340e-11, 5.3094e-10, 5.2568e-11, 5.8949e-11,
          3.0731e-10],
         [7.9374e-09, 1.8149e-09, 3.7947e-09, 1.5596e-09, 1.9630e-09,
          1.4436e-09, 7.4007e-10, 6.6527e-10, 7.8198e-10, 4.8061e-10,
          5.6323e-10, 7.4443e-11, 2.8774e-10, 2.4789e-10, 5.8615e-10,
          1.4765e-10, 1.2967e-10, 1.2757e-10, 3.5907e-10, 2.8683e-10,
          1.0093e-11, 8.0356e-12, 3.4573e-10, 3.4231e-11, 3.8386e-11,
          2.0012e-10],
         [7.5453e-09, 1.7253e-09, 3.6072e-09, 1.4825e-09, 1.8660e-09,
          1.3723e-09, 7.0350e-10, 6.3240e-10, 7.4335e-10, 4.5687e-10,
          5.3541e-10, 7.0765e-11, 2.7353e-10, 2.3565e-10, 5.5719e-10,
          1.4036e-10, 1.2326e-10, 1.2127e-10, 3.4133e-10, 2.7266e-10,
          9.5946e-12, 7.6386e-12, 3.2865e-10, 3.2540e-11, 3.6489e-11,
          1.9023e-10],
         [8.2578e-09, 1.8882e-09, 3.9478e-09, 1.6225e-09, 2.0423e-09,
          1.5019e-09, 7.6994e-10, 6.9212e-10, 8.1354e-10, 5.0001e-10,
          5.8597e-10, 7.7448e-11, 2.9936e-10, 2.5790e-10, 6.0980e-10,
          1.5361e-10, 1.3490e-10, 1.3272e-10, 3.7356e-10, 2.9840e-10,
          1.0501e-11, 8.3599e-12, 3.5969e-10, 3.5613e-11, 3.9935e-11,
          2.0819e-10],
         [1.1715e-08, 2.6787e-09, 5.6006e-09, 2.3018e-09, 2.8972e-09,
          2.1307e-09, 1.0923e-09, 9.8188e-10, 1.1541e-09, 7.0934e-10,
          8.3128e-10, 1.0987e-10, 4.2468e-10, 3.6587e-10, 8.6510e-10,
          2.1792e-10, 1.9138e-10, 1.8828e-10, 5.2995e-10, 4.2333e-10,
          1.4897e-11, 1.1860e-11, 5.1027e-10, 5.0522e-11, 5.6654e-11,
          2.9535e-10],
         [7.2423e-09, 1.6560e-09, 3.4624e-09, 1.4230e-09, 1.7911e-09,
          1.3172e-09, 6.7526e-10, 6.0701e-10, 7.1350e-10, 4.3852e-10,
          5.1391e-10, 6.7924e-11, 2.6255e-10, 2.2619e-10, 5.3482e-10,
          1.3472e-10, 1.1831e-10, 1.1640e-10, 3.2762e-10, 2.6171e-10,
          9.2094e-12, 7.3319e-12, 3.1546e-10, 3.1233e-11, 3.5024e-11,
          1.8259e-10],
         [7.2697e-09, 1.6623e-09, 3.4755e-09, 1.4284e-09, 1.7979e-09,
          1.3222e-09, 6.7781e-10, 6.0931e-10, 7.1620e-10, 4.4018e-10,
          5.1586e-10, 6.8181e-11, 2.6354e-10, 2.2704e-10, 5.3684e-10,
          1.3523e-10, 1.1876e-10, 1.1684e-10, 3.2886e-10, 2.6270e-10,
          9.2443e-12, 7.3597e-12, 3.1665e-10, 3.1352e-11, 3.5157e-11,
          1.8328e-10],
         [1.7432e-08, 3.9860e-09, 8.3340e-09, 3.4252e-09, 4.3113e-09,
          3.1706e-09, 1.6254e-09, 1.4611e-09, 1.7174e-09, 1.0555e-09,
          1.2370e-09, 1.6349e-10, 6.3195e-10, 5.4443e-10, 1.2873e-09,
          3.2428e-10, 2.8479e-10, 2.8017e-10, 7.8859e-10, 6.2994e-10,
          2.2167e-11, 1.7648e-11, 7.5931e-10, 7.5179e-11, 8.4304e-11,
          4.3950e-10],
         [1.3722e-08, 3.1377e-09, 6.5602e-09, 2.6962e-09, 3.3937e-09,
          2.4958e-09, 1.2794e-09, 1.1501e-09, 1.3519e-09, 8.3088e-10,
          9.7372e-10, 1.2870e-10, 4.9745e-10, 4.2856e-10, 1.0133e-09,
          2.5527e-10, 2.2417e-10, 2.2054e-10, 6.2075e-10, 4.9587e-10,
          1.7449e-11, 1.3892e-11, 5.9770e-10, 5.9179e-11, 6.6362e-11,
          3.4596e-10],
         [1.4442e-08, 3.3022e-09, 6.9042e-09, 2.8376e-09, 3.5716e-09,
          2.6266e-09, 1.3465e-09, 1.2104e-09, 1.4228e-09, 8.7444e-10,
          1.0248e-09, 1.3544e-10, 5.2353e-10, 4.5103e-10, 1.0665e-09,
          2.6865e-10, 2.3593e-10, 2.3211e-10, 6.5329e-10, 5.2186e-10,
          1.8364e-11, 1.4620e-11, 6.2904e-10, 6.2281e-11, 6.9840e-11,
          3.6409e-10],
         [5.7576e-09, 1.3165e-09, 2.7526e-09, 1.1313e-09, 1.4239e-09,
          1.0472e-09, 5.3683e-10, 4.8257e-10, 5.6723e-10, 3.4863e-10,
          4.0856e-10, 5.4000e-11, 2.0872e-10, 1.7982e-10, 4.2518e-10,
          1.0711e-10, 9.4060e-11, 9.2537e-11, 2.6046e-10, 2.0806e-10,
          7.3215e-12, 5.8289e-12, 2.5079e-10, 2.4831e-11, 2.7844e-11,
          1.4516e-10],
         [5.2924e-09, 1.2101e-09, 2.5302e-09, 1.0399e-09, 1.3089e-09,
          9.6257e-10, 4.9345e-10, 4.4358e-10, 5.2140e-10, 3.2046e-10,
          3.7555e-10, 4.9636e-11, 1.9186e-10, 1.6529e-10, 3.9082e-10,
          9.8451e-11, 8.6460e-11, 8.5060e-11, 2.3941e-10, 1.9125e-10,
          6.7299e-12, 5.3579e-12, 2.3052e-10, 2.2824e-11, 2.5594e-11,
          1.3343e-10]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(14689.6484, grad_fn=<NegBackward>) non event loss:  tensor([0.5173], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.2440, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[6.8877e-09, 7.2232e-10, 8.4551e-10, 5.4603e-10, 1.9974e-10,
          3.3170e-10, 2.7489e-10, 2.3304e-10, 1.8541e-10, 4.4648e-10,
          4.6578e-10],
         [4.1963e-09, 4.4007e-10, 5.1512e-10, 3.3267e-10, 1.2169e-10,
          2.0208e-10, 1.6748e-10, 1.4198e-10, 1.1296e-10, 2.7202e-10,
          2.8377e-10],
         [4.5218e-09, 4.7421e-10, 5.5508e-10, 3.5848e-10, 1.3113e-10,
          2.1776e-10, 1.8047e-10, 1.5299e-10, 1.2172e-10, 2.9312e-10,
          3.0579e-10],
         [3.7264e-09, 3.9079e-10, 4.5744e-10, 2.9542e-10, 1.0806e-10,
          1.7946e-10, 1.4872e-10, 1.2608e-10, 1.0031e-10, 2.4156e-10,
          2.5200e-10],
         [3.9880e-09, 4.1822e-10, 4.8955e-10, 3.1615e-10, 1.1565e-10,
          1.9205e-10, 1.5916e-10, 1.3493e-10, 1.0735e-10, 2.5851e-10,
          2.6968e-10],
         [4.6498e-09, 4.8764e-10, 5.7080e-10, 3.6862e-10, 1.3484e-10,
          2.2393e-10, 1.8558e-10, 1.5733e-10, 1.2517e-10, 3.0142e-10,
          3.1444e-10],
         [5.6989e-09, 5.9766e-10, 6.9958e-10, 4.5179e-10, 1.6527e-10,
          2.7445e-10, 2.2745e-10, 1.9282e-10, 1.5341e-10, 3.6942e-10,
          3.8539e-10],
         [3.4347e-09, 3.6020e-10, 4.2163e-10, 2.7229e-10, 9.9603e-11,
          1.6541e-10, 1.3708e-10, 1.1621e-10, 9.2455e-11, 2.2265e-10,
          2.3227e-10],
         [3.7186e-09, 3.8997e-10, 4.5648e-10, 2.9479e-10, 1.0784e-10,
          1.7908e-10, 1.4841e-10, 1.2582e-10, 1.0010e-10, 2.4105e-10,
          2.5147e-10],
         [5.9485e-09, 6.2383e-10, 7.3022e-10, 4.7158e-10, 1.7250e-10,
          2.8647e-10, 2.3741e-10, 2.0127e-10, 1.6012e-10, 3.8560e-10,
          4.0227e-10],
         [2.6553e-09, 2.7847e-10, 3.2596e-10, 2.1051e-10, 7.7003e-11,
          1.2788e-10, 1.0598e-10, 8.9842e-11, 7.1477e-11, 1.7213e-10,
          1.7957e-10]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(2650.0496, grad_fn=<NegBackward>) non event loss:  tensor([0.0421], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1119, grad_fn=<SumBackward0>)
-1
-1
### event lambdas:  tensor([[[6.3120e-10, 3.1906e-10, 3.4261e-12, 3.6347e-12, 1.9917e-10,
          1.2797e-10],
         [5.7445e-10, 2.9037e-10, 3.1180e-12, 3.3078e-12, 1.8126e-10,
          1.1647e-10],
         [4.5418e-10, 2.2958e-10, 2.4652e-12, 2.6153e-12, 1.4331e-10,
          9.2082e-11],
         [7.5561e-10, 3.8195e-10, 4.1014e-12, 4.3511e-12, 2.3842e-10,
          1.5320e-10],
         [4.9857e-10, 2.5202e-10, 2.7062e-12, 2.8709e-12, 1.5732e-10,
          1.0108e-10],
         [5.4672e-10, 2.7636e-10, 2.9675e-12, 3.1482e-12, 1.7251e-10,
          1.1084e-10]]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(849.1695, grad_fn=<NegBackward>) non event loss:  tensor([0.0089], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1204, grad_fn=<SumBackward0>)