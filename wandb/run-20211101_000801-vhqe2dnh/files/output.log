
CUDA availability: True
### event lambdas:  tensor([[2.7595, 3.7590, 3.2845, 3.3843, 4.3962, 4.8736, 4.6780, 3.6703, 5.4263]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[5.7891, 3.8313, 6.3845, 5.6237, 5.3111, 4.5473, 5.8193, 6.8302, 4.2405,
         5.6087, 5.7379, 5.3595, 6.0829, 5.1533, 3.8682, 5.5225, 5.8527, 5.8441,
         5.0481, 5.0694, 4.4959, 5.5062, 5.6377, 4.5983, 4.6763, 4.8367, 5.3497,
         5.3013, 5.3135, 5.2688, 5.5159, 4.4035, 6.4401, 4.9445, 4.9657, 6.8166,
         5.2456, 5.5112, 6.5252, 3.9843, 6.1218, 5.4038, 4.5006, 5.3619, 5.2692,
         4.6321, 5.6930, 6.2557, 4.1463, 5.6766, 5.1469, 5.8804, 6.0233, 6.0381,
         4.9356, 5.3005, 3.5994, 5.8249, 4.4715, 3.9091, 5.4339, 4.0824, 5.2776,
         5.0211, 6.1312, 4.9006, 5.1900, 4.3973, 4.4934, 4.7579, 4.2674, 4.2708,
         3.8127, 5.5527, 6.6784, 4.2923, 5.3654, 5.7239, 5.2451, 5.5287, 5.4942,
         4.6562, 4.6579, 5.4097, 5.3386, 5.0637, 5.4923, 4.4961, 4.6651, 4.7875]],
       grad_fn=<SoftplusBackward>)
##### event loss: -12.346543312072754 non event loss:  3730002.293701172 chocie_l: 3.5501818656921387
### event lambdas:  tensor([[1.9815, 3.0451, 2.3610, 1.7649, 2.2122, 1.8666]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[2.2377, 3.2933, 1.9375, 1.8682, 2.7910, 1.5049, 2.4137, 2.4171, 2.5129,
         1.7144, 2.1027, 2.4044, 2.3050, 3.0635, 2.1209, 2.4704, 2.2060, 2.0117,
         1.8191, 2.4451, 2.7259, 1.7775, 2.4637, 1.8198, 2.7880, 2.3798, 2.6141,
         2.4101, 2.6573, 2.4160, 1.9309, 2.1554, 2.9882, 2.4547, 2.3797, 2.6042,
         3.1962, 2.0338, 1.9693, 2.1158, 2.1217, 2.3103, 2.8371, 3.0593, 2.7292,
         1.7018, 2.3005, 2.6856, 2.3581, 2.8149, 1.9787, 1.9866, 1.7944, 2.3678,
         3.2352, 2.1298, 2.6295, 2.0331, 2.9015, 2.7509]],
       grad_fn=<SoftplusBackward>)
##### event loss: -4.642721652984619 non event loss:  1051199.309387207 chocie_l: 2.554105758666992
### event lambdas:  tensor([[0.3806, 0.6629, 0.3459, 0.7541, 0.8276, 0.4136, 0.3405]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[0.3783, 0.4572, 0.6843, 0.4838, 0.5316, 0.4471, 0.3999, 0.5013, 0.4059,
         0.3808, 1.0027, 0.6070, 0.4551, 0.3758, 0.3995, 0.2493, 0.3229, 0.7436,
         0.5516, 0.3318, 0.4344, 0.5667, 0.3065, 0.5919, 0.4528, 0.3757, 0.4128,
         0.3869, 0.2527, 0.5235, 0.3234, 0.3904, 0.7798, 0.7344, 0.5285, 0.4943,
         0.5000, 0.2702, 0.4754, 0.6337, 0.5934, 0.6194, 0.2642, 0.5879, 0.5045,
         0.3251, 0.4414, 0.4442, 1.0041, 0.4779, 0.4480, 0.5173, 0.2928, 0.4661,
         0.3817, 0.2320, 0.5858, 0.4935, 0.4285, 0.3759, 0.4143, 0.8952, 0.3828,
         0.6166, 0.4370, 0.2117, 0.6908, 0.3888, 0.3423, 0.5441]],
       grad_fn=<SoftplusBackward>)
##### event loss: 4.870405197143555 non event loss:  203384.5584411621 chocie_l: 0.5533987879753113
### event lambdas:  tensor([[0.0681, 0.0961, 0.1812, 0.1678, 0.1606, 0.1682, 0.0704, 0.1346, 0.0059,
         0.0869, 0.0065, 0.1218, 0.1188, 0.0462, 0.0660, 0.0803, 0.0225]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[0.0561, 0.0751, 0.0554, 0.0489, 0.1509, 0.0360, 0.0743, 0.0357, 0.0373,
         0.0484, 0.0776, 0.0671, 0.0514, 0.0304, 0.0613, 0.0482, 0.0271, 0.0737,
         0.0463, 0.0278, 0.0587, 0.0472, 0.0763, 0.0324, 0.0574, 0.0422, 0.1982,
         0.0487, 0.1119, 0.0217, 0.0758, 0.0620, 0.0311, 0.0524, 0.0352, 0.0824,
         0.0606, 0.0722, 0.0593, 0.0390, 0.1483, 0.0850, 0.0375, 0.0412, 0.0645,
         0.0348, 0.0529, 0.0486, 0.0433, 0.0340, 0.0415, 0.0482, 0.0756, 0.0776,
         0.0400, 0.0708, 0.0528, 0.0512, 0.0653, 0.0433, 0.0319, 0.1291, 0.0368,
         0.0499, 0.0359, 0.0810, 0.0544, 0.2005, 0.0532, 0.0505, 0.0637, 0.0307,
         0.1622, 0.0531, 0.0376, 0.0295, 0.0492, 0.0295, 0.0551, 0.0458, 0.0759,
         0.0426, 0.1322, 0.0720, 0.0587, 0.0443, 0.0415, 0.0925, 0.0898, 0.0636,
         0.1094, 0.0484, 0.0728, 0.0317, 0.0541, 0.0432, 0.0515, 0.0486, 0.1385,
         0.0896, 0.0294, 0.0359, 0.0378, 0.1457, 0.0593, 0.0240, 0.0481, 0.0711,
         0.0484, 0.0301, 0.0642, 0.0463, 0.0284, 0.0609, 0.1020, 0.0460, 0.0984,
         0.0592, 0.0748, 0.0132, 0.0852, 0.0492, 0.1800, 0.0355, 0.0489, 0.0761,
         0.0537, 0.0654, 0.0645, 0.0555, 0.0425, 0.0855, 0.0514, 0.0486, 0.0513,
         0.0239, 0.0391, 0.0304, 0.0738, 0.1128, 0.0415, 0.0257, 0.0424, 0.0367,
         0.2074, 0.0484, 0.0611, 0.1739, 0.0892, 0.0732, 0.0467, 0.0248, 0.0646,
         0.0655, 0.0374, 0.0658, 0.0186, 0.1247, 0.0608, 0.0383, 0.0209, 0.0842,
         0.0388, 0.0301, 0.1217, 0.1476, 0.0491, 0.1095, 0.0720, 0.0202]],
       grad_fn=<SoftplusBackward>)
##### event loss: 45.74818420410156 non event loss:  74931.12924194336 chocie_l: 0.05693090707063675
### event lambdas:  tensor([[0.0070, 0.0045, 0.0046, 0.0038, 0.0190, 0.0146]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[0.0205, 0.0072, 0.0136, 0.0071, 0.0131, 0.0050, 0.0081, 0.0198, 0.0091,
         0.0055, 0.0077, 0.0057, 0.0067, 0.0183, 0.0043, 0.0084, 0.0069, 0.0158,
         0.0066, 0.0108, 0.0061, 0.0086, 0.0139, 0.0181, 0.0222, 0.0053, 0.0090,
         0.0101, 0.0026, 0.0113, 0.0109, 0.0034, 0.0119, 0.0037, 0.0058, 0.0101,
         0.0069, 0.0094, 0.0089, 0.0096, 0.0063, 0.0196, 0.0146, 0.0026, 0.0175,
         0.0060, 0.0102, 0.0067, 0.0054, 0.0126, 0.0109, 0.0120, 0.0060, 0.0025,
         0.0130, 0.0104, 0.0283, 0.0048, 0.0130, 0.0065]],
       grad_fn=<SoftplusBackward>)
##### event loss: 29.494930267333984 non event loss:  2052.6943670511246 chocie_l: 0.01167986635118723
  3%|████▋                                                                                                                                                                              | 13/496 [00:02<01:38,  4.90it/s]
Traceback (most recent call last):
  File "main.py", line 156, in <module>
    main()
  File "main.py", line 152, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 107, in train
    loss, pos_timing_loss, neg_timing_loss, choice_l = model(arr_b.float(), arr_c.float(), arr_delta_time.float(), event_data, non_event_data, estimate_length, choice_data_dict)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 178, in forward
    mat_c = self.c_net(arr_c)[0] # (B, L2, embedding_c);
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/rnn.py", line 821, in forward
    result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/traceback.py", line 197, in format_stack
    return format_list(extract_stack(f, limit=limit))
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/traceback.py", line 211, in extract_stack
    stack = StackSummary.extract(walk_stack(f), limit=limit)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/traceback.py", line 362, in extract
    linecache.checkcache(filename)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/linecache.py", line 74, in checkcache
    stat = os.stat(fullname)
KeyboardInterrupt
### event lambdas:  tensor([[0.0007, 0.0002, 0.0004, 0.0004, 0.0006]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[0.0004, 0.0006, 0.0002, 0.0004, 0.0003, 0.0008, 0.0008, 0.0007, 0.0005,
         0.0003, 0.0005, 0.0006, 0.0010, 0.0022, 0.0005, 0.0032, 0.0005, 0.0025,
         0.0023, 0.0007, 0.0008, 0.0002, 0.0004, 0.0003, 0.0005, 0.0027, 0.0005,
         0.0012, 0.0016, 0.0003, 0.0006, 0.0006, 0.0007, 0.0015, 0.0019, 0.0012,
         0.0006, 0.0027, 0.0004, 0.0003, 0.0007, 0.0013, 0.0002, 0.0006, 0.0006,
         0.0005, 0.0034, 0.0003, 0.0022, 0.0007]], grad_fn=<SoftplusBackward>)
##### event loss: 38.8773193359375 non event loss:  382.96605345606804 chocie_l: 0.01564721018075943
### event lambdas:  tensor([[0.0003, 0.0004, 0.0002, 0.0002]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[1.1950e-04, 6.4521e-05, 3.0162e-04, 1.4303e-04, 1.3278e-04, 2.2645e-04,
         5.9899e-04, 8.2237e-05, 8.8559e-05, 3.0793e-04, 2.3019e-04, 2.4916e-04,
         1.1595e-04, 2.0396e-04, 5.9446e-04, 4.1111e-05, 2.9470e-04, 3.5892e-04,
         2.3244e-04, 3.2142e-04, 1.6785e-04, 2.0743e-04, 2.1100e-04, 2.0888e-04,
         1.8410e-04, 1.1537e-04, 6.1931e-05, 1.6702e-04, 9.8874e-05, 8.7807e-05,
         2.8166e-04, 7.9944e-05, 1.0976e-04, 1.5338e-04, 2.8516e-04, 1.6415e-04,
         1.2751e-04, 1.1698e-04, 5.5595e-05, 1.0983e-04]],
       grad_fn=<SoftplusBackward>)
##### event loss: 32.916587829589844 non event loss:  20.59552397299558 chocie_l: 0.013698931783437729
### event lambdas:  tensor([[6.6906e-05, 3.7401e-05, 2.4696e-05, 4.8253e-06]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[2.5067e-05, 1.2026e-05, 6.1887e-05, 6.0487e-06, 2.7967e-05, 1.0737e-05,
         2.7503e-05, 1.3044e-05, 1.4009e-05, 1.0255e-05, 8.1405e-06, 3.0479e-05,
         1.6864e-05, 3.4857e-05, 2.4779e-05, 4.1721e-05, 2.2067e-05, 2.1262e-05,
         2.1125e-05, 2.6264e-05, 3.7495e-05, 7.6644e-06, 6.5136e-05, 2.6617e-05,
         9.9709e-06, 4.3655e-06, 2.6620e-05, 6.5900e-05, 2.3281e-05, 1.0496e-05,
         2.9618e-05, 2.5458e-05, 5.4790e-06, 2.7657e-05, 2.3152e-05, 1.8537e-05,
         2.7956e-05, 1.8559e-05, 2.6322e-05, 3.0801e-05]],
       grad_fn=<SoftplusBackward>)
##### event loss: 42.65652847290039 non event loss:  6.844789757626131 chocie_l: 0.02275819703936577
### event lambdas:  tensor([[2.2676e-05, 1.0946e-05, 1.6881e-05, 1.2534e-06, 4.7737e-06, 7.6743e-06,
         7.9537e-07, 2.1680e-06, 2.0242e-06, 1.2607e-06, 9.6660e-06]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[2.4160e-06, 7.9348e-06, 1.2990e-05, 6.6301e-06, 6.0648e-06, 3.8287e-06,
         6.6770e-06, 4.4961e-06, 4.1771e-06, 4.8739e-06, 2.3656e-06, 7.7376e-06,
         7.1754e-06, 2.0931e-05, 1.9389e-06, 4.5048e-06, 6.5245e-06, 1.3365e-05,
         2.6903e-06, 9.6397e-06, 1.0409e-05, 3.9898e-06, 3.6228e-06, 8.3461e-06,
         4.3975e-06, 5.0642e-06, 6.7487e-06, 5.9125e-06, 7.9546e-06, 7.1013e-06,
         4.5405e-06, 6.6104e-06, 8.5438e-06, 1.0540e-05, 2.0207e-06, 6.9123e-06,
         5.8604e-06, 5.3184e-06, 6.2246e-06, 1.1778e-05, 3.1512e-06, 4.8853e-06,
         1.3421e-05, 1.1766e-05, 4.2478e-06, 4.8427e-06, 8.9285e-06, 7.1885e-06,
         1.3457e-05, 4.4199e-06, 2.5502e-05, 6.0461e-06, 7.6350e-06, 2.3858e-06,
         1.0949e-05, 1.5752e-05, 7.8554e-06, 2.2032e-05, 4.0354e-06, 4.3687e-06,
         2.6256e-06, 2.6489e-06, 6.0012e-06, 5.7893e-07, 1.1263e-06, 5.1743e-06,
         1.3999e-06, 3.0520e-06, 4.5446e-06, 3.5827e-06, 8.5157e-06, 6.9942e-06,
         2.9602e-06, 6.7027e-06, 4.5407e-06, 3.4321e-06, 2.5794e-06, 1.2571e-05,
         4.0920e-06, 1.3398e-05, 2.4689e-06, 1.3726e-05, 1.8395e-05, 1.0521e-05,
         8.1457e-06, 7.7814e-06, 7.1151e-06, 1.0757e-05, 2.3994e-06, 1.6970e-05,
         8.6493e-06, 1.0461e-05, 1.1915e-05, 9.3243e-06, 3.4306e-06, 4.4493e-06,
         8.0273e-06, 1.6262e-05, 4.4498e-06, 6.5441e-06, 3.2494e-06, 2.2794e-05,
         5.3640e-06, 3.9823e-06, 2.7532e-06, 4.0779e-06, 3.9285e-06, 8.5592e-06,
         3.0876e-06, 8.6945e-06]], grad_fn=<SoftplusBackward>)
##### event loss: 136.05294799804688 non event loss:  3.1048788860207424 chocie_l: 0.04973585903644562
### event lambdas:  tensor([[2.4436e-06, 3.3818e-06, 1.8883e-06]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[3.0029e-06, 4.3740e-06, 2.3832e-06, 2.4824e-06, 2.5277e-06, 2.2802e-06,
         4.6396e-07, 3.1160e-06, 1.5540e-06, 4.7739e-07, 1.9343e-06, 2.2101e-06,
         2.1670e-06, 1.4038e-06, 1.6711e-06, 1.2656e-06, 8.7928e-07, 3.1938e-07,
         2.3217e-06, 1.2321e-06, 2.1069e-06, 4.0229e-06, 6.7121e-07, 2.2087e-06,
         9.9721e-07, 3.5217e-06, 2.6439e-06, 4.1230e-06, 2.0558e-06, 2.7007e-06]],
       grad_fn=<SoftplusBackward>)
##### event loss: 38.698936462402344 non event loss:  0.29097415223077405 chocie_l: 0.021097663789987564
### event lambdas:  tensor([[2.4740e-08, 1.7010e-07, 7.3551e-08, 4.1242e-07]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[4.2514e-07, 2.1288e-07, 5.3791e-07, 4.0937e-08, 4.9817e-07, 4.0875e-07,
         4.8754e-07, 4.1988e-08, 2.9505e-07, 5.5255e-07, 4.2661e-07, 2.3860e-07,
         9.9896e-07, 2.1926e-07, 4.1952e-07, 5.2361e-08, 1.3012e-06, 2.7258e-07,
         4.6893e-07, 7.2908e-08, 1.3027e-07, 5.5331e-07, 7.5622e-08, 5.3658e-07,
         3.3527e-07, 3.4676e-07, 3.6575e-07, 4.5382e-07, 5.2266e-07, 2.7270e-07,
         2.5163e-07, 1.8401e-07, 2.2423e-07, 5.0878e-08, 9.3661e-08, 4.6476e-07,
         9.5552e-08, 4.1375e-07, 4.1086e-08, 3.4892e-07]],
       grad_fn=<SoftplusBackward>)
##### event loss: 64.22825622558594 non event loss:  0.06065902582849958 chocie_l: 0.04507635533809662
### event lambdas:  tensor([[4.2846e-07, 4.0021e-07, 6.1152e-07, 1.0831e-07, 1.9326e-07, 3.6429e-07,
         4.5627e-07, 1.7925e-07, 7.3271e-07, 7.7310e-07, 6.6455e-07]],
       grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[4.1290e-07, 1.6824e-07, 7.4238e-07, 3.9751e-07, 4.8771e-07, 3.0595e-07,
         4.1170e-08, 4.9169e-07, 4.8601e-07, 6.4478e-07, 1.0740e-06, 7.5262e-08,
         1.0917e-07, 3.2713e-07, 5.4157e-08, 8.0696e-08, 1.0538e-07, 1.0801e-07,
         4.1728e-07, 5.5915e-07, 6.6341e-07, 5.2061e-07, 1.2023e-07, 3.3433e-07,
         3.2318e-07, 6.3466e-07, 3.2372e-07, 1.5554e-07, 2.1620e-07, 3.5158e-07,
         5.2563e-08, 4.3555e-07, 9.1795e-07, 4.4509e-07, 6.1259e-07, 2.9242e-07,
         5.8313e-07, 9.7831e-07, 7.8941e-07, 1.2790e-06, 5.9387e-07, 1.2608e-07,
         8.8772e-08, 2.3861e-07, 1.7324e-07, 6.8532e-07, 3.8185e-07, 4.9827e-07,
         4.4736e-07, 6.0329e-07, 8.9083e-08, 3.5267e-07, 2.0054e-07, 5.2444e-07,
         5.5518e-07, 6.3314e-07, 3.2172e-07, 4.9405e-07, 4.6397e-07, 7.6367e-07,
         6.7397e-07, 2.1994e-07, 4.0832e-07, 3.9176e-08, 1.3276e-07, 4.0927e-07,
         5.2033e-07, 5.8428e-07, 7.4073e-08, 7.6195e-07, 9.3796e-07, 2.0287e-07,
         6.3151e-07, 3.7173e-07, 6.8792e-07, 1.2626e-07, 6.3062e-07, 3.9876e-07,
         3.0914e-07, 6.1743e-07, 1.4103e-06, 7.1689e-07, 5.1215e-07, 6.4683e-07,
         7.5606e-08, 7.5938e-07, 4.2448e-07, 8.6232e-08, 3.3086e-07, 3.9162e-07,
         2.7830e-07, 4.9893e-07, 1.0759e-07, 1.3237e-06, 4.6883e-07, 2.7282e-07,
         6.8337e-08, 5.0559e-07, 6.3670e-07, 4.0207e-07, 3.5493e-07, 3.0187e-07,
         8.8931e-07, 3.6493e-07, 6.3535e-07, 5.5384e-07, 9.2269e-07, 5.1310e-08,
         1.7916e-07, 8.0372e-08]], grad_fn=<SoftplusBackward>)
##### event loss: 162.58267211914062 non event loss:  0.32070298132748576 chocie_l: 0.11320023238658905
### event lambdas:  tensor([[7.0701e-08, 1.0951e-07, 6.2034e-08, 1.4078e-07, 7.2417e-08, 1.2092e-08,
         4.1759e-08, 1.1245e-08, 8.9679e-09]], grad_fn=<SoftplusBackward>)
### non event lambdas:  tensor([[6.5522e-08, 3.0269e-08, 1.9116e-08, 7.2398e-08, 8.5789e-09, 2.2331e-08,
         4.5201e-08, 4.5021e-08, 1.3223e-08, 8.5083e-09, 1.4471e-07, 1.7694e-08,
         1.9586e-08, 3.0570e-08, 1.8847e-08, 3.8976e-08, 2.5379e-07, 3.6892e-08,
         2.9256e-08, 1.9142e-08, 1.4123e-08, 9.3911e-08, 1.6691e-08, 6.6993e-08,
         1.0861e-08, 8.7068e-08, 1.6966e-08, 1.5839e-09, 3.4046e-08, 3.3314e-09,
         2.2421e-09, 3.0903e-08, 2.6039e-08, 6.3056e-09, 6.4077e-09, 1.7407e-08,
         2.8633e-08, 7.7058e-08, 1.4115e-07, 3.1323e-08, 1.9732e-08, 5.2306e-08,
         8.2713e-08, 6.4974e-08, 3.3884e-08, 4.7592e-08, 3.5236e-08, 3.9851e-08,
         2.8424e-08, 5.8770e-08, 5.3126e-08, 1.1599e-07, 4.0487e-08, 1.5881e-08,
         6.8136e-08, 5.5273e-08, 3.1882e-08, 7.3354e-08, 9.0358e-08, 5.0937e-08,
         1.7594e-08, 2.2900e-08, 4.3205e-08, 7.1329e-09, 1.1568e-07, 2.2284e-09,
         2.1000e-09, 6.2002e-08, 8.2329e-08, 8.7887e-09, 3.0835e-08, 1.5375e-08,
         2.4524e-08, 3.2717e-09, 5.5117e-08, 1.6063e-08, 1.1360e-07, 2.0573e-07,
         1.0103e-07, 6.8112e-09, 5.1365e-08, 2.6352e-08, 3.1752e-08, 1.4770e-09,
         7.8208e-08, 2.9268e-08, 1.8172e-08, 3.9970e-08, 3.5392e-08, 3.3034e-09]],
       grad_fn=<SoftplusBackward>)
##### event loss: 153.3595428466797 non event loss:  0.02943834232792142 chocie_l: 0.13041897118091583