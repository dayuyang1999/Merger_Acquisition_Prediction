
CUDA availability: True
Traceback (most recent call last):
  File "main.py", line 89, in <module>
    main()
  File "main.py", line 85, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 48, in train
    loss, timing_loss, choice_loss  = model(arr_b.float(), arr_c.float(), arr_delta_time.float(), event_data, non_event_data, estimate_length, choice_data_dict)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 199, in forward
    event_choice_loss = self.choice_net(mat_b, mat_c, choice_data_dict, self.s_year, self.e_year)*1000
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 359, in forward
    choice_l = F.binary_cross_entropy(torch.sigmoid(logits_i), true_tar_idxs_i)  # inputs are both (N_i_2, N_i_1)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/functional.py", line 2759, in binary_cross_entropy
    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
RuntimeError: all elements of input should be between 0 and 1
#### arr_b tensor([[[ 2.1178,  0.3464, -0.0881, -0.3440, -0.3440, -0.3440, -0.3440,
          -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440],
         [ 2.4585,  0.4226, -0.0881, -0.3440, -0.3440, -0.3440, -0.3440,
          -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440],
         [ 2.6785,  0.5416, -0.2873, -0.3440, -0.3440, -0.3440, -0.3440,
          -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440],
         [ 3.0798,  0.5252, -0.2812, -0.3440, -0.3440, -0.3440, -0.3440,
          -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440],
         [ 3.6346,  0.5599, -0.2824, -0.3440, -0.3440, -0.3440, -0.3440,
          -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440],
         [ 4.1343,  0.5799, -0.2564, -0.3440, -0.3440, -0.3440, -0.3440,
          -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440],
         [ 3.1081,  0.4573, -0.0881, -0.3440, -0.3440, -0.3440, -0.3440,
          -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440],
         [ 3.1081,  0.4573, -0.0881, -0.3440, -0.3440, -0.3440, -0.3440,
          -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440],
         [ 3.1081,  0.4573, -0.0881, -0.3440, -0.3440, -0.3440, -0.3440,
          -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440],
         [ 5.1569,  0.8298, -0.2351, -0.3440, -0.3440, -0.3440, -0.3440,
          -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440],
         [ 3.1081,  0.4573, -0.0881, -0.3440, -0.3440, -0.3440, -0.3440,
          -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440],
         [ 5.0634,  0.7334,  0.1558, -0.3440, -0.3440, -0.3440, -0.3440,
          -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440, -0.3440]]]) torch.Size([1, 12, 14])
#### mat_b tensor([[[ 0.0087,  0.2683,  0.0167, -0.3396,  0.1119,  0.1395, -0.1544,
          -0.3565,  0.2028,  0.1245,  0.1479, -0.1375,  0.2080,  0.1929,
          -0.0481,  0.1949, -0.0019,  0.0735,  0.2495, -0.1306, -0.0574,
           0.3002, -0.0490, -0.1957, -0.1177,  0.3895,  0.1007, -0.1271,
           0.5306,  0.1790, -0.1031, -0.2817],
         [ 0.1229,  0.0656,  0.0116, -0.3781,  0.1151,  0.1597, -0.1854,
          -0.3448,  0.2543,  0.2632,  0.3709,  0.0101,  0.1917,  0.3341,
          -0.1710, -0.0283,  0.0339,  0.1018,  0.2929, -0.1196, -0.0744,
           0.1976,  0.0205, -0.2238, -0.1411,  0.3070,  0.2207, -0.2167,
           0.4890,  0.0677, -0.1730, -0.2422],
         [ 0.3060, -0.0838,  0.2386, -0.1649,  0.1132,  0.0867, -0.2097,
          -0.2236,  0.1502,  0.1741,  0.3270, -0.1495,  0.2033,  0.4044,
          -0.3610, -0.0660,  0.1997,  0.0816,  0.2939, -0.0417, -0.1280,
           0.1888,  0.1719, -0.0565, -0.2212,  0.1908,  0.1244, -0.2500,
           0.2249, -0.0823, -0.3014, -0.1301],
         [ 0.1541,  0.1751, -0.0271, -0.2875, -0.0850,  0.3279, -0.3085,
          -0.2879,  0.3333,  0.2912,  0.3824, -0.0431,  0.2572,  0.4221,
          -0.2119, -0.0911, -0.0640,  0.3607,  0.0691,  0.0334, -0.1689,
           0.2280,  0.0583, -0.1943, -0.1253,  0.4644,  0.2323, -0.0897,
           0.5813,  0.0455, -0.0406, -0.2994],
         [ 0.1186,  0.2916,  0.1534, -0.1261, -0.0771,  0.1952, -0.5935,
          -0.3072,  0.3531,  0.1963,  0.1834, -0.4449,  0.2839,  0.6996,
          -0.0901,  0.0668,  0.1157,  0.1383,  0.4896,  0.0062, -0.1594,
           0.3560,  0.1560, -0.1246, -0.2599,  0.4436,  0.0516, -0.2427,
           0.6355, -0.0094, -0.4247, -0.2980],
         [-0.2449,  0.4300, -0.0868, -0.4416,  0.0811,  0.2509, -0.3263,
          -0.4855,  0.3088,  0.1525,  0.0317, -0.3416,  0.5351,  0.3202,
           0.2027,  0.2265,  0.0341,  0.2494,  0.3225, -0.2273, -0.2682,
           0.3438, -0.0889, -0.3169, -0.0802,  0.5759,  0.1124, -0.3625,
           0.8999,  0.4894, -0.0405, -0.5536],
         [ 0.1465,  0.4911, -0.0869, -0.3155,  0.0083,  0.0962, -0.5242,
          -0.3101,  0.3618,  0.2302,  0.3787, -0.3219,  0.3582,  0.2747,
          -0.2666,  0.0413, -0.0311,  0.2285,  0.0401, -0.0687, -0.0099,
           0.3123, -0.2250, -0.1956, -0.1434,  0.5046,  0.0991, -0.4123,
           0.6666,  0.1234, -0.2760, -0.1770],
         [ 0.0523,  0.4201, -0.0763, -0.2367,  0.0916,  0.2003, -0.4812,
          -0.3195,  0.4801,  0.1840,  0.3062, -0.2502,  0.5146,  0.4139,
          -0.1076,  0.0646,  0.0920,  0.1314,  0.1275, -0.0100, -0.1006,
           0.1544, -0.2028, -0.1395, -0.2659,  0.4411, -0.0240, -0.2839,
           0.6105,  0.1660, -0.2445, -0.1698],
         [ 0.0285,  0.0130,  0.3097,  0.1293, -0.0462,  0.1381, -0.3923,
          -0.3621,  0.2712,  0.1421,  0.0343,  0.0231,  0.0679,  0.4938,
          -0.2911, -0.0078, -0.0102,  0.2869,  0.3490,  0.2544, -0.2102,
           0.2037,  0.1607,  0.0602, -0.0597,  0.4763,  0.2002, -0.0400,
           0.3588,  0.0125, -0.3881, -0.1210],
         [ 0.1241,  0.3616,  0.3234,  0.0881, -0.4361,  0.5237, -0.5926,
          -0.4617,  0.3131,  0.2137,  0.0678, -0.1029, -0.0344,  0.9089,
          -0.1678,  0.2159,  0.0301,  0.4271,  0.3992,  0.2183, -0.3610,
           0.4855,  0.2823, -0.1011, -0.1385,  0.6943,  0.1533,  0.1238,
           0.7858, -0.1280,  0.0389, -0.4090],
         [-0.0029,  0.1972, -0.2079, -0.3453, -0.1816,  0.2977, -0.3162,
          -0.1710,  0.2545,  0.4402,  0.4055, -0.1720,  0.1282,  0.2367,
          -0.0157, -0.1115,  0.1016,  0.1671, -0.0033, -0.0552, -0.2099,
           0.0097, -0.1782, -0.4137,  0.0444,  0.3963, -0.0885, -0.2202,
           0.4450,  0.1054, -0.1065, -0.2513],
         [-0.2180,  0.7946, -0.3276, -0.0902, -0.5799,  0.2989, -0.4828,
          -0.6207,  0.7462,  0.7123,  0.5372, -0.3542,  0.3792,  0.6440,
          -0.1208, -0.0193, -0.0792,  0.5592, -0.1281, -0.0682, -0.3014,
           0.4368,  0.2114, -0.1639, -0.1246,  0.9128, -0.0145, -0.5063,
           0.8990,  0.3914, -0.6222, -0.3456]]], grad_fn=<AddBackward0>) torch.Size([1, 12, 32])
#### arr_b tensor([[[ 1.8171,  0.2861, -0.0801, -0.3430, -0.3430, -0.3430, -0.3430,
          -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430],
         [ 2.1860,  0.3663, -0.0801, -0.3430, -0.3430, -0.3430, -0.3430,
          -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430],
         [ 2.5361,  0.4445, -0.0801, -0.3430, -0.3430, -0.3430, -0.3430,
          -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430],
         [ 2.7621,  0.5668, -0.2848, -0.3430, -0.3430, -0.3430, -0.3430,
          -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430],
         [ 3.1743,  0.5500, -0.2785, -0.3430, -0.3430, -0.3430, -0.3430,
          -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430],
         [ 3.7443,  0.5856, -0.2797, -0.3430, -0.3430, -0.3430, -0.3430,
          -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430],
         [ 4.2576,  0.6062, -0.2530, -0.3430, -0.3430, -0.3430, -0.3430,
          -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430],
         [ 3.2034,  0.4802, -0.0801, -0.3430, -0.3430, -0.3430, -0.3430,
          -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430],
         [ 3.2034,  0.4802, -0.0801, -0.3430, -0.3430, -0.3430, -0.3430,
          -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430],
         [ 3.2034,  0.4802, -0.0801, -0.3430, -0.3430, -0.3430, -0.3430,
          -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430],
         [ 5.3081,  0.8629, -0.2311, -0.3430, -0.3430, -0.3430, -0.3430,
          -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430],
         [ 3.2034,  0.4802, -0.0801, -0.3430, -0.3430, -0.3430, -0.3430,
          -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430],
         [ 5.2120,  0.7638,  0.1704, -0.3430, -0.3430, -0.3430, -0.3430,
          -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430, -0.3430]]]) torch.Size([1, 13, 14])
#### mat_b tensor([[[ 0.2137,  0.1140,  0.0210, -0.1974,  0.1201,  0.0565, -0.1085,
          -0.2160,  0.1401, -0.0605,  0.3405, -0.1588, -0.0082,  0.1827,
          -0.3675, -0.1049, -0.0834,  0.2218,  0.2266,  0.1364, -0.0266,
           0.3458, -0.0511, -0.0100, -0.2232,  0.3388,  0.2617, -0.2212,
           0.4383, -0.0971, -0.2992, -0.2031],
         [ 0.2439,  0.2623,  0.0538, -0.2723, -0.1450,  0.0177, -0.1242,
          -0.1265,  0.2302,  0.0285,  0.3986, -0.3454, -0.1027,  0.0746,
          -0.2688, -0.0661,  0.0929,  0.2128,  0.1377,  0.0122, -0.0964,
           0.3244,  0.0563,  0.0151, -0.1599,  0.3754,  0.1912, -0.4124,
           0.5012, -0.1512, -0.2532, -0.4253],
         [ 0.1537,  0.4186, -0.1742, -0.1575, -0.1450,  0.0519, -0.2416,
          -0.3820,  0.3706,  0.1037,  0.4027, -0.1011, -0.0209,  0.1223,
          -0.5335, -0.0900, -0.2924,  0.4687, -0.0197,  0.1817,  0.2133,
           0.4481, -0.2827, -0.0293, -0.2592,  0.6537,  0.2734, -0.3066,
           0.7210, -0.0245, -0.4206, -0.1151],
         [ 0.1637,  0.6512, -0.1875, -0.3880, -0.1525, -0.0169, -0.2940,
          -0.0657,  0.5772,  0.0434,  0.3828, -0.0983,  0.0217, -0.0735,
          -0.4338, -0.1041, -0.3601,  0.5924, -0.0502,  0.1046, -0.0175,
           0.3729, -0.2895,  0.1795, -0.1189,  0.6701,  0.2811, -0.4992,
           0.9027, -0.0326, -0.3515, -0.4588],
         [ 0.1779,  0.7296, -0.3102, -0.3497, -0.2785, -0.0332, -0.3936,
          -0.1057,  0.5436,  0.0511,  0.4037, -0.2445,  0.0760, -0.0433,
          -0.4987, -0.0366, -0.5116,  0.5728, -0.0902,  0.1098,  0.1530,
           0.2635, -0.3405,  0.0878, -0.3294,  0.7965,  0.1908, -0.3309,
           0.8012, -0.1592, -0.3796, -0.2172],
         [ 0.3703,  0.5530, -0.3218, -0.6586, -0.2867,  0.0853, -0.2925,
           0.0564,  0.7343,  0.2594,  0.7470, -0.3305,  0.0751,  0.2302,
          -0.3619, -0.3251, -0.2082,  0.3119, -0.0275, -0.0257,  0.0757,
           0.3087, -0.2675, -0.1054, -0.4028,  0.5340,  0.4573, -0.6032,
           1.0132, -0.2287, -0.3003, -0.6260],
         [ 0.4243,  0.7945, -0.3274, -0.5667, -0.5655,  0.1218, -0.2532,
          -0.0510,  0.8846,  0.2042,  0.4817, -0.4171,  0.0592,  0.3111,
          -0.4794, -0.2897, -0.5334,  0.6713, -0.2782,  0.0508,  0.2062,
           0.6231, -0.0750,  0.0025, -0.4269,  1.0588,  0.4331, -0.4664,
           1.1636, -0.1342, -0.6177, -0.7306],
         [ 0.3134,  0.4672, -0.2935, -0.5634, -0.2056, -0.0115, -0.1695,
           0.0104,  0.5591,  0.0823,  0.5405, -0.4201,  0.2004,  0.1699,
          -0.4501, -0.1706, -0.3341,  0.5260, -0.0508,  0.1532,  0.1423,
           0.4241, -0.1454, -0.0074, -0.3590,  0.5986,  0.4021, -0.4670,
           0.8644, -0.1172, -0.3101, -0.4057],
         [ 0.0486,  0.5251, -0.4032, -0.5779,  0.0598,  0.0694, -0.2271,
           0.0240,  0.5649, -0.1470,  0.2375, -0.2280,  0.2687, -0.0021,
          -0.2531, -0.0809, -0.3767,  0.4037,  0.0760,  0.0197, -0.0355,
           0.2003, -0.5150, -0.0862, -0.1197,  0.5581,  0.2391, -0.3905,
           0.7815,  0.0957, -0.1822, -0.3141],
         [ 0.0921,  0.8122, -0.3701, -0.3939, -0.2957, -0.0972, -0.4209,
          -0.2043,  0.5103,  0.0816,  0.6331, -0.4054,  0.0102, -0.0361,
          -0.4905, -0.0123, -0.3578,  0.5169, -0.0846,  0.1597, -0.0347,
           0.4115, -0.4181,  0.0148, -0.1013,  0.6855,  0.2509, -0.6303,
           0.7722, -0.0642, -0.3935, -0.1480],
         [ 0.2567,  0.6246, -0.5189, -0.7879, -0.6866, -0.0705, -0.1299,
           0.3630,  0.4387,  0.5266,  0.9116, -0.5493,  0.0048,  0.0115,
          -0.4123, -0.4455, -0.2206,  1.1826, -0.3401,  0.1595, -0.1394,
           0.3862, -0.1887, -0.0524,  0.1807,  0.6217,  0.1042, -0.7673,
           0.8480, -0.0573, -0.1267, -0.5981],
         [ 0.2090,  0.6785,  0.0189, -0.1952, -0.3992, -0.0302, -0.2843,
          -0.1160,  0.5064,  0.0458,  0.4410, -0.3071, -0.1703,  0.1589,
          -0.5404, -0.0786, -0.2239,  0.5731,  0.0116,  0.1680, -0.2330,
           0.5481, -0.0336,  0.1744, -0.0986,  0.6461,  0.2104, -0.6005,
           0.6672, -0.2011, -0.5551, -0.3750],
         [ 0.5153,  0.8364, -0.6054, -0.2046, -0.8138,  0.0102, -0.5569,
          -0.0980,  0.9264,  0.4108,  1.1332, -0.5278,  0.1087,  0.3013,
          -0.6048, -0.5460, -0.2200,  0.5515, -0.7881,  0.3525,  0.4145,
           0.4623, -0.4607, -0.1238, -0.3975,  0.9850,  0.3902, -0.4364,
           0.9593, -0.3581, -0.5292, -0.2868]]], grad_fn=<AddBackward0>) torch.Size([1, 13, 32])
#### arr_b tensor([[[ 1.6416,  0.2271, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 1.8722,  0.3001, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.2511,  0.3824, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.6105,  0.4627, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.8426,  0.5884, -0.2861, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2659,  0.5711, -0.2796, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.8512,  0.6076, -0.2809, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 4.3783,  0.6288, -0.2535, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.4571,  0.8924, -0.2310, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.3584,  0.7907,  0.1813, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.1351,  0.7417,  0.2302, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 4.3846,  0.7205,  0.3123, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3435, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4078, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3785, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3619, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 1.5889,  0.3488, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459]]]) torch.Size([1, 24, 14])
#### mat_b tensor([[[ 0.2878,  0.2318, -0.1295, -0.2961,  0.0656, -0.0481, -0.0724,
           0.0498,  0.2582, -0.1131,  0.3961, -0.3044, -0.0129, -0.1230,
          -0.2963, -0.1773, -0.0061,  0.2189,  0.0029,  0.0623, -0.0178,
           0.2045, -0.2758,  0.0422, -0.1044,  0.3329,  0.0727, -0.3586,
           0.2748, -0.1070, -0.2636, -0.2771],
         [ 0.4075,  0.5298, -0.1268, -0.5118, -0.1096, -0.1024, -0.2431,
           0.0163,  0.3785, -0.0988,  0.4121, -0.3790, -0.0423, -0.1145,
          -0.4771, -0.2028, -0.2218,  0.5152, -0.0840,  0.1610,  0.1795,
           0.3984, -0.4399,  0.1512, -0.1286,  0.5832,  0.2166, -0.4286,
           0.5920, -0.1320, -0.3341, -0.3118],
         [ 0.3140,  0.7211, -0.2472, -0.3865, -0.2894, -0.1948, -0.2611,
           0.0372,  0.5579, -0.1542,  0.4924, -0.4292, -0.0521, -0.1754,
          -0.6037, -0.2479, -0.2722,  0.6567, -0.2122,  0.2172,  0.1457,
           0.3992, -0.4304,  0.2192, -0.0654,  0.6795,  0.2840, -0.6315,
           0.7190, -0.1463, -0.4484, -0.2211],
         [ 0.1373,  0.4243, -0.1682, -0.3511, -0.2025, -0.2149, -0.0015,
          -0.1915,  0.2976, -0.1547,  0.2966, -0.4520,  0.0154, -0.1686,
          -0.3291, -0.0965, -0.2307,  0.4987, -0.2939,  0.2776,  0.0724,
           0.4250, -0.1728, -0.0086, -0.0577,  0.7547,  0.3064, -0.4827,
           0.6534,  0.0991, -0.4552, -0.3269],
         [ 0.4019,  0.6545, -0.4123, -0.5773, -0.2479, -0.2010, -0.1367,
           0.1394,  0.7287, -0.0510,  0.5393, -0.5077,  0.1599, -0.1533,
          -0.4513, -0.2752, -0.3664,  0.5564, -0.2802,  0.2973,  0.2161,
           0.4738, -0.3312,  0.2574, -0.4059,  0.8403,  0.2665, -0.6695,
           0.7411, -0.0647, -0.6071, -0.4703],
         [ 0.3733,  0.6664, -0.2904, -0.4823, -0.1837, -0.2517, -0.2516,
          -0.0988,  0.6573, -0.0473,  0.7273, -0.4572,  0.0640,  0.0663,
          -0.6328, -0.2947, -0.3093,  0.4234, -0.1639,  0.2864,  0.2649,
           0.4816, -0.3999,  0.1118, -0.3699,  0.7549,  0.5727, -0.6812,
           0.9599, -0.1853, -0.6460, -0.3652],
         [ 0.3569,  0.5447,  0.0393, -0.2312, -0.5878, -0.1682, -0.1617,
           0.0713,  0.6058, -0.0460,  0.3396, -0.6642, -0.2053,  0.1812,
          -0.2621, -0.2248, -0.1425,  0.4042, -0.0221,  0.3896, -0.0253,
           0.6720,  0.0660,  0.3148, -0.4203,  0.7806,  0.4503, -0.5221,
           0.9042, -0.2273, -0.6729, -0.8072],
         [ 0.1093,  1.1050, -0.5404, -0.8019, -0.5005, -0.1940, -0.0099,
          -0.0184,  0.7710, -0.0671,  0.5593, -0.6680, -0.1021, -0.3544,
          -0.1865, -0.1336, -0.3349,  0.4143, -0.3349, -0.2666,  0.2515,
           0.4271, -0.3933, -0.0974, -0.2352,  0.9994,  0.3603, -0.7986,
           1.3207, -0.0684, -0.4439, -1.0235],
         [ 0.1230,  0.3284, -0.2741, -0.3247, -0.1345, -0.2809,  0.0891,
           0.0233,  0.2059, -0.1468,  0.4410, -0.5657,  0.0105,  0.0648,
          -0.5115, -0.1415, -0.3442,  0.4552,  0.1020,  0.2493, -0.0703,
           0.4248, -0.0502,  0.0787, -0.2518,  0.5029,  0.2688, -0.4724,
           0.5246, -0.0756, -0.6800, -0.1683],
         [ 0.4097,  0.8518, -0.4633, -0.5590, -0.5305, -0.2122, -0.2036,
           0.0673,  0.7112,  0.0263,  0.8463, -0.4904, -0.0734, -0.0601,
          -0.6505, -0.3957, -0.5005,  0.7769, -0.3126,  0.2594,  0.2161,
           0.5047, -0.3801,  0.1944, -0.4344,  0.8317,  0.4926, -0.6444,
           1.1251, -0.3668, -0.5547, -0.5049],
         [ 0.1458,  0.7453, -0.2918, -0.2908, -0.6060, -0.1491,  0.0293,
          -0.1513,  0.7062,  0.0623,  0.6069, -0.4272, -0.0679, -0.1902,
          -0.3253, -0.2808, -0.2183,  0.5965, -0.4085,  0.2241,  0.0946,
           0.5804, -0.0924,  0.1944, -0.3044,  0.8609,  0.4669, -0.6534,
           0.9163, -0.0159, -0.4981, -0.6374],
         [ 0.4300,  1.0340, -0.2497, -0.0776, -1.1462, -0.3468, -0.2833,
          -0.2166,  0.6912,  0.0093,  0.6958, -1.1851, -0.3994,  0.2516,
          -0.4324, -0.2342, -0.2759,  0.7116, -0.2847,  0.3509,  0.1862,
           1.1162,  0.1414,  0.3371, -0.5453,  1.1218,  0.4905, -0.7609,
           1.1233, -0.2999, -0.9984, -0.7221],
         [ 0.4896,  0.7122, -0.2030, -0.3147, -0.3551, -0.2455, -0.3586,
           0.2568,  0.5783, -0.1828,  0.4725, -0.7444, -0.0619,  0.0580,
          -0.7664, -0.1269, -0.3891,  0.5441, -0.0901,  0.4027,  0.0899,
           0.4707, -0.2893,  0.2907, -0.3869,  0.7792,  0.2490, -0.6690,
           0.6942, -0.3839, -0.6721, -0.2736],
         [ 0.9396,  0.6175, -0.2661, -0.4774, -0.2874,  0.0487, -0.3804,
           0.4500,  0.9294, -0.0833,  0.8060, -0.7594,  0.0685,  0.7883,
          -0.6720, -0.6308, -0.1827,  0.4945,  0.0294,  0.5401,  0.3911,
           0.7454, -0.5050,  0.3707, -0.9011,  0.5384,  0.4216, -0.4460,
           1.1141, -0.6248, -0.6070, -0.6523],
         [ 0.7825,  1.0132, -0.1467, -0.5676, -0.5997, -0.2010, -0.4126,
           0.4014,  0.6755, -0.1120,  0.6519, -0.4890, -0.5092,  0.1638,
          -0.9594, -0.4902, -0.7798,  1.1320, -0.0072,  0.2998,  0.0021,
           0.9969, -0.2623,  0.5956, -0.1991,  0.8049,  0.5770, -0.7310,
           1.1679, -0.6052, -0.7242, -0.7065],
         [ 0.3433,  0.5181, -0.3449, -0.1662, -0.3864,  0.0078, -0.1091,
           0.0190,  0.6595,  0.1292,  0.7124, -0.4565, -0.0551,  0.1743,
          -0.4886, -0.3405, -0.1890,  0.3550, -0.0693,  0.3318,  0.2324,
           0.6421, -0.2629,  0.0924, -0.7370,  0.6206,  0.3195, -0.5632,
           0.8781, -0.2606, -0.6386, -0.5085],
         [ 0.2556,  0.7336, -0.4477, -0.5013, -0.4099, -0.0597, -0.0961,
          -0.0970,  0.7560,  0.0615,  0.8869, -0.2968,  0.0444, -0.0419,
          -0.5246, -0.4304, -0.2835,  0.5712, -0.2305,  0.1757,  0.0044,
           0.4792, -0.4757,  0.1570, -0.4555,  0.5793,  0.4625, -0.6861,
           0.9391, -0.1858, -0.4928, -0.4052],
         [ 0.3024,  0.7838, -0.3533, -0.6244, -0.3072, -0.1611, -0.3565,
           0.0176,  0.6122, -0.1486,  0.5197, -0.3371, -0.0838, -0.1977,
          -0.3616, -0.2550, -0.5121,  0.7524, -0.2966,  0.2661, -0.0095,
           0.4703, -0.6295,  0.0940,  0.0284,  0.8658,  0.2851, -0.5565,
           0.7932, -0.1750, -0.3819, -0.4806],
         [ 0.4385,  0.8428, -0.4377, -0.6207, -0.7110, -0.2052, -0.1769,
          -0.1812,  0.8248,  0.1375,  1.1712, -0.4386, -0.1868,  0.1445,
          -0.9535, -0.5223, -0.4915,  0.7367, -0.3302,  0.3999,  0.2243,
           0.6332, -0.2848,  0.0202, -0.3587,  1.1448,  0.9289, -0.7682,
           1.2288, -0.4770, -0.7329, -0.5382],
         [ 0.6539,  0.3663,  0.2070, -0.4303, -0.1590, -0.1513, -0.2548,
           0.1437,  0.4010, -0.1723,  0.2418, -0.4811, -0.1484,  0.3635,
          -0.6454, -0.3344, -0.2996,  0.5115,  0.1120,  0.3638,  0.1783,
           0.5298, -0.0460,  0.2732, -0.2897,  0.6876,  0.3929, -0.3412,
           0.5968, -0.3704, -0.7144, -0.3996],
         [ 0.3045,  0.7523, -0.3667, -0.5428, -0.5243, -0.0941, -0.1933,
          -0.0252,  0.5622,  0.0743,  0.7672, -0.3488, -0.1827, -0.2903,
          -0.3025, -0.3093, -0.2221,  0.5010, -0.2639,  0.0700,  0.0405,
           0.3362, -0.2012,  0.0939, -0.2254,  0.8493,  0.3968, -0.6025,
           0.8891, -0.2624, -0.2948, -0.6721],
         [ 0.4893,  0.6027, -0.1569, -0.3394, -0.1765, -0.1590, -0.4603,
           0.2908,  0.4893, -0.1328,  0.5326, -0.5862, -0.0155,  0.1602,
          -0.4602, -0.3273, -0.1873,  0.3947,  0.0893,  0.3151,  0.0889,
           0.3202, -0.3991,  0.2908, -0.3776,  0.5519,  0.2360, -0.4077,
           0.6944, -0.3796, -0.4967, -0.3763],
         [ 0.3706,  0.5647, -0.4548, -0.5633, -0.1297, -0.0828, -0.0266,
           0.1222,  0.6248,  0.0215,  0.8176, -0.3980,  0.1978,  0.0479,
          -0.5356, -0.3251, -0.1698,  0.4939, -0.1937,  0.2889,  0.2476,
           0.4779, -0.5097,  0.1332, -0.4188,  0.3779,  0.3367, -0.5850,
           0.7848, -0.1189, -0.2622, -0.2635],
         [ 0.2307,  0.3263,  0.0019, -0.0811, -0.1378, -0.0175, -0.0362,
          -0.1864,  0.2165, -0.1327,  0.2437, -0.2809, -0.1004, -0.0233,
          -0.3083, -0.0760, -0.0520,  0.2626, -0.0938,  0.0813, -0.0215,
           0.3513, -0.1120,  0.1350, -0.1984,  0.3617,  0.0622, -0.2233,
           0.3810, -0.0738, -0.3860, -0.2030]]], grad_fn=<AddBackward0>) torch.Size([1, 24, 32])
#### arr_b tensor([[[ 1.5819,  0.2132, -0.0801, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413],
         [ 1.8051,  0.2838, -0.0801, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413],
         [ 2.1717,  0.3634, -0.0801, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413],
         [ 2.5195,  0.4412, -0.0801, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413],
         [ 2.7441,  0.5627, -0.2835, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413],
         [ 3.1537,  0.5460, -0.2772, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413],
         [ 3.7201,  0.5813, -0.2784, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413],
         [ 4.2301,  0.6018, -0.2519, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413],
         [ 3.1826,  0.4766, -0.0801, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413],
         [ 3.1826,  0.4766, -0.0801, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413],
         [ 3.1826,  0.4766, -0.0801, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413],
         [ 5.2740,  0.8569, -0.2302, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413],
         [ 3.1826,  0.4766, -0.0801, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413],
         [ 5.1785,  0.7585,  0.1688, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413],
         [ 4.9625,  0.7111,  0.2161, -0.3413, -0.3413, -0.3413, -0.3413,
          -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413, -0.3413]]]) torch.Size([1, 15, 14])
#### mat_b tensor([[[ 0.3990,  0.3005, -0.0825, -0.3564, -0.0867, -0.2027, -0.1173,
           0.1746,  0.2879, -0.1357,  0.3848, -0.4258, -0.1181, -0.1395,
          -0.3951, -0.2275, -0.1671,  0.4246,  0.0739,  0.3301,  0.0431,
           0.3566, -0.2289,  0.2624, -0.1251,  0.4743,  0.2268, -0.3873,
           0.3473, -0.1911, -0.3898, -0.3111],
         [ 0.4397,  0.5750, -0.0728, -0.3829, -0.2659, -0.0974, -0.1201,
           0.1244,  0.3552, -0.1190,  0.4918, -0.4208, -0.2202, -0.1102,
          -0.6027, -0.2356, -0.2893,  0.4330, -0.0270,  0.1864,  0.0390,
           0.4296, -0.2758,  0.1364, -0.3011,  0.5985,  0.2816, -0.4863,
           0.5891, -0.3742, -0.4806, -0.3809],
         [ 0.2861,  0.4653, -0.2861, -0.4823, -0.2312, -0.0362,  0.0662,
           0.1075,  0.4595, -0.0179,  0.4786, -0.1122, -0.1481, -0.2070,
          -0.4611, -0.3360, -0.2814,  0.5208, -0.2562,  0.0399,  0.1132,
           0.3442, -0.5085,  0.0220, -0.0898,  0.3693,  0.2196, -0.4355,
           0.6388, -0.1345, -0.2574, -0.3057],
         [ 0.2828,  0.7996, -0.4972, -0.6808, -0.2394, -0.2693, -0.0594,
           0.2420,  0.6252, -0.1767,  0.6035, -0.5217, -0.0609, -0.3164,
          -0.4579, -0.3667, -0.4311,  0.6399, -0.2619,  0.1946,  0.1740,
           0.4204, -0.5499,  0.1244, -0.1776,  0.7574,  0.3993, -0.7360,
           0.9743, -0.1368, -0.4684, -0.6028],
         [ 0.3750,  0.6672, -0.4655, -0.7031, -0.2039, -0.2609, -0.0302,
           0.0226,  0.4613, -0.2467,  0.7350, -0.5429, -0.0779, -0.2316,
          -0.6761, -0.3661, -0.5031,  0.6239, -0.1652,  0.2668,  0.1702,
           0.5538, -0.5184,  0.0075, -0.2191,  0.8957,  0.5947, -0.7232,
           0.8798, -0.2095, -0.5356, -0.4336],
         [ 0.5986,  0.9657, -0.5113, -0.7412, -0.4802, -0.3301, -0.0662,
           0.2443,  0.8244, -0.2167,  0.7719, -0.6121, -0.1067, -0.1632,
          -0.7620, -0.5180, -0.5282,  0.8666, -0.3596,  0.2719,  0.3347,
           0.6570, -0.5343,  0.3830, -0.3990,  0.8064,  0.5101, -0.7942,
           1.1327, -0.2977, -0.6823, -0.4845],
         [ 0.5896,  0.9638, -0.6183, -0.9489, -0.6599, -0.2319, -0.0450,
           0.4433,  0.7190,  0.0149,  0.9105, -0.8278, -0.2354, -0.1962,
          -0.7563, -0.5246, -0.4470,  0.8590, -0.4356,  0.1716,  0.3074,
           0.5671, -0.6067, -0.0269, -0.2194,  0.9086,  0.4210, -0.9775,
           1.1694, -0.4332, -0.5167, -0.7146],
         [ 0.6055,  0.7249, -0.3105, -0.8514, -0.1614, -0.1313, -0.1474,
           0.4943,  0.5382, -0.0483,  0.7369, -0.6454, -0.2513, -0.0194,
          -0.5103, -0.5239, -0.2573,  0.4988,  0.1301,  0.1307,  0.1940,
           0.5301, -0.6469,  0.1675, -0.4394,  0.5142,  0.2168, -0.7762,
           0.9918, -0.5277, -0.5449, -0.8428],
         [ 0.3518,  0.7408, -0.4211, -0.4419, -0.3606, -0.4082, -0.0251,
           0.0403,  0.6988, -0.0868,  0.6954, -0.5023, -0.0254, -0.1247,
          -0.7610, -0.4104, -0.4533,  0.6833, -0.2744,  0.3495,  0.2608,
           0.5613, -0.3995,  0.3569, -0.3799,  0.7688,  0.5464, -0.7738,
           1.0168, -0.1049, -0.8698, -0.3062],
         [ 0.5085,  1.0181, -0.5205, -0.7364, -0.6634, -0.3420, -0.1093,
           0.0860,  0.9415, -0.0741,  0.9261, -0.6022, -0.1850, -0.1692,
          -0.6919, -0.4471, -0.5151,  0.7935, -0.4329,  0.3354,  0.2589,
           0.7259, -0.4939,  0.2511, -0.4737,  0.9504,  0.6046, -0.9502,
           1.2380, -0.3694, -0.7477, -0.6800],
         [ 0.6054,  0.8479,  0.0053, -0.4325, -0.5437, -0.3147, -0.2333,
           0.1505,  0.5820, -0.2728,  0.6296, -0.6741, -0.3887, -0.1884,
          -0.7182, -0.2428, -0.1502,  0.5366, -0.1794,  0.2222,  0.0792,
           0.5383, -0.1975,  0.3287, -0.2212,  0.7873,  0.4278, -0.8580,
           0.8246, -0.5892, -0.5420, -0.5881],
         [ 0.2379,  1.3117, -0.8760, -1.0565, -0.9743, -0.5452,  0.2023,
           0.3807,  0.6826, -0.1888,  0.7601, -1.4180, -0.1706, -0.5885,
          -0.5976, -0.2542, -0.7110,  1.1117, -0.6592,  0.4251, -0.0538,
           0.9091, -0.3482,  0.1368, -0.0984,  1.4253,  0.6372, -1.3891,
           1.3272,  0.0697, -0.6925, -0.9497],
         [ 0.7840,  0.7190, -0.1489, -0.3976, -0.4330, -0.0668, -0.2011,
           0.3430,  0.5517, -0.1819,  0.5806, -0.5162, -0.3144,  0.1535,
          -0.9867, -0.4152, -0.4464,  0.7172, -0.1770,  0.3418,  0.2574,
           0.6690, -0.4166,  0.2796, -0.4703,  0.6556,  0.3948, -0.5497,
           0.8812, -0.5991, -0.5308, -0.3856],
         [ 0.6884,  1.0767, -0.3262, -0.2438, -0.8976, -0.3204, -0.3244,
           0.1616,  0.4351, -0.2033,  1.0210, -1.1721, -0.4053,  0.2134,
          -0.7093, -0.3858, -0.0846,  0.8002, -0.2077,  0.6257,  0.1507,
           0.8897, -0.3493,  0.4979, -0.5009,  0.8112,  0.3270, -0.6461,
           1.0342, -0.6126, -0.5802, -0.4431],
         [ 0.5756,  1.8230, -0.8151, -0.7856, -1.2115, -0.5044, -0.3451,
           0.3479,  1.2548, -0.0310,  1.2298, -0.9057, -0.5267, -0.3090,
          -1.2228, -0.6397, -0.9874,  1.5338, -0.6969,  0.6457,  0.2458,
           0.8002, -0.6944,  0.6204, -0.3388,  1.6230,  0.6825, -1.3007,
           1.6976, -0.6427, -1.0558, -0.7426]]], grad_fn=<AddBackward0>) torch.Size([1, 15, 32])
#### arr_b tensor([[[ 1.6416,  0.2271, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 1.8722,  0.3001, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.2511,  0.3824, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.6105,  0.4627, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 2.8426,  0.5884, -0.2861, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2659,  0.5711, -0.2796, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.8512,  0.6076, -0.2809, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 4.3783,  0.6288, -0.2535, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.4571,  0.8924, -0.2310, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.3584,  0.7907,  0.1813, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 5.1351,  0.7417,  0.2302, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4994, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 4.3846,  0.7205,  0.3123, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3435, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.4078, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3785, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 3.2958,  0.3619, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459],
         [ 1.5889,  0.3488, -0.0759, -0.3459, -0.3459, -0.3459, -0.3459,
          -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459, -0.3459]]]) torch.Size([1, 24, 14])
#### mat_b tensor([[[ 3.3489e-01,  5.7989e-01, -1.6826e-01, -4.1756e-01, -2.9501e-01,
          -3.4091e-01,  1.2169e-02, -4.6736e-02,  3.8699e-01, -1.8479e-01,
           5.4730e-01, -4.3985e-01, -2.0523e-01, -3.2781e-01, -5.5029e-01,
          -2.5467e-01, -2.7362e-01,  5.3830e-01, -1.1837e-01,  3.2168e-01,
           1.9897e-01,  4.5354e-01, -2.7145e-01,  1.7312e-01, -1.3636e-01,
           7.6089e-01,  5.3569e-01, -5.7500e-01,  6.8836e-01, -2.0367e-01,
          -4.5565e-01, -3.5669e-01],
         [ 3.7136e-01,  2.4510e-01, -1.8284e-01, -1.3897e-01, -1.8244e-01,
          -1.7439e-01,  1.2289e-01, -5.9429e-02,  3.4567e-01, -3.0634e-02,
           6.0811e-01, -2.6428e-01, -1.8670e-01,  3.4555e-03, -5.9517e-01,
          -3.1962e-01, -2.0509e-01,  4.1675e-01, -6.2932e-02,  4.1547e-01,
           1.2005e-01,  5.5553e-01, -2.2090e-01,  2.2531e-01, -4.2938e-01,
           4.0411e-01,  3.7468e-01, -4.4294e-01,  5.8476e-01, -2.0557e-01,
          -5.8720e-01, -2.5175e-01],
         [ 3.9327e-01,  6.9116e-01, -1.0450e-01, -3.4793e-01, -3.4009e-01,
          -3.0083e-01, -8.0504e-02,  2.0488e-01,  3.4570e-01, -3.7275e-01,
           3.6864e-01, -6.2661e-01, -2.4462e-01, -3.0419e-01, -5.3638e-01,
          -1.6549e-01, -2.7162e-01,  6.0547e-01, -2.3047e-01,  2.8042e-01,
          -1.3358e-02,  4.5338e-01, -2.6927e-01,  1.9859e-01, -4.9361e-02,
           7.3558e-01,  2.9121e-01, -6.2854e-01,  6.1252e-01, -2.9607e-01,
          -3.9698e-01, -4.4442e-01],
         [ 4.4576e-01,  8.3832e-01, -2.7645e-01, -6.2124e-01, -5.0582e-01,
          -2.5355e-01,  8.5906e-03,  1.0481e-01,  6.5020e-01, -3.1234e-01,
           3.9517e-01, -5.0244e-01, -1.6713e-01, -3.1872e-01, -6.5396e-01,
          -1.1330e-01, -4.6619e-01,  6.4966e-01, -3.6292e-01,  2.1852e-01,
           2.1384e-01,  5.3826e-01, -3.9992e-01,  2.6413e-01, -2.5010e-01,
           8.2717e-01,  4.2096e-01, -5.9008e-01,  9.2682e-01, -2.1746e-01,
          -4.4317e-01, -4.2714e-01],
         [ 5.2248e-01,  4.1042e-01, -3.8769e-01, -3.7433e-01, -3.7390e-01,
          -2.1843e-01,  1.6364e-01,  4.9497e-02,  8.1624e-01,  3.9023e-03,
           6.6223e-01, -7.5715e-02, -1.5926e-01, -1.1629e-01, -7.3737e-01,
          -5.1792e-01, -4.1994e-01,  6.6061e-01, -4.1854e-01,  3.9237e-01,
           4.0828e-01,  6.2716e-01, -3.7826e-01,  3.3823e-01, -4.4017e-01,
           6.9040e-01,  5.6171e-01, -6.0479e-01,  8.7406e-01, -1.4246e-01,
          -6.4549e-01, -4.2274e-01],
         [ 4.8954e-01,  1.0852e+00, -4.5064e-01, -6.5543e-01, -6.2778e-01,
          -3.7965e-01, -1.6028e-01,  2.1522e-01,  5.9423e-01, -4.8686e-01,
           7.2150e-01, -8.2480e-01, -2.1892e-01, -5.6405e-01, -7.5686e-01,
          -2.9049e-01, -4.7889e-01,  8.8914e-01, -5.6525e-01,  3.4339e-01,
           1.6891e-01,  5.0543e-01, -6.4742e-01,  1.2635e-01,  1.4918e-03,
           1.1392e+00,  5.6378e-01, -8.1904e-01,  9.7832e-01, -4.2224e-01,
          -2.9924e-01, -4.8274e-01],
         [ 6.2875e-01,  1.3460e+00, -4.9785e-01, -8.5208e-01, -1.0964e+00,
          -5.2561e-01, -1.2780e-01,  3.3707e-01,  9.1718e-01, -2.2065e-01,
           9.5345e-01, -8.0604e-01, -5.3464e-01, -5.6468e-01, -9.7906e-01,
          -3.9061e-01, -5.9155e-01,  1.1348e+00, -5.0406e-01,  3.0283e-01,
           2.2772e-01,  7.0534e-01, -4.0304e-01,  4.1986e-01, -2.0422e-01,
           1.2705e+00,  8.3904e-01, -1.2216e+00,  1.5097e+00, -5.8312e-01,
          -5.3503e-01, -8.8909e-01],
         [ 8.7012e-01,  1.2294e+00, -5.2584e-01, -8.2123e-01, -9.7977e-01,
          -5.3488e-01, -2.0704e-01,  5.6238e-01,  1.3015e+00, -1.7544e-01,
           9.8227e-01, -7.6670e-01, -3.9863e-01, -3.3667e-01, -1.0984e+00,
          -7.5968e-01, -8.8591e-01,  1.3200e+00, -6.3012e-01,  7.8815e-01,
           3.8415e-01,  8.9927e-01, -7.0112e-01,  7.2992e-01, -4.6277e-01,
           1.4161e+00,  9.7038e-01, -1.1510e+00,  1.4711e+00, -6.2869e-01,
          -8.7462e-01, -9.9251e-01],
         [ 5.9086e-01,  1.0908e+00, -7.1619e-01, -8.7547e-01, -6.8118e-01,
          -4.5439e-01,  3.3594e-02,  4.0913e-01,  7.2007e-01, -2.3306e-01,
           1.0152e+00, -9.4221e-01, -2.6980e-01, -5.2516e-01, -9.1507e-01,
          -6.0376e-01, -7.1046e-01,  1.0493e+00, -5.9825e-01,  4.0807e-01,
           2.4573e-01,  7.6574e-01, -6.8900e-01,  1.7239e-01, -2.4491e-01,
           1.1064e+00,  6.7462e-01, -1.1286e+00,  1.1192e+00, -3.9517e-01,
          -6.7003e-01, -6.4470e-01],
         [ 3.8824e-01,  9.3132e-01, -4.4655e-01, -5.6040e-01, -5.9757e-01,
          -3.6324e-01, -4.5153e-02, -3.2247e-01,  7.0372e-01, -2.3504e-01,
           9.4736e-01, -5.4893e-01, -2.8154e-01, -3.5875e-01, -6.5707e-01,
          -3.6025e-01, -4.0895e-01,  5.5107e-01, -3.0607e-01,  3.6966e-01,
           3.8655e-01,  7.6113e-01, -4.0513e-01,  1.2456e-01, -4.8100e-01,
           1.1831e+00,  8.4405e-01, -8.2818e-01,  1.1454e+00, -3.2809e-01,
          -6.9219e-01, -5.7008e-01],
         [ 5.8944e-01,  7.6540e-01, -6.0256e-01, -4.0179e-01, -5.4671e-01,
          -3.6707e-01, -4.7343e-02, -6.5455e-02,  6.7933e-01, -6.1068e-02,
           1.1866e+00, -5.4378e-01, -1.9891e-01, -1.7259e-01, -9.4773e-01,
          -6.3003e-01, -3.8336e-01,  7.1103e-01, -4.8316e-01,  5.2592e-01,
           5.3544e-01,  7.5467e-01, -5.8522e-01,  2.0172e-01, -4.5711e-01,
           9.0729e-01,  6.9409e-01, -7.7509e-01,  9.0050e-01, -3.7826e-01,
          -7.2872e-01, -1.9678e-01],
         [ 3.2312e-01,  1.2282e+00, -1.1089e+00, -9.4425e-01, -8.1303e-01,
          -5.5788e-01,  4.0716e-01,  1.8530e-01,  1.0806e+00, -5.8875e-02,
           1.2934e+00, -1.1344e+00, -1.7292e-01, -2.3086e-01, -1.1524e+00,
          -6.8403e-01, -7.6305e-01,  1.1737e+00, -5.2889e-01,  7.5492e-01,
           5.3779e-01,  1.1532e+00, -8.6398e-01,  1.1057e-01, -6.6794e-01,
           1.3833e+00,  9.5942e-01, -1.5421e+00,  1.7643e+00, -8.1670e-02,
          -1.1673e+00, -7.6495e-01],
         [ 6.9034e-01,  7.8290e-01, -2.6537e-01, -5.3715e-01, -6.0619e-01,
          -4.4398e-01, -1.6867e-02,  1.4255e-01,  6.5545e-01, -2.1879e-01,
           9.3902e-01, -7.9388e-01, -4.3293e-01, -4.2808e-02, -1.0799e+00,
          -4.6635e-01, -5.2397e-01,  6.6800e-01, -1.0945e-01,  5.3819e-01,
           2.7452e-01,  8.9026e-01, -2.2987e-01,  2.9010e-01, -5.8079e-01,
           1.0334e+00,  8.4037e-01, -9.7349e-01,  1.0716e+00, -6.1866e-01,
          -1.0147e+00, -6.0110e-01],
         [ 8.3677e-01,  1.3722e+00, -7.0683e-01, -1.0426e+00, -1.4520e+00,
          -6.2362e-01,  1.2695e-01,  4.0183e-01,  1.0521e+00,  1.8818e-01,
           1.5580e+00, -9.1401e-01, -7.5763e-01, -2.0556e-01, -1.6439e+00,
          -9.1938e-01, -8.8058e-01,  1.4413e+00, -6.9111e-01,  5.4570e-01,
           3.1683e-01,  8.0340e-01, -2.9798e-01,  4.6600e-01, -3.9740e-01,
           1.5174e+00,  1.1463e+00, -1.4079e+00,  1.5956e+00, -7.9894e-01,
          -1.1934e+00, -8.2479e-01],
         [ 6.0265e-01,  1.1721e+00, -8.1745e-01, -4.6892e-01, -7.7015e-01,
          -4.0795e-01, -2.3919e-01, -1.4782e-01,  1.3560e+00, -1.1666e-01,
           1.3066e+00, -3.6481e-01, -2.9537e-01, -1.8971e-01, -1.1807e+00,
          -8.8150e-01, -9.3233e-01,  8.7334e-01, -5.8843e-01,  6.3616e-01,
           5.7912e-01,  7.1227e-01, -8.3881e-01,  4.2997e-01, -8.6446e-01,
           1.4629e+00,  1.1840e+00, -9.7222e-01,  1.5235e+00, -6.3467e-01,
          -1.1610e+00, -5.4421e-01],
         [ 6.1307e-01,  9.8900e-01, -4.0535e-01, -6.8395e-01, -7.2871e-01,
          -4.0614e-01, -1.4348e-01,  1.5384e-01,  6.8862e-01, -8.8615e-02,
           9.2390e-01, -7.8439e-01, -3.3765e-01, -2.5838e-01, -5.9625e-01,
          -4.6424e-01, -3.5305e-01,  9.6825e-01, -3.9629e-01,  6.1251e-01,
           4.3914e-01,  8.5276e-01, -4.9441e-01,  3.5654e-01, -3.7701e-01,
           1.0334e+00,  6.2229e-01, -8.7870e-01,  1.2394e+00, -4.2244e-01,
          -4.7055e-01, -7.3933e-01],
         [ 4.3808e-01,  7.5340e-01, -7.2282e-01, -6.1438e-01, -3.3754e-01,
          -3.5731e-01, -3.9045e-02,  1.7898e-01,  9.2812e-01,  4.5800e-02,
           8.5167e-01, -4.4675e-01,  3.2536e-02, -2.4697e-01, -3.7041e-01,
          -4.4584e-01, -4.8747e-01,  6.7448e-01, -3.3476e-01,  5.3308e-01,
           5.0378e-01,  6.8305e-01, -6.7926e-01,  4.5820e-01, -6.9198e-01,
           7.6719e-01,  3.3196e-01, -6.8588e-01,  1.0592e+00, -1.3518e-01,
          -7.0316e-01, -5.8134e-01],
         [ 3.1520e-01,  8.1576e-01, -7.2423e-01, -8.9918e-01, -4.4252e-01,
          -4.4792e-01,  2.2973e-01,  4.2860e-01,  8.7669e-01, -8.1663e-02,
           7.6110e-01, -7.1843e-01, -4.6007e-03, -4.0343e-01, -4.7010e-01,
          -3.9886e-01, -4.7209e-01,  7.2049e-01, -4.6706e-01,  2.3537e-01,
           2.9622e-02,  4.6405e-01, -5.0043e-01,  2.7475e-01, -2.5634e-01,
           7.1497e-01,  3.4447e-01, -1.0838e+00,  9.3768e-01, -5.2388e-02,
          -6.9538e-01, -6.9436e-01],
         [ 9.7204e-01,  9.3562e-01, -7.0347e-01, -9.3365e-01, -7.4708e-01,
          -3.7208e-01,  3.3399e-02,  2.3815e-01,  9.3449e-01, -1.8798e-01,
           1.3582e+00, -6.3950e-01, -4.0977e-01,  5.9595e-03, -1.3686e+00,
          -9.4873e-01, -9.3550e-01,  1.0383e+00, -4.6963e-01,  5.4676e-01,
           5.4442e-01,  8.9659e-01, -5.5748e-01,  2.6517e-01, -6.5317e-01,
           1.2156e+00,  1.3623e+00, -8.9743e-01,  1.5272e+00, -7.7759e-01,
          -8.2706e-01, -6.7128e-01],
         [ 7.1730e-01,  1.1081e+00, -5.8804e-01, -7.9043e-01, -7.9416e-01,
          -4.8029e-01, -5.5949e-02,  2.2016e-01,  9.9415e-01, -1.6628e-01,
           1.1248e+00, -7.5614e-01, -3.1948e-01, -3.1994e-01, -9.1011e-01,
          -6.1298e-01, -6.5691e-01,  9.4278e-01, -5.9767e-01,  4.9112e-01,
           3.6782e-01,  8.1598e-01, -5.8094e-01,  3.7183e-01, -5.3046e-01,
           1.0905e+00,  7.7548e-01, -1.0513e+00,  1.2971e+00, -5.9310e-01,
          -8.4027e-01, -7.1444e-01],
         [ 6.8574e-01,  6.1291e-01, -2.0103e-01, -7.6040e-01, -3.3268e-01,
          -3.8592e-01, -7.4135e-02,  5.2070e-01,  7.8907e-01, -6.8408e-02,
           7.4520e-01, -6.7707e-01, -2.4131e-01, -1.2099e-01, -5.3533e-01,
          -4.7143e-01, -2.9802e-01,  5.1891e-01, -2.4348e-02,  4.8938e-01,
           6.9469e-02,  5.5902e-01, -2.7013e-01,  5.5179e-01, -4.7945e-01,
           7.0723e-01,  4.1014e-01, -9.2396e-01,  7.4643e-01, -4.9238e-01,
          -7.7701e-01, -8.6155e-01],
         [ 4.8461e-01,  9.1118e-01, -5.0216e-01, -8.6521e-01, -4.9039e-01,
          -3.6345e-01,  1.8669e-01,  2.8835e-01,  8.6520e-01, -2.8489e-01,
           6.7971e-01, -7.5444e-01, -1.1732e-01, -3.2856e-01, -6.0340e-01,
          -3.2417e-01, -5.2336e-01,  6.6832e-01, -2.6687e-01,  3.7501e-01,
           3.1954e-01,  7.3936e-01, -3.7457e-01,  3.4645e-01, -5.4598e-01,
           9.6372e-01,  7.7764e-01, -9.1670e-01,  1.3030e+00, -2.2955e-01,
          -5.3498e-01, -8.7492e-01],
         [ 5.5951e-01,  8.6396e-01, -2.2761e-01, -3.9228e-01, -7.9452e-01,
          -3.1683e-01,  1.6868e-02,  1.1765e-01,  7.0194e-01, -2.3380e-01,
           7.1752e-01, -7.3891e-01, -4.0398e-01, -2.9736e-01, -6.2570e-01,
          -3.3342e-01, -3.3093e-01,  6.1778e-01, -3.3885e-01,  3.6784e-01,
           1.3559e-01,  8.4386e-01, -6.2747e-02,  3.0862e-01, -4.5109e-01,
           1.0715e+00,  6.1268e-01, -8.4353e-01,  9.7177e-01, -4.6197e-01,
          -7.3905e-01, -8.2758e-01],
         [ 4.0694e-01,  4.3648e-01, -3.8132e-01, -4.3208e-01, -2.0945e-01,
          -2.9129e-01, -7.4525e-03,  6.3217e-02,  5.0536e-01, -1.0879e-01,
           5.0387e-01, -3.7099e-01, -5.2015e-02, -2.9706e-01, -3.8698e-01,
          -2.7774e-01, -3.6906e-01,  5.7367e-01, -2.4113e-01,  3.3396e-01,
           1.8345e-01,  4.6515e-01, -4.2803e-01,  3.3004e-01, -2.3542e-01,
           5.7632e-01,  2.7108e-01, -4.4603e-01,  5.3140e-01, -5.4812e-02,
          -4.8134e-01, -3.1936e-01]]], grad_fn=<AddBackward0>) torch.Size([1, 24, 32])
#### arr_b tensor([[[ 1.6107,  0.2177, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 1.8378,  0.2896, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 2.2109,  0.3706, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 2.5649,  0.4498, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 2.7934,  0.5735, -0.2877, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2103,  0.5564, -0.2813, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.7867,  0.5924, -0.2826, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 4.3058,  0.6133, -0.2556, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 5.3681,  0.8729, -0.2334, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 5.2710,  0.7727,  0.1726, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 5.0511,  0.7244,  0.2207, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.4858, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 4.3120,  0.7036,  0.3016, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3324, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3956, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3668, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466],
         [ 3.2397,  0.3505, -0.0807, -0.3466, -0.3466, -0.3466, -0.3466,
          -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466, -0.3466]]]) torch.Size([1, 23, 14])
#### mat_b tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan],
         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
          nan, nan, nan, nan, nan, nan, nan, nan, nan]]],
       grad_fn=<AddBackward0>) torch.Size([1, 23, 32])