
CUDA availability: True
  1%|██▌                                                                                                                                                                                 | 7/496 [00:01<01:11,  6.87it/s]
### event lambdas:  tensor([[0.6902, 0.7878, 0.4189, 0.1433]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(3.4224, grad_fn=<NegBackward>) non event loss:  tensor([34807.8919], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(2.1556, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[0.0336, 0.0135, 0.0076, 0.0019, 0.0023, 0.0050]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(30.1991, grad_fn=<NegBackward>) non event loss:  tensor([2301.7855], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(3.0365, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[0.0271, 0.0224, 0.0098, 0.0030, 0.0025, 0.0008, 0.0035, 0.0009, 0.0009,
         0.0011, 0.0011, 0.0009]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(71.3988, grad_fn=<NegBackward>) non event loss:  tensor([1498.4948], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(1.5906, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[0.0071, 0.0052, 0.0006, 0.0003, 0.0002, 0.0002, 0.0002]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(52.0446, grad_fn=<NegBackward>) non event loss:  tensor([183.1117], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0991, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[4.6682e-04, 1.4134e-04, 1.3960e-04, 1.5243e-04, 3.8312e-05, 4.9786e-05,
         5.8427e-05]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(64.0247, grad_fn=<NegBackward>) non event loss:  tensor([51.2895], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0103, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[0.0013, 0.0002, 0.0001, 0.0002, 0.0002, 0.0001]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(50.6816, grad_fn=<NegBackward>) non event loss:  tensor([52.4856], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0241, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[3.0130e-04, 1.4415e-03, 6.3587e-04, 5.9134e-05, 4.7713e-05, 6.2739e-05,
         4.3929e-05, 3.3943e-05, 3.8327e-05, 2.9079e-05, 5.3105e-05]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(102.1543, grad_fn=<NegBackward>) non event loss:  tensor([30.4378], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0387, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[9.3854e-04, 6.8175e-05, 5.9936e-05, 5.9790e-05, 3.0154e-05, 5.0350e-05,
         2.0854e-05, 1.1730e-05, 1.0352e-05, 4.1128e-06, 3.3699e-06, 3.4059e-06,

  3%|█████▍                                                                                                                                                                             | 15/496 [00:03<01:46,  4.51it/s]
##### event loss: tensor(138.5554, grad_fn=<NegBackward>) non event loss:  tensor([69.9767], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0553, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.0814e-05, 1.6880e-05, 9.5930e-06, 5.2718e-06, 1.2452e-06, 2.6275e-06,
         1.9160e-06, 8.2285e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(99.7532, grad_fn=<NegBackward>) non event loss:  tensor([1.7180], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0783, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.7280e-04, 2.1243e-05, 1.1501e-05, 6.2827e-06, 2.2866e-06, 5.0501e-06,
         2.1081e-06, 2.0561e-06, 4.1607e-07, 1.2016e-06, 7.8373e-07, 6.8910e-07]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(150.2374, grad_fn=<NegBackward>) non event loss:  tensor([5.3232], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1218, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[4.7377e-05, 6.3959e-06, 4.8492e-07, 6.0826e-07, 2.8078e-07, 1.1044e-07,
         2.7781e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(96.9700, grad_fn=<NegBackward>) non event loss:  tensor([0.8095], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0533, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.7979e-06, 5.6622e-06, 2.2367e-07, 3.0492e-08, 1.1252e-07, 9.0984e-08,
         4.0568e-07, 3.9234e-07, 4.8329e-07, 4.3114e-07, 3.7389e-07]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(163.6098, grad_fn=<NegBackward>) non event loss:  tensor([1.0867], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1685, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[9.0079e-06, 2.7678e-06, 8.1819e-07, 7.4376e-07, 2.2713e-07, 2.7912e-07,
         3.1620e-07, 2.6385e-07, 2.6689e-07, 2.0106e-07, 1.8807e-07, 5.3058e-07,
         4.6418e-08, 3.8261e-08, 5.2276e-08, 3.3588e-08, 4.9093e-08, 4.0590e-08,
         6.1647e-08, 2.8495e-07, 7.0076e-08, 1.8291e-07, 1.2018e-07, 1.8840e-07,
         1.9572e-07, 6.5454e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(400.0938, grad_fn=<NegBackward>) non event loss:  tensor([0.8932], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.3464, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[9.1858e-05, 1.8615e-05, 5.8567e-06, 2.4833e-06, 2.6185e-06, 1.0474e-06]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(71.7628, grad_fn=<NegBackward>) non event loss:  tensor([0.9906], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1062, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[4.6400e-05, 3.4825e-05, 1.1690e-05, 2.1903e-07, 1.5697e-07, 5.1207e-08,
         3.4081e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(94.2807, grad_fn=<NegBackward>) non event loss:  tensor([0.8831], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1304, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.2501e-06, 7.2858e-07, 1.1892e-06, 2.0206e-07, 2.0882e-07, 3.9161e-07]],

  5%|█████████▋                                                                                                                                                                         | 27/496 [00:05<01:29,  5.21it/s]
##### event loss: tensor(86.3284, grad_fn=<NegBackward>) non event loss:  tensor([0.1358], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1087, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.3798e-06, 5.1082e-07, 3.6648e-07, 2.8700e-07, 1.0651e-07, 1.0464e-07,
         4.4016e-08, 1.8256e-08, 1.0354e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(140.8326, grad_fn=<NegBackward>) non event loss:  tensor([0.2173], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1275, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[4.1229e-06, 1.1041e-06, 1.8412e-06, 1.3421e-06, 1.4520e-06, 1.9870e-06,
         1.8464e-06, 9.0279e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(106.5333, grad_fn=<NegBackward>) non event loss:  tensor([1.1862], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1510, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.9791e-05, 9.5212e-07, 1.5788e-06, 6.4020e-07, 3.4917e-07, 2.7078e-07,
         1.3821e-07, 1.6847e-08]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(115.9984, grad_fn=<NegBackward>) non event loss:  tensor([0.0787], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0880, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.5308e-07, 1.4107e-07, 1.7001e-08, 3.6429e-08, 1.2609e-08]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(84.1703, grad_fn=<NegBackward>) non event loss:  tensor([0.0162], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0639, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[6.6256e-06, 8.3712e-06, 2.2847e-06, 7.8454e-07, 7.1612e-07, 2.1504e-07,
         6.1267e-08, 7.0248e-08]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(113.2439, grad_fn=<NegBackward>) non event loss:  tensor([0.1315], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0827, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.9634e-07, 3.1510e-07, 1.5935e-07, 8.2905e-08]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(61.9599, grad_fn=<NegBackward>) non event loss:  tensor([0.0224], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0419, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.4660e-07, 3.8890e-08, 6.0963e-08, 3.4506e-08, 4.8419e-08, 1.0637e-08,
         1.9204e-08, 6.3023e-08]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(135.6234, grad_fn=<NegBackward>) non event loss:  tensor([0.0393], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1523, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[8.6761e-06, 8.1619e-07, 3.2958e-07, 3.1761e-07, 4.8095e-08, 9.7163e-08,
         6.8928e-08, 8.9205e-08, 5.5465e-08, 5.5915e-08, 8.6565e-08, 5.7727e-08,
         3.5081e-08, 3.3534e-08, 1.3497e-08, 2.8957e-08, 3.0356e-08, 4.2801e-08,
         2.6780e-08, 1.0656e-08, 6.3814e-09, 4.9215e-09, 5.8375e-08, 8.8866e-09,
         3.3644e-08, 5.1370e-08, 1.3765e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(450.5270, grad_fn=<NegBackward>) non event loss:  tensor([0.1312], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.2982, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[7.2084e-08, 5.6442e-08, 2.9155e-08, 5.4056e-08, 6.0042e-08]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(83.8476, grad_fn=<NegBackward>) non event loss:  tensor([0.0681], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0848, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.2329e-07, 4.4290e-07, 3.9566e-07, 2.8837e-08, 5.5007e-08, 7.3161e-09]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(97.4981, grad_fn=<NegBackward>) non event loss:  tensor([0.0393], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1006, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.4954e-07, 5.6716e-09, 9.5697e-09, 2.6886e-09, 1.4308e-08]],
       grad_fn=<SoftplusBackward>)

  8%|██████████████▊                                                                                                                                                                    | 41/496 [00:07<00:51,  8.84it/s]
### event lambdas:  tensor([[1.0834e-07, 7.8809e-08, 2.2753e-07, 2.9409e-07, 3.2352e-08, 3.0574e-08,
         3.5255e-08, 1.7445e-08, 2.2398e-08, 1.2464e-07, 1.0213e-07, 6.5679e-08,
         4.4694e-08, 4.9992e-08, 9.2373e-08, 1.4350e-07]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(264.1411, grad_fn=<NegBackward>) non event loss:  tensor([0.3177], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.2232, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.5011e-06, 1.9573e-06, 1.7125e-06, 6.0236e-07, 2.9520e-08, 4.1605e-09]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(90.2785, grad_fn=<NegBackward>) non event loss:  tensor([0.0562], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0776, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.1796e-06, 2.3217e-07, 1.3875e-07, 3.5695e-07, 1.2425e-07]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(74.8494, grad_fn=<NegBackward>) non event loss:  tensor([0.0512], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0765, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.2126e-06, 5.7821e-07, 5.8659e-07, 1.1615e-07, 1.6093e-07, 1.3151e-07,
         9.2201e-08, 1.7610e-07, 1.5098e-07, 7.8848e-08, 1.0681e-07, 1.2393e-07]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(184.9575, grad_fn=<NegBackward>) non event loss:  tensor([0.0971], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1259, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.0746e-06, 1.5517e-06, 7.3315e-07, 1.4697e-08, 2.9531e-08, 5.0771e-09,
         3.2949e-08]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(112.9459, grad_fn=<NegBackward>) non event loss:  tensor([0.0637], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0949, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.4095e-07, 2.8948e-07, 3.3545e-07, 4.7544e-08, 2.4761e-08, 3.7976e-08]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(96.6636, grad_fn=<NegBackward>) non event loss:  tensor([0.0184], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0496, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.6173e-07, 2.8208e-07, 1.6064e-07, 1.4556e-08, 4.9405e-08, 5.6367e-08,
         6.5947e-08, 1.1530e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(130.4325, grad_fn=<NegBackward>) non event loss:  tensor([0.0627], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1319, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[3.4633e-07, 2.3813e-07, 6.5028e-08, 1.1963e-07, 2.8141e-08, 3.0007e-08,
         1.9017e-07, 1.2907e-07, 1.2012e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(144.5945, grad_fn=<NegBackward>) non event loss:  tensor([0.0949], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1458, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.2538e-06, 3.0054e-07, 1.7107e-07, 1.5594e-07, 9.7607e-08, 1.3549e-07]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(91.8187, grad_fn=<NegBackward>) non event loss:  tensor([0.0292], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0619, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[4.9775e-06, 2.7495e-07, 1.3713e-07, 7.6654e-08, 6.0253e-08, 7.8654e-08,
         7.0572e-08, 4.4318e-08, 3.1282e-08, 2.2738e-08, 7.5012e-09, 1.4012e-08,
         1.3530e-09, 9.3521e-09]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(236.4645, grad_fn=<NegBackward>) non event loss:  tensor([0.0639], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1356, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[4.5069e-07, 3.4817e-07, 3.4279e-08, 3.6182e-08, 1.6502e-08]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(81.7263, grad_fn=<NegBackward>) non event loss:  tensor([0.0061], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0551, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[7.1033e-07, 1.1392e-07, 3.2656e-08, 4.8946e-08, 5.1435e-08, 1.0101e-08]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(99.4087, grad_fn=<NegBackward>) non event loss:  tensor([0.0508], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0933, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.7626e-07, 1.1768e-07, 3.5740e-08, 2.2196e-08, 8.9609e-08, 4.0743e-08]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(99.5208, grad_fn=<NegBackward>) non event loss:  tensor([0.0207], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0676, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[8.5103e-08, 4.7727e-08, 1.8509e-08]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(50.9422, grad_fn=<NegBackward>) non event loss:  tensor([0.0050], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0278, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.7781e-05, 5.2649e-07, 1.9168e-07, 1.5154e-07, 7.3317e-08, 5.5468e-08,

 10%|██████████████████▊                                                                                                                                                                | 52/496 [00:09<01:12,  6.09it/s]
##### event loss: tensor(142.3985, grad_fn=<NegBackward>) non event loss:  tensor([0.0981], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1438, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.1142e-06, 6.6671e-07, 1.3195e-07, 9.9178e-09]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(62.1981, grad_fn=<NegBackward>) non event loss:  tensor([0.0030], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0270, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.6690e-07, 4.6041e-08, 3.1708e-08, 2.4940e-08, 2.1330e-08, 2.0483e-08,
         1.1653e-08, 1.4090e-08, 8.4893e-09, 1.2843e-08, 1.3256e-08, 1.3521e-08,
         1.0364e-08, 7.8405e-09, 1.3469e-08, 8.0146e-09, 6.0666e-09, 1.5141e-08,
         5.2639e-09, 1.2388e-08, 1.7243e-08, 1.0256e-08, 9.3160e-09, 1.0935e-08,
         1.9469e-09, 2.3089e-09, 6.6328e-09, 2.1040e-09, 4.4314e-09]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(530.6207, grad_fn=<NegBackward>) non event loss:  tensor([0.0427], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1914, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.8310e-06, 5.8630e-07, 1.4412e-07, 5.2219e-08, 3.6245e-08, 7.1218e-08,
         7.1075e-08]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(109.6948, grad_fn=<NegBackward>) non event loss:  tensor([0.0457], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0803, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.6747e-07, 2.6615e-07, 8.2372e-08, 2.8028e-08, 4.9929e-08]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(81.2564, grad_fn=<NegBackward>) non event loss:  tensor([0.0321], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0857, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.1744e-07, 1.3038e-07, 1.4698e-07, 3.0871e-08, 4.6738e-08, 3.0516e-08,
         6.0909e-09, 1.0099e-08, 4.4940e-08]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(152.6495, grad_fn=<NegBackward>) non event loss:  tensor([0.0835], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1582, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[4.3430e-07, 5.6117e-07, 2.0763e-07, 2.4798e-07]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(59.6402, grad_fn=<NegBackward>) non event loss:  tensor([0.0194], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0606, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.0745e-06, 2.7789e-07, 3.7570e-07, 2.3110e-07, 2.7154e-07]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(73.3758, grad_fn=<NegBackward>) non event loss:  tensor([0.0601], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0440, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[9.2229e-08, 3.6609e-08, 9.7905e-09, 1.2152e-08, 3.7674e-09, 5.2509e-09,
         1.1657e-08, 1.2700e-08, 2.2156e-09]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(164.8281, grad_fn=<NegBackward>) non event loss:  tensor([0.0113], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1002, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[7.5069e-06, 1.0251e-06, 7.0437e-07, 6.3067e-07, 2.8461e-07, 1.5574e-07,
         3.6336e-07, 5.0569e-07, 1.8637e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(129.6009, grad_fn=<NegBackward>) non event loss:  tensor([0.2389], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1158, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[8.7560e-07, 1.1703e-06, 6.9441e-07, 1.7994e-07, 1.8744e-07]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(72.8072, grad_fn=<NegBackward>) non event loss:  tensor([0.1001], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0909, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[5.2995e-07, 1.9116e-07, 9.9136e-08, 7.1238e-08, 2.4260e-08, 3.4724e-07,
         2.3471e-07, 1.5883e-07, 1.2816e-07]], grad_fn=<SoftplusBackward>)
 12%|██████████████████████▍                                                                                                                                                            | 62/496 [00:10<01:16,  5.66it/s]
Traceback (most recent call last):
  File "main.py", line 156, in <module>
    main()
  File "main.py", line 152, in main
    model_trained = train(dataset, config,  device)
  File "main.py", line 107, in train
    loss, pos_timing_loss, neg_timing_loss, choice_l = model(arr_b.float(), arr_c.float(), arr_delta_time.float(), event_data, non_event_data, estimate_length, choice_data_dict)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 195, in forward
    choice_l = self.choice_net(mat_b, mat_c, choice_data_dict, self.s_year, self.e_year)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 369, in forward
    z_vt_i = self.gnn_choice(features_i.squeeze(), edges_i.squeeze()) # (N_i_1, embedding_z)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 472, in forward
    x = self.convs[i](x, edge_index)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 507, in forward
    prop = self.propagate(edge_index, x=(x, x), size=size)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 294, in propagate
    out = self.aggregate(out, **aggr_kwargs)
  File "/home/dalab5/Projects/MA_packed/model.py", line 523, in aggregate
    out = torch_scatter.scatter(inputs, index, node_dim, dim_size=dim_size, reduce='mean')
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch_scatter/scatter.py", line 157, in scatter
    return scatter_mean(src, index, dim, out, dim_size)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch_scatter/scatter.py", line 42, in scatter_mean
    out = scatter_sum(src, index, dim, out, dim_size)
  File "/home/dalab5/miniconda3/envs/GNN/lib/python3.8/site-packages/torch_scatter/scatter.py", line 21, in scatter_sum
    return out.scatter_add_(dim, index, src)
KeyboardInterrupt
### event lambdas:  tensor([[1.2755e-07, 2.6049e-08, 2.4983e-08, 3.1437e-08, 2.8414e-08, 1.1356e-08,
         6.1585e-09, 5.7026e-09, 6.0652e-09]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(160.5967, grad_fn=<NegBackward>) non event loss:  tensor([0.1004], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1332, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.1721e-06, 3.6263e-07, 2.5549e-07, 2.6863e-07, 1.8935e-07, 1.2025e-07,
         7.1366e-08, 1.6133e-07, 4.3435e-08]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(139.2573, grad_fn=<NegBackward>) non event loss:  tensor([0.1843], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1391, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[3.0895e-06, 3.7675e-07, 2.1071e-07, 1.2070e-07, 8.8294e-09, 1.9224e-08,
         1.5241e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(110.7909, grad_fn=<NegBackward>) non event loss:  tensor([0.0452], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1096, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.7292e-06, 4.4630e-07, 3.9275e-07, 3.3659e-07, 3.2174e-07, 3.4904e-07,
         4.2086e-07, 2.6892e-07, 2.6827e-07, 3.8410e-07, 7.9168e-08, 4.6199e-07]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(178.0151, grad_fn=<NegBackward>) non event loss:  tensor([0.1940], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1512, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[4.5511e-07, 4.0086e-08, 6.8823e-08, 2.0894e-08, 6.4217e-08]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(82.3715, grad_fn=<NegBackward>) non event loss:  tensor([0.0900], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0813, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[8.4964e-07, 5.1171e-07, 1.3050e-07, 1.2910e-07, 1.9641e-07, 5.9810e-08,
         1.1531e-07, 1.2419e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(124.1309, grad_fn=<NegBackward>) non event loss:  tensor([0.3391], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1307, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[7.4650e-07, 8.2735e-07, 1.2519e-07, 3.2801e-07, 1.0698e-07, 1.6565e-07]],
       grad_fn=<SoftplusBackward>)
##### event loss: tensor(90.6006, grad_fn=<NegBackward>) non event loss:  tensor([0.1376], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0899, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[2.8068e-06, 5.3583e-07, 1.4287e-07, 2.0435e-07, 4.2956e-07, 2.8902e-07,
         6.2834e-07, 3.0349e-07]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(117.3931, grad_fn=<NegBackward>) non event loss:  tensor([0.4096], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.1759, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[1.0692e-05, 3.2961e-06, 4.7162e-06, 3.6066e-06, 4.0972e-06, 1.8760e-06,
         1.3397e-06, 2.5193e-07, 1.3311e-07, 2.5076e-07, 1.9418e-07, 1.9828e-07,
         9.4916e-08, 3.9776e-07, 3.6654e-08]], grad_fn=<SoftplusBackward>)
##### event loss: tensor(213.1231, grad_fn=<NegBackward>) non event loss:  tensor([0.3639], dtype=torch.float64, grad_fn=<MulBackward0>) chocie_l: tensor(0.0599, grad_fn=<SumBackward0>)
### event lambdas:  tensor([[8.9236e-06, 5.5572e-06, 5.6405e-06, 3.3833e-06, 1.2334e-06, 4.2142e-07,
         3.4509e-07, 4.0177e-07, 4.1871e-07, 4.0967e-07, 4.4247e-07, 1.1433e-06]],
       grad_fn=<SoftplusBackward>)